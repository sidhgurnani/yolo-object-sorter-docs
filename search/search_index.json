{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#yolo-based-binary-object-sorting-system","title":"YOLO-Based Binary Object Sorting System","text":"<p>Welcome! This mkdocs page will contain documentation regarding what this project is about as well as progress for where I am at and all developments that have occured. This serves as a log of information I have collected throughout the development process.</p> <p>I just want to give a special thank you to Dr. Nirav Merchant from the University of Arizona for being an incredible mentor throughout the whole project. </p>"},{"location":"#about-me","title":"About Me","text":"<p>My name is Sidh Gurnani, and I studied Mechanical Engineering at Purdue University, and graduated with my Bachelor's in May 2025. I have worked on this project from June 2024 up to November 2025.</p> <p>Visit my portfolio</p>"},{"location":"#overview","title":"Overview","text":"<p>View the presentation below to get a high level summary of the project:</p> <p>Trouble Loading? Click Here to View PDF</p> <p></p>"},{"location":"#github-repository","title":"GitHub Repository","text":"<p>This GitHub repo contains all of the files I used when I did all demos, including the Python app, Arduino code, STL files for the mechanical components, trained models I used, and test code for electronics. I found the best way to run this was to use PlatformIO within VSCode, so it is set up with that framework in mind. Feel free to have a look!</p> <p>Visit GitHub Repo</p>"},{"location":"#project-status","title":"Project Status\ud83e\udd16 YOLO Binary Object Sorter","text":"0% <ul> <li>\u2705 Milestone 1: Refresh programming knowledge</li> <li>\u2705 Milestone 2: Understand Basics of Machine Learning</li> <li>\u2705 Milestone 3: Develop Basic Software</li> <li> \u2705 Milestone 4: 3D Model and Design Physical Product</li> <li> \u2705 Milestone 5: Integrate Final Software and Hardware</li> <li>\u2705 Milestone 6: Final Testing</li> <li>\u2705 Milestone 7: Reflection and Next Steps</li> </ul>      \ud83d\udccc Up Next: Future Improvements"},{"location":"WebUSB_Findings/","title":"Version 0 - WebUSB Findings (Shelved)","text":""},{"location":"WebUSB_Findings/#brief-intro","title":"Brief Intro","text":"<p>This page outlines the basics of WebUSB, and how I set it up and tested for basic functionality. It also outlines my conclusion, which was presented on the Architecture page.</p> <p>WebUSB is an API that allows certain compatible microcontrollers to be able to communicate to a web browser. This would open up the potential for users to be able to interact with the Arduino using an HTML file. </p> <p>This relates to the project, as it is possible to be able to have a videofeed and have the user see what is going on and allow for a bit of manual control.</p> <p>This guide has some demos as well as code that can be ran to ensure that WebUSB is working as expected. The following is an adapted version of the tutorials presented in this video. For more information about the code and details about WebUSB, watch the linked video. </p>"},{"location":"WebUSB_Findings/#demos","title":"Demos","text":"<ol> <li>USB Recognition</li> <li>Microcontroller to Web Browser Communication</li> <li>Web Browser to Microcontroller Communication</li> </ol>"},{"location":"WebUSB_Findings/#usb-recognition","title":"USB Recognition","text":"<p>The goal of this demo is to create a basic website that will allow the user to plug in a USB device and obtain important details to the console. This demo does not require the use of the WebUSB library, and no code needs to be uploaded to the microcontroller. This means that ANY device, regardless of whether it supports WebUSB or not, can run this test successfully, as this relies on the browser picking up the fact that a USB was plugged in rather than communicating with it.</p> USB_recog.html<pre><code>&lt;a href=\"#\" id=\"click\"&gt;Connect to USB Device&lt;/a&gt;\n\n&lt;script&gt;\nclick.onclick = function() {\n    navigator.usb.requestDevice( {filters: [\n        {'vendorId': 0x2341}\n    ]})\n    .then(device =&gt; {\n        console.log(device)\n        console.log(\"Product Name: \" + device.productName.toString(16))\n        console.log(\"Product ID: \" + device.productId.toString(16))\n        console.log(\"Vendor ID: \"+ device.vendorId.toString(16))\n    })\n    .catch(error =&gt; {\n        console.log(error)\n    })\n}\n&lt;/script&gt;\n</code></pre> <p>Images below show output of html code and how it works when an Arduino Leonardo is connected:</p> <p></p> <p></p> <p>Note that no code is needed for the Arduino.</p>"},{"location":"WebUSB_Findings/#microcontroller-to-web-browser-communication","title":"Microcontroller to Web Browser Communication","text":"<p>The goal of this demo is to be able to send data from the microcontroller and the website. While this demo will work in this particular way, it sets up the backbone for establishing a 2 way communication between the microcontroller and the website.</p> <p>HTML Code:</p> Leo_to_Web.html<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;title&gt;USB Communication Test&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;a href=\"#\" id=\"click\"&gt;Listen to Leo&lt;/a&gt;\n        &lt;button id=\"connect\"&gt;Connect&lt;/button&gt;\n\n        &lt;script src=\"serial.js\"&gt;&lt;/script&gt;\n\n        &lt;script&gt;\n            document.getElementById('click').onclick = function() {\n                navigator.usb.requestDevice({ filters: [{ 'vendorId': 0x2341 }] })\n                    .then(device =&gt; {\n                        console.log(device);\n                        console.log(\"Product Name: \" + device.productName);\n                        console.log(\"Product ID: \" + device.productId.toString(16));\n                        console.log(\"Vendor ID: \" + device.vendorId.toString(16));\n                        console.log(\"Device Found! Awaiting messages...\");\n                    })\n                    .catch(error =&gt; {\n                        console.log(error);\n                    });\n            };\n\n            var port;\n            var connectButton = document.getElementById('connect');\n            var textDecoder = new TextDecoder();\n            var textEncoder = new TextEncoder();\n\n            connectButton.addEventListener('click', function() {\n              if (port) {\n                    // If port is already connected, disconnect it\n                    connectButton.textContent = 'Connect';\n                    port.disconnect();\n                    port = null;\n                    console.log('Device is disconnected.');\n                } else {\n                    // If there is no port, then connect to a new port\n                    serial.requestPort().then(selectedPort =&gt; {\n                        port = selectedPort;\n                        port.connect().then(() =&gt; {\n                            console.log('Device is connected to Product ID: ' + port.device_.productId.toString(16) + ' and Vendor ID: ' + port.device_.vendorId.toString(16));\n\n                            connectButton.textContent = 'Disconnect';\n                            port.onReceive = data =&gt; {\n                                console.log(textDecoder.decode(data));\n                            };\n                            port.onReceiveError = error =&gt; {\n                                console.log('Receive error: ' + error);\n                            };\n                        }, error =&gt; {\n                            console.log('Connection error: ' + error);\n                        });\n                    }).catch(error =&gt; {\n                        console.log('Connection error: ' + error);\n                    });\n                }\n            });\n\n            serial.requestPort = function() {\n                const filters = [\n                    { 'vendorId': 0x2341 }\n                ];\n                return navigator.usb.requestDevice({ 'filters': filters }).then(\n                    device =&gt; new serial.Port(device)\n                );\n            };\n        &lt;/script&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Arduino Code:</p> Leo2.ino<pre><code>#include &lt;WebUSB.h&gt;\n\n// Modified from example https://webusb.github.io/arduino/demos/console\nWebUSB WebUSBSerial(1, \"webusb.github.io/arduino/demos/console\");\nint c = 0;\n\nvoid setup() {\n  WebUSBSerial.begin(9600);\n  while (!WebUSBSerial) {}\n  delay(100);\n}\n\nvoid loop() {\n  c = c + 1;\n  if (WebUSBSerial){\n    WebUSBSerial.println(c);\n    WebUSBSerial.flush();    \n  } else {\n    c = 0;\n  }\n\n  delay(1000);\n}\n</code></pre> <p>Serial.js code:</p> serial.js<pre><code>var serial = {};\n\n(function() {\n  'use strict';\n\n  serial.getPorts = function() {\n    return navigator.usb.getDevices().then(devices =&gt; {\n      return devices.map(device =&gt; new serial.Port(device));\n    });\n  };\n\n  serial.requestPort = function() {\n    const filters = [\n      { 'vendorId': 0x2341, 'productId': 0x8036 }, // Arduino Leonardo\n      { 'vendorId': 0x2341, 'productId': 0x8037 }, // Arduino Micro\n      { 'vendorId': 0x2341, 'productId': 0x804d }, // Arduino/Genuino Zero\n      { 'vendorId': 0x2341, 'productId': 0x804e }, // Arduino/Genuino MKR1000\n      { 'vendorId': 0x2341, 'productId': 0x804f }, // Arduino MKRZERO\n      { 'vendorId': 0x2341, 'productId': 0x8050 }, // Arduino MKR FOX 1200\n      { 'vendorId': 0x2341, 'productId': 0x8052 }, // Arduino MKR GSM 1400\n      { 'vendorId': 0x2341, 'productId': 0x8053 }, // Arduino MKR WAN 1300\n      { 'vendorId': 0x2341, 'productId': 0x8054 }, // Arduino MKR WiFi 1010\n      { 'vendorId': 0x2341, 'productId': 0x8055 }, // Arduino MKR NB 1500\n      { 'vendorId': 0x2341, 'productId': 0x8056 }, // Arduino MKR Vidor 4000\n      { 'vendorId': 0x2341, 'productId': 0x8057 }, // Arduino NANO 33 IoT\n      { 'vendorId': 0x239A }, // Adafruit Boards!\n    ];\n    return navigator.usb.requestDevice({ 'filters': filters }).then(\n      device =&gt; new serial.Port(device)\n    );\n  }\n\n  serial.Port = function(device) {\n    this.device_ = device;\n    this.interfaceNumber_ = 2;  // original interface number of WebUSB Arduino demo\n    this.endpointIn_ = 5;       // original in endpoint ID of WebUSB Arduino demo\n    this.endpointOut_ = 4;      // original out endpoint ID of WebUSB Arduino demo\n  };\n\n  serial.Port.prototype.connect = function() {\n    let readLoop = () =&gt; {\n      this.device_.transferIn(this.endpointIn_, 64).then(result =&gt; {\n        this.onReceive(result.data);\n        readLoop();\n      }, error =&gt; {\n        this.onReceiveError(error);\n      });\n    };\n\n    return this.device_.open()\n        .then(() =&gt; {\n          if (this.device_.configuration === null) {\n            return this.device_.selectConfiguration(1);\n          }\n        })\n        .then(() =&gt; {\n          var configurationInterfaces = this.device_.configuration.interfaces;\n          configurationInterfaces.forEach(element =&gt; {\n            element.alternates.forEach(elementalt =&gt; {\n              if (elementalt.interfaceClass==0xff) {\n                this.interfaceNumber_ = element.interfaceNumber;\n                elementalt.endpoints.forEach(elementendpoint =&gt; {\n                  if (elementendpoint.direction == \"out\") {\n                    this.endpointOut_ = elementendpoint.endpointNumber;\n                  }\n                  if (elementendpoint.direction==\"in\") {\n                    this.endpointIn_ =elementendpoint.endpointNumber;\n                  }\n                })\n              }\n            })\n          })\n        })\n        .then(() =&gt; this.device_.claimInterface(this.interfaceNumber_))\n        .then(() =&gt; this.device_.selectAlternateInterface(this.interfaceNumber_, 0))\n        // The vendor-specific interface provided by a device using this\n        // Arduino library is a copy of the normal Arduino USB CDC-ACM\n        // interface implementation and so reuses some requests defined by\n        // that specification. This request sets the DTR (data terminal\n        // ready) signal high to indicate to the device that the host is\n        // ready to send and receive data.\n        .then(() =&gt; this.device_.controlTransferOut({\n            'requestType': 'class',\n            'recipient': 'interface',\n            'request': 0x22,\n            'value': 0x01,\n            'index': this.interfaceNumber_}))\n        .then(() =&gt; {\n          readLoop();\n        });\n  };\n\n  serial.Port.prototype.disconnect = function() {\n    // This request sets the DTR (data terminal ready) signal low to\n    // indicate to the device that the host has disconnected.\n    return this.device_.controlTransferOut({\n            'requestType': 'class',\n            'recipient': 'interface',\n            'request': 0x22,\n            'value': 0x00,\n            'index': this.interfaceNumber_})\n        .then(() =&gt; this.device_.close());\n  };\n\n  serial.Port.prototype.send = function(data) {\n    return this.device_.transferOut(this.endpointOut_, data);\n  };\n})();\n</code></pre> <p>Images below show output and how it works when an Arduino Leonardo is connected:</p> <p></p> <p></p>"},{"location":"WebUSB_Findings/#web-browser-to-microcontroller-communication-blinky","title":"Web Browser to Microcontroller Communication \u2192 Blinky","text":"<p>The goal of this demo is to be able to control a microcontroller by having the user interface with a website. For the project, it would open up many possibilities for human interaction as the sorter is working through sorting. As of today, the only thing that makes sense would be to have a manual override in case something goes wrong, and maybe a stop and start function. An HTML would also be able to display possible metrics that are coming in from the microcontroller. This would include how many items were sorted, a running count of each type of item sorted, etc. Metrics are something that I would consider desirable and not required. The biggest use case of the website would be to train the ML model that would be used to then sort. This would be something very similar to what is implemented on Teachable Machine by Google. </p> <p>This demo uses an Arduino Leonardo and an HTML file to turn on and off the builtin LED. </p> <p>HTML Code:</p> Leo_to_Web_BLINKY.html<pre><code>&lt;a href=\"#\" id=\"connect\"&gt;Connect&lt;/a&gt;\n\n&lt;p&gt;\n    &lt;button id=\"on\"&gt;LED ON&lt;/button&gt;\n    &lt;button id=\"off\"&gt;LED OFF&lt;/button&gt;\n&lt;/p&gt;\n\n&lt;script src=\"serial.js\"&gt;&lt;/script&gt;\n\n&lt;script&gt;\n    serial.requestPort = function() {\n        const filters = [\n            {'vendorId': 0x2341}\n        ];\n        return navigator.usb.requestDevice({'filters': filters}).then(\n            device =&gt; new serial.Port(device)\n        );\n    }\n\n    var port;\n    var connectButton = document.getElementById('connect');\n    var textDecoder = new TextDecoder();\n    var textEncoder = new TextEncoder();\n\n    document.querySelector('#on').addEventListener('click', function() {\n        if (port !== undefined) {\n            port.send(textEncoder.encode('H')).catch(error =&gt; {\n                console.log(\"Error: \" + error)\n            })\n            console.log(\"HTML: Turning on the LED!\")\n        }\n    })\n\n    document.querySelector('#off').addEventListener('click', function() {\n        if (port !== undefined) {\n            port.send(textEncoder.encode('L')).catch(error =&gt; {\n                console.log(\"Error: \" + error)\n            })\n            console.log(\"HTML: Turning off the LED!\")\n        }\n    })\n\n\n    connectButton.addEventListener('click', function() {\n              if (port) {\n                    // If port is already connected, disconnect it\n                    connectButton.textContent = 'Connect';\n                    port.disconnect();\n                    port = null;\n                    console.log('Device is disconnected.');\n                } else {\n                    // If there is no port, then connect to a new port\n                    serial.requestPort().then(selectedPort =&gt; {\n                        port = selectedPort;\n                        port.connect().then(() =&gt; {\n                            console.log('Device is connected to Product ID: ' + port.device_.productId.toString(16) + ' and Vendor ID: ' + port.device_.vendorId.toString(16));\n\n                            connectButton.textContent = 'Disconnect';\n                            port.onReceive = data =&gt; {\n                                console.log(textDecoder.decode(data));\n                            };\n                            port.onReceiveError = error =&gt; {\n                                console.log('Receive error: ' + error);\n                            };\n                        }, error =&gt; {\n                            console.log('Connection error: ' + error);\n                        });\n                    }).catch(error =&gt; {\n                        console.log('Connection error: ' + error);\n                    });\n                }\n            });\n&lt;/script&gt;\n</code></pre> <p>Arduino Code:</p> Blinky.ino<pre><code>#include &lt;WebUSB.h&gt;\nWebUSB WebUSBSerial(1, \"webusb.github.io/arduino/demos/console\");\n\nconst int ledPin = 13;\n\nvoid setup() {\n  WebUSBSerial.begin(9600);\n  while (!WebUSBSerial) {}\n  delay(100);\n\n  SerialUSB.begin(9600);\n  delay(100);\n\n  WebUSBSerial.write(\"Starting blinky!\");\n  WebUSBSerial.flush();\n  SerialUSB.println(\"Starting...\");\n\n  pinMode(ledPin, OUTPUT);\n}\n\nvoid loop() {\n  if (WebUSBSerial &amp;&amp; WebUSBSerial.available()) {\n    char byte = WebUSBSerial.read();  // Read the incoming byte as a character\n    WebUSBSerial.write(byte);  // Echo the received byte\n\n    if (byte == 'H') {  // Compare the byte with the character 'H'\n      SerialUSB.println(\"Received H!\");\n      WebUSBSerial.write(\"\\nTurning on LED\");\n      digitalWrite(ledPin, HIGH);  // Turn the LED on\n    } else if (byte == 'L') {  // Compare the byte with the character 'L'\n      SerialUSB.println(\"Received L!\");\n      WebUSBSerial.write(\"\\nTurning off LED\");\n      digitalWrite(ledPin, LOW);  // Turn the LED off\n    }\n\n    WebUSBSerial.flush();\n  }\n}\n</code></pre> <p>Serial.js code (same as before, provided for reference):</p> serial.js<pre><code>var serial = {};\n\n(function() {\n  'use strict';\n\n  serial.getPorts = function() {\n    return navigator.usb.getDevices().then(devices =&gt; {\n      return devices.map(device =&gt; new serial.Port(device));\n    });\n  };\n\n  serial.requestPort = function() {\n    const filters = [\n      { 'vendorId': 0x2341, 'productId': 0x8036 }, // Arduino Leonardo\n      { 'vendorId': 0x2341, 'productId': 0x8037 }, // Arduino Micro\n      { 'vendorId': 0x2341, 'productId': 0x804d }, // Arduino/Genuino Zero\n      { 'vendorId': 0x2341, 'productId': 0x804e }, // Arduino/Genuino MKR1000\n      { 'vendorId': 0x2341, 'productId': 0x804f }, // Arduino MKRZERO\n      { 'vendorId': 0x2341, 'productId': 0x8050 }, // Arduino MKR FOX 1200\n      { 'vendorId': 0x2341, 'productId': 0x8052 }, // Arduino MKR GSM 1400\n      { 'vendorId': 0x2341, 'productId': 0x8053 }, // Arduino MKR WAN 1300\n      { 'vendorId': 0x2341, 'productId': 0x8054 }, // Arduino MKR WiFi 1010\n      { 'vendorId': 0x2341, 'productId': 0x8055 }, // Arduino MKR NB 1500\n      { 'vendorId': 0x2341, 'productId': 0x8056 }, // Arduino MKR Vidor 4000\n      { 'vendorId': 0x2341, 'productId': 0x8057 }, // Arduino NANO 33 IoT\n      { 'vendorId': 0x239A }, // Adafruit Boards!\n    ];\n    return navigator.usb.requestDevice({ 'filters': filters }).then(\n      device =&gt; new serial.Port(device)\n    );\n  }\n\n  serial.Port = function(device) {\n    this.device_ = device;\n    this.interfaceNumber_ = 2;  // original interface number of WebUSB Arduino demo\n    this.endpointIn_ = 5;       // original in endpoint ID of WebUSB Arduino demo\n    this.endpointOut_ = 4;      // original out endpoint ID of WebUSB Arduino demo\n  };\n\n  serial.Port.prototype.connect = function() {\n    let readLoop = () =&gt; {\n      this.device_.transferIn(this.endpointIn_, 64).then(result =&gt; {\n        this.onReceive(result.data);\n        readLoop();\n      }, error =&gt; {\n        this.onReceiveError(error);\n      });\n    };\n\n    return this.device_.open()\n        .then(() =&gt; {\n          if (this.device_.configuration === null) {\n            return this.device_.selectConfiguration(1);\n          }\n        })\n        .then(() =&gt; {\n          var configurationInterfaces = this.device_.configuration.interfaces;\n          configurationInterfaces.forEach(element =&gt; {\n            element.alternates.forEach(elementalt =&gt; {\n              if (elementalt.interfaceClass==0xff) {\n                this.interfaceNumber_ = element.interfaceNumber;\n                elementalt.endpoints.forEach(elementendpoint =&gt; {\n                  if (elementendpoint.direction == \"out\") {\n                    this.endpointOut_ = elementendpoint.endpointNumber;\n                  }\n                  if (elementendpoint.direction==\"in\") {\n                    this.endpointIn_ =elementendpoint.endpointNumber;\n                  }\n                })\n              }\n            })\n          })\n        })\n        .then(() =&gt; this.device_.claimInterface(this.interfaceNumber_))\n        .then(() =&gt; this.device_.selectAlternateInterface(this.interfaceNumber_, 0))\n        // The vendor-specific interface provided by a device using this\n        // Arduino library is a copy of the normal Arduino USB CDC-ACM\n        // interface implementation and so reuses some requests defined by\n        // that specification. This request sets the DTR (data terminal\n        // ready) signal high to indicate to the device that the host is\n        // ready to send and receive data.\n        .then(() =&gt; this.device_.controlTransferOut({\n            'requestType': 'class',\n            'recipient': 'interface',\n            'request': 0x22,\n            'value': 0x01,\n            'index': this.interfaceNumber_}))\n        .then(() =&gt; {\n          readLoop();\n        });\n  };\n\n  serial.Port.prototype.disconnect = function() {\n    // This request sets the DTR (data terminal ready) signal low to\n    // indicate to the device that the host has disconnected.\n    return this.device_.controlTransferOut({\n            'requestType': 'class',\n            'recipient': 'interface',\n            'request': 0x22,\n            'value': 0x00,\n            'index': this.interfaceNumber_})\n        .then(() =&gt; this.device_.close());\n  };\n\n  serial.Port.prototype.send = function(data) {\n    return this.device_.transferOut(this.endpointOut_, data);\n  };\n})();\n</code></pre> <p>Images below show output and how it works:</p> <p></p> <p></p>"},{"location":"WebUSB_Findings/#software-creation-attempts","title":"Software Creation Attempts","text":"<p>This section tracks all attempts to get WebUSB working to integrate nicely with a webcam and an Arduino. </p>"},{"location":"WebUSB_Findings/#version-01-set-up-basic-web-interface-connect-communicate-with-arduino","title":"Version 0.1 \u2192 Set up basic web interface + Connect &amp; Communicate with Arduino","text":"<p>HTML code below: </p>V1.html<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;WebUSB Interface&lt;/title&gt;\n&lt;/head&gt;\n&lt;body style=\"background:#111;color:white;font-family:sans-serif;text-align:center;padding:2em\"&gt;\n  &lt;h1&gt;\ud83d\udd0c Connect to Arduino&lt;/h1&gt;\n  &lt;button id=\"connect\"&gt;Connect&lt;/button&gt;\n  &lt;div id=\"status\"&gt;Status: Not connected&lt;/div&gt;\n  &lt;br&gt;&lt;input id=\"command\" placeholder=\"Enter command (e.g. Scanning Mode)\" /&gt;\n  &lt;button onclick=\"sendCommand()\"&gt;Send&lt;/button&gt;\n  &lt;pre id=\"log\"&gt;&lt;/pre&gt;\n\n  &lt;script&gt;\n    let device;\n    const status = document.getElementById(\"status\");\n    const log = document.getElementById(\"log\");\n\n    document.getElementById(\"connect\").onclick = async () =&gt; {\n      try {\n        device = await navigator.usb.requestDevice({ filters: [{ vendorId: 0x2341 }] }); // update with your vendor ID\n        await device.open();\n        await device.selectConfiguration(1);\n        await device.claimInterface(2); // use correct interface #\n        status.innerText = \"Status: Connected\";\n        readLoop();\n      } catch (err) {\n        status.innerText = \"Status: Failed to connect\";\n        log.innerText += err + \"\\n\";\n      }\n    };\n\n    async function sendCommand() {\n      if (!device) return;\n      const cmd = document.getElementById(\"command\").value + \"\\n\";\n      const encoder = new TextEncoder();\n      await device.transferOut(4, encoder.encode(cmd)); // use correct endpoint\n    }\n\n    async function readLoop() {\n      while (device) {\n        const result = await device.transferIn(5, 64); // correct endpoint #\n        const decoder = new TextDecoder();\n        log.innerText += decoder.decode(result.data) + \"\\n\";\n      }\n    }\n  &lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Output Below: </p> <p></p> <p></p> <p>Ultimately, it didn't work out as well as expected, and all of it is most likely down to not having the Arduino set up properly to be able to recieve commands. It is able to recognize the Arduino, but the Arduino cannot recieve any of the messages that were sent. </p> <p>Putting aside everything related to connectivity, there are issues with getting the webcam to work on a basic web interface on html. This could mainly be because of the potential for security risks, and so browsers will tend to block access to the webcam. To emphasize, this is my belief based on my findings and testing. </p>"},{"location":"WebUSB_Findings/#version-02-build-webapp-hope-for-webcam-to-work","title":"Version 0.2 \u2192 Build Webapp + Hope for webcam to work","text":"<p>For this version, I created a virtual coding environment within VSCode and attempted to use Flask to set up a basic web interface and get the webcam and Arduino to talk to one another. </p> <p>Here is the python code:</p> appv2.py<pre><code>from flask import Flask, render_template, Response, request\nimport cv2\nfrom datetime import datetime\nimport threading\nimport time\nimport numpy as np\nfrom ultralytics import YOLO\nimport os\n\napp = Flask(__name__)\n\n# -------------------------\n# Config\n# -------------------------\nCAMERA_INDEX = 0\nLOG_FILE = \"log.txt\"\nMODEL_PATH = \"yolov8n.pt\"\n\n# -------------------------\n# State\n# -------------------------\ncap = cv2.VideoCapture(CAMERA_INDEX)\nmodel = YOLO(MODEL_PATH) if os.path.exists(MODEL_PATH) else None\ncurrent_mode = None\nlog_lock = threading.Lock()\ndetection_active = False\n\ndef log_message(message):\n    timestamp = datetime.now().strftime(\"[%H:%M:%S]\")\n    line = f\"{timestamp} {message}\\n\"\n    with log_lock:\n        with open(LOG_FILE, \"a\") as f:\n            f.write(line)\n\ndef gen_frames():\n    global detection_active\n    while True:\n        success, frame = cap.read()\n        if not success:\n            black_frame = (255 * np.zeros((480, 640, 3), dtype=np.uint8))\n            ret, buffer = cv2.imencode('.jpg', black_frame)\n            frame = buffer.tobytes()\n            yield (b'--frame\\r\\n'\n                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n            continue\n\n        if detection_active and model:\n            results = model(frame)[0]\n            frame = results.plot()\n\n            # Handle modes\n            for box in results.boxes:\n                cls_id = int(box.cls[0])\n                class_name = model.names[cls_id]\n\n                if current_mode == \"scan\":\n                    log_message(f\"MODE Scanning Detected: {class_name}\")\n                elif current_mode == \"sort\":\n                    log_message(f\"MODE Sorting Detected: {class_name}\")\n                    break\n\n        ret, buffer = cv2.imencode('.jpg', frame)\n        frame = buffer.tobytes()\n        yield (b'--frame\\r\\n'\n               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n\n@app.route(\"/upload_model\", methods=[\"POST\"])\ndef upload_model():\n    global model\n    file = request.files[\"model\"]\n    if file and file.filename.endswith(\".pt\"):\n        path = os.path.join(\"models\", file.filename)\n        file.save(path)\n        model = YOLO(path)\n        log(f\"\u2705 Model loaded: {file.filename}\")\n        return \"\u2705 Model loaded successfully\"\n    return \"\u274c Invalid model file\"\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n@app.route('/video_feed')\ndef video_feed():\n    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n\nmode = \"stop\"\n\n@app.route('/set_mode/&lt;new_mode&gt;')\ndef set_mode(new_mode):\n    global mode\n    mode = new_mode\n    return f\"Mode set to {new_mode}\"\n\nlog_data = []\n\n@app.route('/log')\ndef get_log():\n    return \"\\n\".join(log_data[-50:])  # Keep only recent 50 lines\n\ndef log(message):\n    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n    log_data.append(f\"[{timestamp}] {message}\")\n\nif __name__ == '__main__':\n    log_message(\"Flask Backend Started\")\n    app.run(host='0.0.0.0', port=5000, debug=True)\n</code></pre> <p></p> <p>Turns out the webcam doesn't really work here either... </p> <p>At this point, I have tried working with it and it ultimately did not work. At this point in the project timeline, I had made the decision to abandon the idea of programming a web interface and focus more on iterating through software that works and runs locally. Web development can be explored as an option, but is something I would consider to be \"out of scope\" for the project, but can be mentioned as a future improvements. </p>"},{"location":"WebUSB_Findings/#conclusion","title":"Conclusion","text":"<p>WebUSB is not ideal (from a simplicity point of view) due to the communication protocol that needs to be put in place. With any webpage, a client and server is needed. However, this communication would have to be extended to the Arduino as well. With a large amount of communication happening between the user, client, server, and Arduino, there is bound to be a loss of data somewhere due to data being sent and recieved from multiple sources, essentially overloading the system. While the ideal scenario would be to run something like this, my prototype will not be using a web-based system to reduce the complexity of communicating information.</p> <p>Click to go back to architecture page.</p>"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/#software-considerations","title":"Software Considerations","text":"<p>Early in the project timeline, the focus for any architectural decisions was heavily biased towards the software, as there are many possibilities for the software, and significantly fewer physical prototype solutions. </p>"},{"location":"architecture/#early-software-decisions","title":"Early Software Decisions","text":"<p>Given that the project solution requires a cyberphysical system, it is best to work with some kind of microcontroller. In addition, since laptops can vary with processing power, age, graphics performance, etc, it is best to utilize a solution that is lighter on a laptop. The goal here is to have as many devices as possible be able to run the software. </p> <p>This is where the first major pathway to a solution arrives: using WebUSB. WebUSB is an API that allows certain compatible microcontrollers to be able to communicate to a web browser. This would open up the potential for users to be able to interact with the Arduino using an HTML file. Keeping this solution on a web browser would be able to allow the system to run much lighter.</p> <p>Such a solution can be seen with Google's Tiny Sorter, which is primarily used as a teaching tool to help people learn about computer vision and sorting. One of the main drawbacks about this solution is that it doesn't accomodate for a variety of object types, and would be difficult to sort larger and heavier objects. It also does not allow a user to input a pretrained model, and instead relies on the end user to train the system. If done improperly, or in bad lighting, then the model produced is not as accurate.</p> <p>This led me down a rabbit hole of using WebUSB and getting my hands on an Arduino Leonardo, which is a WebUSB-compatible Arduino. My findings about WebUSB are laid out in more detail here. Note that this page can also be found by navigating via the development section, so you can view it then as well.</p> <p>Long story short, WebUSB is not ideal (from a simplicity point of view) due to the communication protocol that needs to be put in place. With any webpage, a client and server is needed. However, this communication would have to be extended to the Arduino as well. With a large amount of communication happening between the user, client, server, and Arduino, there is bound to be a loss of data somewhere due to data being sent and recieved from multiple sources, essentially overloading the system. While the ideal scenario would be to run something like this, my prototype will not be using a web-based system to reduce the complexity of communicating information. </p>"},{"location":"architecture/#final-software-decisions","title":"Final Software Decisions","text":"<p>Based on the information outlined above, I have chosen to run the program locally. A graphical user interface (GUI) will be built via Python, which will also handle communication to and from the Arduino via a serial communication port. </p> <p>The GUI will allow the user to dictate what gets done and when as well as monitor the whole system and provide that information to the user. A GUI can be constructed in many ways, however, I have chosen to use tkinter for Python. </p> <p>Communication to and from the Arduino via a serial communication port is a good option as it allows data to be sent to and from using one channel, whereas using WebUSB would mean data has to transfer from client to server to Arduino. </p> <p>More technical details can be seen on the development pages, where the software versions are outlined as I iterate through them towards a working solution. </p>"},{"location":"architecture/#prototype-considerations","title":"Prototype Considerations","text":""},{"location":"architecture/#early-prototype-decisions","title":"Early Prototype Decisions","text":"<p>Early on, the choice had to be made to decide whether to design a prototype that works well with one kind of object or womething that won't work as well but can support a varierty of objects. </p> <p>Initially, I thought about going with the former. Coins are something that a lot of people have at their homes, including myself, and I thought testing using that would be great. I had initially wanted to design a system that works really well with coins, but coins only. However, it is more ideal to use a system that can support a variety of objects, even at reduced ability and capacity, as it allows for a proper proof of concept to be established with a relatively universal solution.</p> <p>There are more things that need to be figured out before designing any prototype:</p> <ul> <li>How are objects fed into system?</li> <li>What happens if the user cannot feed objects one-by-one? How does the system handle this?</li> <li>How can the system detect the objects in a webcam? Should a box be built around the webcam and an LED to illuminate it or is there another solution?</li> <li>What mode of movement should objects use when sending an object to the webcam and from the webcam to the bin?</li> <li>etc...</li> </ul>"},{"location":"architecture/#final-prototype-decisions","title":"Final Prototype Decisions","text":"<p>Here are some answers to some of the questions I posed above:</p> <ul> <li>How are objects fed into system? \u2192 They can be fed one by one or ideally, through some kind of feeder, either vibration based or centrifugal.</li> <li>What happens if the user cannot feed objects one-by-one? How does the system handle this? \u2192 Using something like a feeder can allow objects to be fed more uniformly, regardless of how the user would load the objects.</li> <li>How can the system detect the objects in a webcam? Should a box be built around the webcam and an LED to illuminate it or is there another solution? \u2192 Two options can be considered: 1. creating a custom enclosure around the webcam with a light that will hopefully detect objects, or 2. using a mirror to angle the view of the webcam downward and create a 3D printed conveyor belt. </li> <li>What mode of movement should objects use when sending an object to the webcam and from the webcam to the bin? \u2192 Two options can be considered: 1. Using a relatively universal rail that could transfer objects via a rail 2. perhaps this can be done with a 3D printed conveyor belt, with bins being put on the side of the conveyor belt for easy object sorting via motors or something built into the belt itself.</li> </ul> <p>Update (Nov 2025):</p> <ul> <li>Note that I answered the questions with what concepts I had in mind at that time, which did not line up 100% with the concept that I ended up going with. The questions and answers were more posed to generate thinking on my side. The answers to the questions were nonbinding at the time, and ended up differing from what the final prototype looked like.</li> </ul>"},{"location":"dev_roadmap/","title":"Relative Timeline","text":""},{"location":"dev_roadmap/#relative-development-timeline","title":"Relative Development Timeline","text":"<p>This timeline shows the relative development timeline of the two most important aspects of the project: software and physical prototype. The goal here is to emphasize that this is a parallel process rather than working on developing software fully first then the physical prototype. Click on each card to go to the page with more information about that specific version along the development path.</p> Software Physical Prototype Beginning of Development (June 2025) Version 0 <p>Attempted to build a web app and communicate information between app and Arduino via WebUSB. Got basic communication to work, but ended up having issues getting webcam to work.</p> Version 1 <p>Switched to Python App and programmed a graphical user interface (GUI) using tkinter to allow user to perform basic functions. Basic features included, but not all requirements met as outlined in Milestone 3.</p> Version 1 <p>Attempted to implement a vibration bowl feeder, and went through two design iterations before shelving the idea due to increased overall complexity for a part of the project that was mostly insignificant.</p> Version 2 <p>Refined Python App for more modern look by opting to use customtkinter and fully implemented sorting franework. Minimum viable software achieved at this stage.</p> Version 2 <p>Changed development path and prototyped a standalone device with an external USB webcam and a servo-controlled platform to sort objects into bins.</p> Version 3 <p>Further refined version of software, focused on user experience, interface, and control. Implemented an even more modern appearance and focused on simplifying controls to make it more intuitive for end user.</p> End of Development / Final Integration (November 2025)"},{"location":"final_testing/","title":"Testing","text":""},{"location":"final_testing/#testing-overview","title":"Testing Overview","text":"<p>After concluding development of the full cyber physical prototype, testing must be carried out to ensure that it meets the goals that it was intended to, or at least reasonably show that it can do so with further refinement.</p> <p>One important thing to note here is that the object sorter prototype is NOT optimized for speed. It was tuned entirely with accuracy in mind. With further tuning and refinement, some time can be saved. Areas of refinement include: speeding up the servo, reducing the cooldown, better model training, etc. I will not consider these future improvements as these are more refinements that can be done to enhance and optimize what is already there.</p>"},{"location":"final_testing/#test-setup-and-scenario","title":"Test Setup and Scenario","text":"<p>I took some assorted coins I had at home and mixed them up. This pile comprises of pennies, dimes, and quarters. My goal is to be able to use the model trained to be able to sort through this pile.</p> <p>Throughout the testing I want to answer the following questions:</p> <ul> <li>How does the prototype compare to a human (myself) when both are binary sorting?</li> <li>How does the prototype compare to a human (myself) when the human sorts without limitations?</li> </ul>"},{"location":"final_testing/#testing-methodology","title":"Testing Methodology","text":"<p>Below is a list of rules and/or notes regarding the testing methodology:</p> <ul> <li>Repeatability is required on the most tests to use averages as a baseline rather than relying just on a human being consistent (as humans are consistently inconsistent).</li> <li>In general, I will be working at a moderate pace, not too slowly or quickly.</li> <li>When I am binary sorting, I will have all objects in a pile, and pull from them one at a time without looking at what I am grabbing from the pile. If the object I select matches what I am looking for, it goes in one pile, and if it does not, it goes into a 'discard' pile. Once the pass has been completed, the discard pile is poured to where the original pile was, and the process is repeated until all objects have been sorted. After sorting, then the objects are counted, written down, and added together to calculate statistics (minus throughput).</li> <li>Tests carried out that do not limit the human (myself) will only be ran once to get a picture of the differences rather than averaged. In other words, all non-binary testing done by me will be conducted once to illustrate an obvious and expected difference rather than try to gather any meaningful data.</li> <li>When using the prototype, any time spent between passes counts as part of passing, so it is important to ensure that the end user doesn't waste too much time during these downtimes.</li> </ul>"},{"location":"final_testing/#testing-plan","title":"Testing Plan","text":"<p>A pile of coins was chosen to be the test pile. It is the same pile used across all tests (including manual and prototype testing). The pile consists of 15 Quarters, 15 Pennies, 26 Dimes, which yields a total of 56 objects sorted.</p> <ol> <li>Human Sorting in Binary Fashion:<ul> <li>HSB-1: QUARTER-PENNY-DIME</li> <li>HSB-2: DIME-QUARTER-PENNY</li> <li>HSB-3: PENNY-DIME-QUARTER</li> <li>HSB-A: Average of above 3 trials</li> </ul> </li> <li>Human Sorting (No Binary):<ul> <li>HSNB-1: Allowed to take one object at a time from big pile, but able to categorize into smaller sorted piles</li> <li>HSNB-2: Allowed to see full pile and sort into smaller sorted piles</li> </ul> </li> <li>Prototype Sorting:<ul> <li>PS-1</li> <li>PS-2: Recorded on Video (shown below)</li> <li>PS-3: Used supplemental lighting to address any concerns about lighting</li> <li>PS-A: Average of above 3 trials</li> </ul> </li> </ol> <p>Bonus Test: How long does it take to filter out the pennies from the whole pile?</p> <ol> <li>Prototype (PF-1)</li> <li>Manual (HF-1): Must pull from pile one at a time without looking, determine whether object selected is a penny, then act accordingly</li> <li>Manual (HF-2): Pour entire pile out, then filter out all pennies and everything else</li> </ol>"},{"location":"final_testing/#benchmarks","title":"Benchmarks","text":"<ul> <li>90% accuracy between actual objects and amount counted (through whichever sorting process was used)</li> <li>Object sorter must be faster than the times that a human (myself) sorting in a binary fashion</li> </ul>"},{"location":"final_testing/#video","title":"Video","text":""},{"location":"final_testing/#results","title":"Results","text":""},{"location":"final_testing/#speed-comparison","title":"Speed Comparison","text":"Test ID Time (MM:SS) Throughput (objects/min) HSB-1 05:36 10.00 HSB-2 05:18 10.56 HSB-3 05:29 10.21 HSB-A 05:28 10.24 HSNB-1 02:41 20.87 HSNB-2 1:41 33.27 PS-1 05:01 11.16 PS-2 04:26 12.63 PS-3 04:18 13.02 PS-A 04:35 12.22 <p>Findings:</p> <ul> <li>Human sorting in a non-binary fashion is BY FAR faster than anything done in a binary fashion.</li> <li>Binary sorting done by a human or by the prototype is comparable to one another, and overall, the prototype was about 16% quicker on average. Using HSB-A as a baseline, the prototype was capable of being around 21.3% quicker.</li> <li>There is potential to make the prototype faster, especially trimming down the time the servo rotates to either bin and back to the neutral position, however, it is best to minimize risk and ensure it works.</li> </ul>"},{"location":"final_testing/#yolo-accuracy-per-trial","title":"YOLO Accuracy Per Trial","text":"Test ID Pennies Detected Dimes Detected Quarters Detected Type of Error (ACTUAL OBJECT \u2192 DETECTED OBJECT) Number of Errors Accuracy PS-1 13/15 26/26 17/15 Penny \u2192 Dime, Penny \u2192 Quarter, Dime \u2192 Quarter 3 94.6% PS-2 14/15 22/26 20/15 Penny \u2192 Quarter, Dime \u2192 Quarter (x4) 5 91.1% PS-3 16/15 27/26 13/15 Quarter \u2192 Dime, Quarter \u2192 Penny, Dime \u2192 Quarter 3 94.6% <p>Findings:</p> <ul> <li>Pennies and Dimes are fairly strong, with quarters being the weak point</li> <li>Detection of quarters led to the most mistakes</li> <li>Lighting makes a noticable difference, but overall did not impact the results in the end. On one trial the errors were close to zero but I had to abandon that due to issues with the Arduino.</li> <li>Slight overcounting occured in Trial HSB-2, which is as a result of the object getting 'stuck' on the platform due to geometric limitations seen with FDM 3D Printing</li> </ul>"},{"location":"final_testing/#penny-extraction-test","title":"Penny Extraction Test","text":"Test ID Time (MM:SS) Throughput (objects/min) Notes PF-1 02:15 24.44 Prototype was 100% accurate in separating pennies HF-1 02:23 23.07 Slower than the prototype HF-2 00:43 76.74 Humans benefit from global view, but really only applies in situations when global view CAN be utilized (e.g. seeing 1000 resistors for sorting would be tricky)"},{"location":"final_testing/#remarks","title":"Remarks","text":"<p>Overall, the prototype was markedly faster in binary sorting situations compared against myself. However, humans have the benefit of a global view, which is something that isn't really possible with a YOLO Model. The overarching concept of a binary sorter inherently limited the scope of improvement by quite a bit. </p> <p>The speed of the object sorter can be improved in 2 main ways:</p> <ol> <li>Improve the model being used. This could also entail swapping the version of YOLO used or trying out a different line of model all together.</li> <li>Reduce the time spent waiting for the object to fall off the platform. If even 0.5 seconds can be saved here, across 50 objects, that would be a full 25 seconds saved, which can be seen as valuable time in a fast-paced environment.</li> </ol>"},{"location":"integration/","title":"Integration Overview","text":"<p>As with any cyber physical system, the integration between the software and hardware used is very crucial. Most of the integration took place in parallel with the development, as the Arduino was a key part of the software development. This section will focus on the bridge between the software and the hardware, which is the YOLO model itself.</p> <p>Technically speaking, there are a few items which can be seen as connecting a physical device to the software. The serial communication protocol and the USB cable are just two such examples. However, the item that makes or breaks how well this entire system works is the YOLO model.</p> <p>I initially thought that the system was 'plug and play', however, that could not be further from the truth, which is why I have a dedicated page on training models for this system. Note that it has some general training information for all YOLO models, but it is written with this project in mind.</p> <p>Another page is dedicated to troubleshooting. If one chooses to replicate this project and faces issues, refer to the troubleshooting guide to work through some of the issues. Note that all issues may not be encompassed as I was the main end user of this prototype, so I could not replicate all issues.</p>"},{"location":"intro/","title":"Introduction and Motivation","text":"<p>When a bullet is fired at a crime scene it leaves behind a casing and the bullet itself. The bullet size varies depending on the gun that is being used, but each bullet contains a unique identification that can be traced back to a specific gun that it was fired with. There is currently a relatively outdated process in place, whereby an examiner will have to manually measure and identify markings. While more advanced versions of this technique can be used (standards determined by NIST), it still heavily relies on an examiner going through. While human input can be deemed necessary, it is an inefficient process that can be streamlined if the bullets were able to be somehow pre-sorted. This would save time and make the process more efficient. </p> <p>Designing a new device would also require engineers to justify the need for such a product, and also delve into how it can be used in other applications. There are similar existing problems in other applications. An example of such an application would be coin sorting. If there were 1000 assorted coins of differing currencies, it would be possible to sort by hand albeit through a lengthy procedure. Another example is in an agricultural setting, where one would have to maybe sort through 2-3 different types of beans efficiently. Other examples include but are not limited to: various assorted electrical components (resistors, op-amps, capacitors, etc), assorted LEGOs, and assorted perler beads. </p> <p>An ideal device would be able to use an image of the product, identify what it is, and sort it based on the context of what would be coming into the device. This type of device can be designed using machine learning (ML), which is trained using images of a certain category. Note that this is a simplified version of the pipeline, and a more detailed pipeline will be ironed out in later phases of the design and prototyping process. There are various pros and cons to using ML in such an application, with the biggest pro being the ability to make an inefficient process more efficient and the biggest con being that the ability of the device functioning properly depends entirely on how well the ML implementation is done. </p> <p>To my knowledge, there is not such a device in the market, but there are aspects of the solution that are working in the market, and serve as a proof of concept. The first of these are a series of apps that are able to use the image of a coin to be able to give relevant information to the user. An example of such an app is \u201cCoinSnap\u201d, which allows users to scan coins and be provided with information and facts about that specific coin. This idea can be extended to similar apps on a smartphone for different purposes, such as identifying stars in the night sky or even forms of wildlife. </p> <p>A second working proof of concept serves as a working example of such a device. A company called Bulher has created a sorting device that can sort things such as agricultural seeds, coffee beans, etc in their \u201cSORTEX\u201d lineup. The device uses an optical sensor to be able to sort out a sample given the respective categories. </p> <p>But what if there was a solution that was more modular, something that could plug into a laptop and leverage its webcam to be able to physically sort through objects, not just identify them?</p> <p>References:</p> <p>Market Research:</p> <ul> <li> <p>Want to \u201cchange\u201d your fortune? Coin apps might help \u2192 Apps that take image of coins and are able to figure out its value</p> </li> <li> <p>GitHub - thim0o/CoinDetector \u2192 An image based coin counter using Python and Tensorflow Coin Detector on GitHub</p> </li> <li> <p>Optical Sorting Machines \u2192 Working Concept within Agriculture</p> </li> </ul> <p>Publications:</p> <ul> <li>Cell.com |  Intelligent Image-Activated Cell Sorting</li> <li>Nanocellect | Image-guided cell sorting technical overview</li> </ul>"},{"location":"milestones/","title":"Milestones","text":""},{"location":"milestones/#milestones","title":"Milestones","text":"<p>This page will contain a bit of information about each milestone as shown on the main page, including some of the goals of each, and if applicable, anything I have done to ensure that the milestone will be marked as \"complete\". For example, for testing, this page will contain information about any initially planned test runs, but will not cover the results. For more details descriptions of the architecture, design, testing, etc, view those respective pages in the navigation. </p>"},{"location":"milestones/#1-refresh-programming-knowledge","title":"1. Refresh Programming Knowledge","text":"<p>Based on my personal experiences, this phase of the project was more of a refresher for me. However, someone with less background with coding, in my opinion, should go through some coding lessons online and/or take a class. </p> <p>Prior to starting this project, I had used the following:</p> <ul> <li>Java</li> <li>MATLAB</li> <li>Python</li> <li>Arduino IDE</li> </ul> <p>Java was the first programming language I had learned, and I had done so in a more formal way by taking a course during my second semester of my undergrad. This class taught me the basics of Object Oriented Programming, and I was tasked with a variety of assignments with each one getting more complicated. I had learned the basics of everything from writing my first program to loops to client and server code. In addition, I had to work through a project at the end of the semester, where I worked with a team to code a basic learning interface similar to Canvas and Brightspace. </p> <p>I next learned MATLAB, which I used to complete the bulk of my engineering assignments during the first year engineering (FYE) curriculum that Purdue has in place. </p> <p>From there, I learned Python, also by taking a class at Purdue (EBEC 101). Here, I used Python in a traditional sense, by completing relatively simple assignments that taught me the basics of coding, but instead entirely in Python. </p> <p>After that, I learned how to program Arduinos using the Arduino IDE, albeit in a more nontraditional sense where I was introduced to everything in a more practical sense, and have since fine tuned my abilities through project-based learning. </p> <p>That being said, I had a decent background when it came to coding, so a few lessons in Python from YouTube were enough to get me going again and ready to learn more.</p> <p>For someone looking to replicate this, I would strongly suggest learning Python, as that is the programming language that is used throughout this project, as well as learning the basics behind working with Arduinos and familiarity with the IDE. I will also be using PlatformIO to run my project entirely in VSCode instead of using two different IDEs.</p>"},{"location":"milestones/#2-understand-basics-of-machine-learning","title":"2. Understand Basics of Machine Learning","text":"<p>Prior to starting this project, I had zero experience with Machine Learning. This is what I did to familiarize myself with the basics of ML. I ended up taking free online classes to refresh my Python knowledge and expand that understanding into machine learning. Links to the classes are below, with certificates on my LinkedIn page.</p> <ul> <li>Machine Learning with Python course | Cognitive Class</li> <li>Data Visualization with Python course | Cognitive Class</li> <li>Python for Data Science course | Cognitive Class</li> <li>Predictions: Regression for Car Mileage and Diamond Price</li> <li>Customer Clustering with KMeans to Boost Business Strategy</li> <li>Precise Predictions: Classification for Flower and Tumors</li> </ul> <p>While this is not by any means a guide to learning machine learning, the emphasis for this project was to familiarize myself with it and get better at implementing it as I progress through this project. </p>"},{"location":"milestones/#3-develop-basic-software","title":"3. Develop Basic Software","text":"<p>Developing basic software entails having code up and running for the software side of this project, which entails mainly getting YOLO working as well as setting up the interface and all basic functions that need to be in place for this to be successful. At the minimum, here is what is expected:</p> <ul> <li>Be intuitive to use, and look somewhat polished</li> <li>Allow user to perform basic functions</li> <li>Allow user control over the process</li> <li>At the minimum, recognize when an Arduino is connected via USB to laptop</li> <li>Leverage webcam to detect objects</li> <li>Have some error handling in place and prevent user from going too far out of order</li> </ul>"},{"location":"milestones/#4-3d-model-and-design-physical-product","title":"4. 3D Model and Design Physical Product","text":"<p>The goal here is to design a minimum viable prototype, where the parts and system is able to work adequately well and a well established proof of concept is present. At the minimum, here is what is expected:</p> <ul> <li>Be simple to use for the end user</li> <li>Allow user to perform basic functions, notably loading and sorting objects under supervision with minimal human intervention</li> <li>Allow user to load a small to medium number of items for sorting, mainly for testing purposes</li> <li>Objects should get sorted into 2 bins, where one is the target and the other is not the target, hence the \"binary\" aspect of the sorter</li> <li>Keep costs as low as possible, with the aim to be reproducible</li> </ul>"},{"location":"milestones/#5-integrate-software-and-hardware","title":"5. Integrate Software and Hardware","text":"<p>Once basic software and working prototype are set up, work needs to be done to integrate the software and prototype made earlier. Here, the different modes will be properly established:</p> <ul> <li>Object Detection Mode: Here, objects will pass through the mechanical system in place and not do any kind of sorting. The goal is to detect a list of unique objects so that the number of passes the system requires can be established.</li> <li>Object Sorting Mode: Here, objects will be sorted through the system, with motors/actuators being used to facilitate the sorting process.</li> </ul> <p>At this point, small scale testing will be carried out. The aim here is to get around 10-20 objects with at least 3 unique classes of objects properly sorted. </p>"},{"location":"milestones/#6-final-testing","title":"6. Final Testing","text":"<p>At this point, the system is well established, and the testing can be slightly scaled up. In addition, different models will be tested to ensure that the system is more \"plug and play\", where the end user will be able to train or load in a pytorch model to be used with YOLO.</p>"},{"location":"milestones/#7-reflection-and-next-steps","title":"7. Reflection and Next Steps","text":"<p>Reflections will be made here to discuss flaws of working prototype as well as a path forward should the project timeline be extended.</p>"},{"location":"progress/","title":"Project Progress","text":""},{"location":"progress/#project-progress","title":"Project Progress","text":"Refresh Programming Knowledge Understand Basics of Machine Learning Develop Basic Software 3D Model and Design Physical Product Integrate Software and Hardware Final Testing Reflection and Next Steps"},{"location":"prototype_development/","title":"Prototype Development Overview","text":"<p>This page provides a little introduction to what is required by the prototype and how I aim to solve those requirements. </p>"},{"location":"prototype_development/#requirements","title":"Requirements","text":"<p>First off, here is a list of basic requirements:</p> <ul> <li>Prototype must allow user to be able to load objects with relative ease, without having to worry too much about the orientation and the type of object loaded.</li> <li>Prototype must be able to work with, or show potential to work with, a variety of objects with differing geometry, weight, size, etc.</li> <li>Prototype must allow objects to be visible from the webcam and allow the YOLO software to be able to detect and sort objects.</li> <li>Prototype must accomodate a \"target\" and \"other\" bin, to allow for binary sorting.</li> <li>Prototype must allow all electronics to be easily accessible to user to allow for debugging and/or allow for any required work to be performed (rewiring, reconnecting, etc) while also not interfering with the sorting process.</li> <li>Prototype must contain a manual override to allow for human intervention in case of failure or unexpected errors.</li> <li>Prototype must be able to sort, or show potential to sort, with relative high accuracy.</li> </ul> <p>The list above details all basic requirements, however it leaves out a few desireable features, which would be implemented if the project timeline were to be extended. Ideally, the prototype will also contain:</p> <ul> <li>Error Handling \u2192 System should have a way of knowing when something has gone wrong and attempt a correction.</li> <li>Scalability \u2192 System should be \"plug and play\", where there would not be much work to scale this up to whatever application it is required for.</li> </ul>"},{"location":"prototype_development/#final-prototype-solution-ver-2x-93025","title":"Final Prototype Solution (Ver 2.X -- 9/30/25)","text":"<p>After speaking with my project mentor, we came to the conclusion that the solution decided on in Version 1.X (Vibration Bowl Feeder + Conveyor Belt) is not ideal for the scope of the project. Pursuing that route would add a lot of complexities with regards to the object feeding, which is not super in line with the scope of the project. While an automated system to feed objects pretty much effortlessly is a solid idea, it is indeed out of scope. </p> <p>The main focus of the project is on object detection and using various models to be able to detect and sort objects. That being said, object feeding will be done manually and is not a part of the project I will be designing too much.</p> <p>Here is the path forward with regards to the prototype: </p> <ol> <li>Use an external webcam to allow for greater flexibility. </li> <li>Create a standalone device that is not attached to the computer in any way (minus any external webcam connections via USB), so that any changes in laptop size and type can be negated and produce something more universal.</li> </ol> <p>I am providing a brief concept sketch below to detail what the standalone device might look like: </p> <p></p> <p>Below I am doing a requirements check on the object feeding and object transportation, comparing the idea of a standalone device against the selected solutions from Version 1.X. </p>"},{"location":"prototype_development/#object-feeding","title":"Object Feeding","text":"<p>What is being compared?</p> <ul> <li>Vibration Bowl Feeder</li> <li>Manual feeding into standalone device</li> </ul> Requirement Vibration Bowl Feeder Manual Feeding Notes / Explanation Easy loading of objects without worrying about orientation or type \u2714\ufe0f Meets \u2714\ufe0f Meets Vibration Bowl Feeders can feedmore consistently and reliably (IF designed correctly); Manual Feeding is simpler and orientation can be controlled by user Works with a variety of object sizes, weights, and shapes \u26a0\ufe0f Partially meets \u2714\ufe0f Meets Viration Bowl Feeder is limited by the bowl geometry, but manual feeding can work with objects of any geometry (as long as the chute/ramp to feed is large enough) Allows objects to be visible for YOLO detection \u2796 No effect \u2796 No effect Object visibility depends on camera setup, independent of method of feeding Accommodates \u201ctarget\u201d and \u201cother\u201d sorting bins \u2796 No effect \u2796 No effect Sorting bins are outside the feeder design Electronics easily accessible for debugging \u2796 No effect \u2796 No effect Electronics housing will be designed separately Manual override for human intervention \u2796 No effect \u2796 No effect Manual override controlled elsewhere, not part of feeder High accuracy sorting capability \u2796 No effect \u2796 No effect Sorting accuracy depends on YOLO models <p>Even from the table above, the manual feeding is simpler due to less complexity with mechanical components, and more importantly, vibrations. Designing for vibrations is inherently difficult, and even if the feeder was designed and could feed objects up, there will always be a type of object ill-suited to be fed down to either geometry or object's natural frequency. </p>"},{"location":"prototype_development/#transporting-objects-for-detection-and-sorting","title":"Transporting Objects for Detection and Sorting","text":"<p>While a comparison can be drawn for the transportation of objects, something of note is that there are two totally different ideas in play. </p> <p>Version 1.X had the idea of taking objects and having be fed out and moved into view, however, as specified in the concept sketch for Version 2.X, objects will be fed by means of a gravity hopper or manual feeding directly into the view of the object. This induces much less mechanical complexity as a whole and thus there is a very clear, straightforward, and obvious path forward. </p>"},{"location":"prototype_development/#comparison-of-overall-concepts","title":"Comparison of Overall Concepts","text":"<p>Below is a brief description of both concepts. Note that it includes the object's point of view as it travels to the bins.</p> <ul> <li>Version 1.X: Vibration Bowl Feeder \u2192 3D Printed Conveyor Belt \u2192 Webcam's FOV (viewable by using mirror to reorient FOV) \u2192 Bins</li> <li>Version 2.X: Manual Feeding (via hopper/ramp/chute) \u2192 Platform (within Webcam's FOV) \u2192 Bins</li> </ul> <p>I will do two comparisons, one against the requirements as a whole and one that details prototype feasibilty relative to one another.</p> Requirement Version 1.X Version 2.X Notes / Explanation Easy loading of objects without worrying about orientation or type \u2714\ufe0f Meets, but with correct, finely tuned design \u2714\ufe0f Meets, but more user effort Works with a variety of object sizes, weights, and shapes \u26a0\ufe0f Partially meets \u2714\ufe0f Meets Version 1.X is limited by bowl geometry, while Version 2.X can work with a greater variety of objects Allows objects to be visible for YOLO detection \u2714\ufe0f Meets \u2714\ufe0f Meets Both concepts leverage a camera to be able to view and detect objects Accommodates \u201ctarget\u201d and \u201cother\u201d sorting bins \u2714\ufe0f Meets \u2714\ufe0f Meets Both accomodate bins to be able to sort objects Electronics easily accessible for debugging \u2714\ufe0f Meets \u2714\ufe0f Meets Electronics will be housed separately in both cases, but can be made easily accessible Manual override for human intervention \u2714\ufe0f Meets \u2714\ufe0f Meets Manual override can be built in High accuracy sorting capability \u2714\ufe0f Meets \u2714\ufe0f Meets Sorting accuracy depends on YOLO models, which is able to be leveraged in both cases Prototype Feasibility Requirement Version 1.X Version 2.X Notes / Explanation Relative Mechanical Complexity \ud83d\udd34 More complex \ud83d\udfe2 Less complex Relative Electrical Complexity \ud83d\udd34 More complex \ud83d\udfe2 Less complex Version 1.X will need a vibration motor and a DC motor to move the belt, Version 2.X will need a servo motor to control the platform Relative Costs \ud83d\udd34 More \ud83d\udfe2 Less Both will cost a similar amount to put together, which includes costs of making and sourcing components Prototype-able? \ud83d\udd34 Less prototype-able \ud83d\udfe2 More prototype-able Both concepts can be 3D printed and integrated, but Version 1.X requires more components that have to be carefully designed with vibrations in mind Reproducible? \ud83d\udd34 Not really \ud83d\udfe2 Yes, easily Reasoning due to ability to prototype Scalable \ud83d\udd34 Less scalable \ud83d\udfe2 More scalable Version 2.X is simpler, and will be easier to assemble and modify for larger sized objects"},{"location":"prototype_development/#considered-solutions-ver-1x-82625","title":"Considered Solutions (Ver 1.X -- 8/26/25)","text":"<p>NOTE: This is an older version of the prototype that is not being considered after 8/26/25. I have retained the information below for documentation and reference purposes.</p> <p>Based on the list of basic requirements above, here are solutions being considered for the broader aspects of the prototype.</p>"},{"location":"prototype_development/#object-feeding_1","title":"Object Feeding","text":"<p>What is being considered?</p> <ul> <li>Vibration Bowl Feeder</li> <li>Centrifugal Feeder</li> </ul> Requirement Vibration Bowl Feeder Centrifugal Feeder Notes / Explanation Easy loading of objects without worrying about orientation or type \u2714\ufe0f Meets \u2714\ufe0f Meets Vibration Bowl Feeders feed slower, but are more reliable; Centrifugal will require a stronger motor or a high torque gear train, is simpler, but is less universal Works with a variety of object sizes, weights, and shapes \u26a0\ufe0f Partially meets \u26a0\ufe0f Partially meets Both concepts are limited by bowl geometry to an extent, but not heavily affected by it for prototype purposes Allows objects to be visible for YOLO detection \u2796 No effect \u2796 No effect Object visibility depends on camera setup, independent of feeder Accommodates \u201ctarget\u201d and \u201cother\u201d sorting bins \u2796 No effect \u2796 No effect Sorting bins are outside the feeder design Electronics easily accessible for debugging \u2796 No effect \u2796 No effect Electronics housing will be designed separately Manual override for human intervention \u2796 No effect \u2796 No effect Manual override controlled elsewhere, not part of feeder High accuracy sorting capability \u2796 No effect \u2796 No effect Sorting accuracy depends on YOLO models <p>When comparing both solutions on paper, there is no obvious standout choice to start with, I will also do a quick comparison below to highlight a path forward.</p> Prototype Feasibility Requirement Vibration Bowl Feeder Centrifugal Feeder Notes / Explanation Relative Mechanical Complexity \ud83d\udfe2 Less complex \ud83d\udd34 More complex Vibration Bowl Feeder will have less mechanical components to work with; Centrigufal Feeder will have more mechanical components to work with and has to be designed more carefully Relative Electrical Complexity \ud83d\udd34 Slightly more complex \ud83d\udfe2 Slightly less complex Vibration Bowl Feeders will need extra tuning and sourcing of electrical components; Centrifugal Bowl Feeders will require less elctrical components and thus less complexity Relative Costs \u26aa Similar \u26aa Similar Both will cost a similar amount to put together, which includes costs of making and sourcing components Prototype-able? \u26aa Similar \u26aa Similar Both concepts can be 3D printed Reproducible? \ud83d\udfe2 Slightly More \ud83d\udd34 Slightly Less Vibration Bowl Feeders have less parts to put together, which reduces chances of parts not fitting together after 3D printing Scalable \u26aa Similar \u26aa Similar Both concepts can be adapted and scaled in a post-project timeline to fit the needs required through changing out any components that were sourced and altering dimensions in CAD <p>Both are pretty equal in terms of viablility, but the vibration bowl feeder is slightly less complex overall and has the potential to be more reproducible to other people. Therefore, I will stick to making a vibration bowl feeder for now.</p>"},{"location":"prototype_development/#transporting-objects-for-detection-and-sorting_1","title":"Transporting Objects for Detection and Sorting","text":"<p>This section deals with solutions being considered to handle moving the objects being sorted from the feeding mechanism to the webcam'e field of view and then to the bins. </p> <p>What is being considered?</p> <ul> <li>Option 1: System of Linear Tracks \u2192 Webcam's FOV (via a enclosure) \u2192 Bins</li> <li>Option 2: 3D Printed Conveyor Belt \u2192 Webcam's FOV (viewable by using mirror to reorient FOV) \u2192 Bins</li> </ul> Requirement Option 1 Option 2 Notes / Explanation Easy loading of objects without worrying about orientation or type \u26a0\ufe0f Potential negative \u2714\ufe0f Meets I will focus on loading in the context of going to webcam FOV and then to bins; Option 1 has to be designed carefully to accomodate a vast amount of objects; Option 2 is more universal and doesn't deoend on orientation or type Works with a variety of object sizes, weights, and shapes \u26a0\ufe0f Potential Negative \u2714\ufe0f Meets Option 1 is limited in terms of track geometry; Option 2 more universal Allows objects to be visible for YOLO detection \u26a0\ufe0f Potential Negative \u2714\ufe0f Meets Option 1's enclosure has to designed to either allow in natural ambient light or be well-lit; Option 2 uses ambient lighting, which works reasonably well Accommodates \u201ctarget\u201d and \u201cother\u201d sorting bins \u2714\ufe0f Meets \u2714\ufe0f Meets Sorting bins can be integrated into both solutions Electronics easily accessible for debugging \u2796 No effect \u2796 No effect Electronics housing will be designed separately Manual override for human intervention \u2796 No effect \u2796 No effect Manual override controlled elsewhere, not part transportation sub-system High accuracy sorting capability \u2796 No effect \u2796 No effect Sorting accuracy depends on YOLO models <p>Based on requirements alone, there is a clear path forward. At worst, a conveyor belt will be able to provide more proof of concept than the linear track system, and at best, it will be a sub-system that is more universal. No feasibility study will be conducted unless something goes wrong with the conveyor belt concept.</p>"},{"location":"prototype_v2/","title":"Version 2 (Final Prototype)","text":"<p>The focus for this page will be new concept path that I am going down. As a reminder, below is the concept image I had drafted when decided to go down this path of development (Note that this is the same one that appears on the Prototype Development Main Page): </p> <p></p> <p>Note that there are a few changes from the concept image to the prototype:</p> <ol> <li> <p>No inclusion of a gravity hopper: As mentioned a few times across the documentation, object feeding can be considered more of a feature that is nice to have, rather than a requirement for the prototype. In addition, developing a system to feed any kind of objects that have the same relative volume is something more challenging than initially expected. Thus, it makes the most sense to focus on the object detection and sorting more than the feeding into the system, as objects can be manually fed.</p> </li> <li> <p>LCD Screen is included: Above, an LCD screen was listed as an optional feature, however, I have decided to include it on the design. One thing to note is that the LCD working is considered lower priority as it is not important to have that working for the prototype to work.</p> </li> <li> <p>Camera Orientation: On the concept image, the camera orientation is mounted such that objects would fall into view from up to down and along gravity and the camera would be mounted somewhere on the side to be able to see the object. Upon further reflection, it makes more sense to have the camera be top mounted. This is down to the fact that flat objects such as coins can be made more visible from above, and it won't impact the camera's ability to view other classes of objects. In hindsight, this orientation change helped, as the camera sourced for this project is very zoomed in and has a narrow FOV, which meant I had to mount the camera about 7 inches from the viewing platform. This would not have been possible if I had mounted the camera to face sideways instead of looking down at the objects. </p> </li> </ol>"},{"location":"prototype_v2/#version-21","title":"Version 2.1","text":"<p>Below is a table of components (not including those in CAD) that need to be integrated. Note that prices are listed in USD and are reflective of those found in early October 2025. </p> Component Picture Estimated Unit Cost (on Amazon) Walfront USB Camera Module, HBV-W202012HD ~$11-12 MicroServo 9G (SG90) ~$2 (comes in a 4 pack for ~$8) Arduino Leonardo (NOTE: Any microcontroller can be used as long as it meets your requirements) ~$25 Laptop (NOTE: Laptop must be able to run Python and YOLO, which requires either a decently strong CPU and/or a dedicated GPU. I have the HP ENVY x360 2-in-1 Laptop 15-ew1xxx.) See Geekbench here for detailed info about my laptop's specs. ~$800 3.3V/5V Breadboard Power Supply Module ~$1.80 (comes in a 5 pack for ~9) Breadboard and Jumper Cables (and LEDs if desired) ~$10 (for full pack as pictured) 1602 LCD Screen ~$4.33 (comes in a 3 pack for ~$13) AC Adapter (9V, 1A Output) ~$8"},{"location":"prototype_v2/#arduinomicrocontroller-pin-usage","title":"Arduino/Microcontroller Pin Usage","text":"<p>An Arduino Leonardo has a total of 12 Digital Pins (7 of which are PWM) and 6 Analog Pins. Before thinking about the CAD, it is important to see how many pins are used for what is listed above. This provides a good baseline and is able to inform future improvements. </p> <p>Click to view a great article that details information about the Arduino Leonardo and its pins.</p> Electrical Component Description Pins required on Arduino Green LED Lets user know that an object can be fed into the system for sorting 1 Digital PWM Pin Red LED Lets user know that an object can NOT be fed into the system for sorting 1 Digital PWM Pin Servo Rotates platform to send object to target or not target bin 1 Digital PWM Pin LCD Screen Lets user know status of system without having to look at Python interface; Displays stats to user at the end of sorting session 6 Digital Pins <p>One of the things I was initially considering was including a gate to physically stop objects from being fed, however that is not necessary on the prototype. Ultimately, I picked including a screen over a gate, due to constraints on pins. This can be considered another improvement that would be nice to have. </p> <p>Since most of the pins left are analog pins, this leaves room to include any sensors that may be needed should the information from the camera not be enough for the system to work properly.</p>"},{"location":"prototype_v2/#cad","title":"CAD","text":"<p>I used Onshape to create the CAD for this prototype, and you can view the CAD by clicking here.</p> <p>Picture Galleries of CAD:</p> <p>Various galleries are below to show more details about the components and subassemblies of the CAD. Click thumbnail to enlarge the images.</p> <p>Camera Mounting Subassembly: </p> \u276e \u276f \u00d7 <p>Sorting System Subassembly: </p> \u276e \u276f \u00d7 <p>Body Subassembly:</p> \u276e \u276f \u00d7 <p>Full Assembly: </p> \u276e \u276f \u00d7"},{"location":"prototype_v2/#title1","title":"Version 2 (Final Prototype)","text":""},{"location":"prototype_v2/#title2","title":"Version 2 (Final Prototype)","text":""},{"location":"prototype_v2/#title3","title":"Version 2 (Final Prototype)","text":""},{"location":"prototype_v2/#title4","title":"Version 2 (Final Prototype)","text":""},{"location":"prototype_v2/#prototype-production","title":"Prototype Production","text":"<p>A total of 5 colors were used throughout the printing process. I am listing the color as well as the brand and type of filament.</p> <ol> <li>White (Bambu Lab PLA Basic)</li> <li>Black (Bambu Lab PLA Basic)</li> <li>Light Grey (Bambu Lab PLA Basic)</li> <li>Transparent Red (SUNLU Transparent PLA)</li> <li>Transparent Blue (SUNLU Transparent PLA)</li> </ol> <p>Most of the slicing settings are pretty much left untouched, however, there are some notable settings that I used:</p> <ul> <li>Infill Pattern: Gyroid</li> <li>Infill Density: 15% (can probably go as low as 7-10%)</li> <li>Wall Loops: 2</li> <li>Supports: Normal supports with default settings (not tree supports)</li> </ul> <p>Everything else was left as the default settings found in Bambu Studio.</p> <p>Below are some details that summarizes all relevant details after slicing in Bambu Studio:</p> <p>Total Filament Usage (Including Supports):</p> Color Filament Used White 18.76 g Black 35.00 g Light Grey 288.22 g Transparent Red 91.41 g Transparent Blue 31.82 g Total 465.20 g <p>Costs:</p> <p>Regardless of actual filament, assume that all filament is acquired at the rate of $23/kg, which is similar to how much Bambu Lab PLA Basic filament costs. </p> <p>Total Cost = $0.023/g * 465.20 g = $10.70</p> <p>Time: </p> <p>Total time spent printing is calculated at 13 hours 56 minutes (across 7 plates) according to Bambu Studio using default settings for speed.</p>"},{"location":"prototype_v2/#assembly","title":"Assembly","text":"<p>Below are a few tables that show a list of components and hardware required:</p> 3D Printed Part Subsystem Quantity Camera Frame Corner Sleeve Camera Mounting 4 Camera Frame Camera Mounting 1 Top Plate Camera Mounting 1 12-14oz Coffee Cup Sorting 2 Cup Base Sorting 2 Cup 'Washer' Sorting 2 Cup 'Drawer' Sorting 2 Platform Sorting 1 Ramp Sorting 1 Servo Mount Sorting 1 Platform Sorting 1 Base Body 1 Bottom Body 1 Bin Label Plates Body 2 LCD Screen Frame Body 1 Shell Body 1 Electrical Component Quantity Purpose 1602 LCD Scren 1 Display key information and statistics to user Green LED 1 Tells user object can be fed Red LED 1 Tells user objects can NOT be fed 10k\u2126 Potentiometer 1 Controls screen brightness MicroServo 9G (SG90) 1 Rotate platform to move object for sorting into 'Target' or 'Not Target' bin Walfront Camera Module 1 External USB Camera to provide view of object for YOLO to process Arduino Leonardo 1 Communicates back and forth with Python app to perform key functions Breadboard 1 Connects Arduino to External Power Source Breadboard Power Supply Module + AC Adapter 1 Powers Servo, LCD Screen, and Arduino to take load off of Arduino and Laptop M-M Breadboard Jumper Cables Many Creates electrical connection between components, power source, and Arduino pins without soldering F-M Breadboard Jumper Cables Many Creates electrical connection between components, power source, and Arduino pins without soldering Quantity x Screw Size Purpose 4 x M3 Mounts Shell to Bottom; Threads + Nut Sticking out sits flush with base 2 x M3 Mounts LCD Screen Frame to Shell 4 x M2 Mounts 1602 LCD Screen to LCD Screen Frame 2 x M3 Mount Cup Washer + Cup Base + Cup 'Drawer' 4 x M2 Mount Bin Labels to Top of Shell 6 x M2  2 x M3 Mount Ramp to Top of Shell (not all M2 screws needed; I used 2 x M3 and 2 x M2) 2 x M3 Mount Servo Mount to Top of Shell 2 x M2 Mount Servo to Servo Mount 4 x M2 Mount Camera Frame Corner Sleeve to Top of Shell 4 x M2 Mount Top Plate to Camera Frame <p>Quick Assembly Notes:</p> <p>1) How to assemble platform to servo: You will notice that the platform presses directly onto the splined shaft of the servo. The way I was able to achieve this was by using some accessories you get with servo motors. First, take any arm of the servo you were given (I elected to use the single arm piece given) and cut around the center female splined portion. After that, use some super glue and glue that small part into the side of the platform that has an opening for it (should fit snug). Wait for the glue to dry before assembly. To make a stronger bond, I would suggest using something like PLA Bond to increase the strength of the bond but that is not super necessary. I used the following video for inspiration, and you can use as a refernce should you want to recreate the assembly instructions: Video.</p> <p>2) The end of the Platform that has the shaft sticking out had to be sanded/filed down slightly in my case.</p> <p>3) The holes on the LCD Screen Frame were originally intended to accomodate four M3 screws to hold the screen, but actually work better using four M2 screws.</p> <p>4) The Camera does not slot in anywhere, but it is instead sandwiched between the Camera Frame and Top Plate to keep it held in place. </p> <p>Pictures (electronics not wired and LEDs not installed):</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>Feel free to print this out yourself! Use the .3mf if you have a slicing software that can run it, otherwise I have included the stl/step files needed. Note that the zip files will require you to manually add the names of the bins to the bin labels.</p>      Download 3MF         Download STL/STEP ZIP"},{"location":"prototype_v2/#wiring","title":"Wiring","text":"<p>Below is a wiring diagram: </p> <p></p>"},{"location":"prototype_v2/#testing","title":"Testing","text":"<p>Note that this section refers to testing beyond any fit checks and clearances between any hardware, holes, etc present while assembling the prototype. In other words, the prototype is FULLY assembled by this point and theoretically, if the Arduino code was inputted for the final product, then the system would run (i.e. no wiring changes, etc).</p> <p>Before moving on to final integration, the prototype must be tested for a few things to see how it works. This is to ensure that a proof of concept for a strong path forward before working on a more advanced version of the software and integration. </p> <p>Here is a list of components and/or systems that MUST function properly to ensure that the full prototype works properly:</p> <ul> <li>Green LED</li> <li>Red LED</li> <li>1602 LCD Screen</li> <li>Servo + Platform</li> </ul> <p>The most effective way to test everything at once is to write some code that covers across all components. The code is included below, but first, here are some of the features of the code:</p> <ol> <li>Green and Red LEDs are constantly blinking every couple seconds to ensure those are working properly.</li> <li>LCD Screen displays a welcome message and displays the angle that the servo motor is at.</li> <li>Servo and Platform rotation is tracked and can be calibrated so the correct servo angles can be inputted into the final code. Also, platform must be tested to ensure objects can actually fall into both cups for sorting, which is done manually now since the camera is not connected to YOLO.</li> </ol> <p>Code below:</p> electronics_testing.ino<pre><code>/*\n * Servo Position Tuner with LED &amp; LCD - Arduino Leonardo\n * \n * Hardware:\n * - Servo on pin 3\n * - Green LED on pin 10\n * - Red LED on pin 11\n * - LCD: RS=13, E=12, DB4=4, DB5=5, DB6=6, DB7=7\n * \n * Commands:\n * - 0-180: Move to position\n * - 'h': Set HOME position\n * - 'l': Set LOW limit\n * - 'u': Set UPPER limit\n * - 's': Start sweep\n * - 'x': Stop sweep\n * - 'p': Print settings\n * - 'g': Go to HOME\n * - 'o': Go to LOWER LIMIT\n * - 'i': Go to UPPER LIMIT\n */\n\n#include &lt;Servo.h&gt;\n#include &lt;LiquidCrystal.h&gt;\n\n// Pin definitions\nconst int servoPin = 3;\nconst int greenLED = 10;\nconst int redLED = 11;\n\n// LCD: RS, E, D4, D5, D6, D7\nLiquidCrystal lcd(13, 12, 4, 5, 6, 7);\n\nServo myServo;\n\n// Position variables\nint currentPos = 90;\nint homePos = 90;\nint lowLimit = 0;\nint upperLimit = 180;\n\n// Sweep variables\nbool isSweeping = false;\nint sweepDirection = 1;\nint sweepSpeed = 15;\n\n// LED timing\nunsigned long lastLEDToggle = 0;\nbool greenState = true;\n\n// Display state\nbool showingWelcome = true;\n\nvoid setup() {\n  Serial.begin(9600);\n\n  // Setup LEDs\n  pinMode(greenLED, OUTPUT);\n  pinMode(redLED, OUTPUT);\n  digitalWrite(greenLED, HIGH);\n  digitalWrite(redLED, LOW);\n\n  // Setup servo\n  myServo.attach(servoPin);\n  delay(100);\n  myServo.write(currentPos);\n\n  // Setup LCD\n  lcd.begin(16, 2);\n  delay(50);\n  lcd.clear();\n  lcd.setCursor(0, 0);\n  lcd.print(\"  SERVO TUNER\");\n  lcd.setCursor(0, 1);\n  lcd.print(\"  Welcome!\");\n\n  Serial.println(\"=== Servo Position Tuner ===\");\n  Serial.println(\"Commands:\");\n  Serial.println(\"  0-180: Move to position\");\n  Serial.println(\"  h: Set HOME position\");\n  Serial.println(\"  l: Set LOW limit\");\n  Serial.println(\"  u: Set UPPER limit\");\n  Serial.println(\"  s: Start sweep\");\n  Serial.println(\"  x: Stop sweep\");\n  Serial.println(\"  p: Print settings\");\n  Serial.println(\"  g: Go to HOME\");\n  Serial.println(\"  i: Go to UPPER limit\");\n  Serial.println(\"  o: Go to LOWER limit\");\n  Serial.println(\"===========================\");\n  printSettings();\n}\n\nvoid loop() {\n  // Handle LED blinking (every 1 second)\n  unsigned long currentMillis = millis();\n  if (currentMillis - lastLEDToggle &gt;= 1000) {\n    lastLEDToggle = currentMillis;\n    greenState = !greenState;\n\n    if (greenState) {\n      digitalWrite(greenLED, HIGH);\n      digitalWrite(redLED, LOW);\n    } else {\n      digitalWrite(greenLED, LOW);\n      digitalWrite(redLED, HIGH);\n    }\n  }\n\n  // Handle sweeping\n  if (isSweeping) {\n    currentPos += sweepDirection;\n\n    if (currentPos &gt;= upperLimit) {\n      currentPos = upperLimit;\n      sweepDirection = -1;\n    } else if (currentPos &lt;= lowLimit) {\n      currentPos = lowLimit;\n      sweepDirection = 1;\n    }\n\n    myServo.write(currentPos);\n    updateLCD();\n    delay(sweepSpeed);\n  }\n\n  // Handle serial commands\n  if (Serial.available() &gt; 0) {\n    String input = Serial.readStringUntil('\\n');\n    input.trim();\n\n    if (input.length() == 0) return;\n\n    // Switch from welcome to angle display on first command\n    if (showingWelcome) {\n      showingWelcome = false;\n      updateLCD();\n    }\n\n    char cmd = input.charAt(0);\n\n    // Check if it's a number\n    if (isDigit(cmd)) {\n      int pos = input.toInt();\n      if (pos &gt;= 0 &amp;&amp; pos &lt;= 180) {\n        isSweeping = false;\n        currentPos = pos;\n        myServo.write(currentPos);\n        updateLCD();\n        Serial.print(\"Moved to position: \");\n        Serial.println(currentPos);\n      } else {\n        Serial.println(\"Position must be 0-180\");\n      }\n    }\n    // Handle letter commands\n    else {\n      switch (cmd) {\n        case 'h':\n        case 'H':\n          homePos = currentPos;\n          Serial.print(\"HOME set to: \");\n          Serial.println(homePos);\n          break;\n\n        case 'l':\n        case 'L':\n          lowLimit = currentPos;\n          Serial.print(\"LOW limit set to: \");\n          Serial.println(lowLimit);\n          break;\n\n        case 'u':\n        case 'U':\n          upperLimit = currentPos;\n          Serial.print(\"UPPER limit set to: \");\n          Serial.println(upperLimit);\n          break;\n\n        case 's':\n        case 'S':\n          isSweeping = true;\n          sweepDirection = 1;\n          Serial.println(\"Sweeping started\");\n          break;\n\n        case 'x':\n        case 'X':\n          isSweeping = false;\n          Serial.println(\"Sweeping stopped\");\n          break;\n\n        case 'p':\n        case 'P':\n          printSettings();\n          break;\n\n        case 'g':\n        case 'G':\n          isSweeping = false;\n          currentPos = homePos;\n          myServo.write(currentPos);\n          updateLCD();\n          Serial.print(\"Moved to HOME: \");\n          Serial.println(homePos);\n          break;\n\n        case 'i':\n        case 'I':\n          isSweeping = false;\n          currentPos = upperLimit;\n          myServo.write(currentPos);\n          updateLCD();\n          Serial.print(\"Moved to UPPER limit: \");\n          Serial.println(upperLimit);\n          break;\n\n        case 'o':\n        case 'O':\n          isSweeping = false;\n          currentPos = lowLimit;\n          myServo.write(currentPos);\n          updateLCD();\n          Serial.print(\"Moved to LOWER limit: \");\n          Serial.println(lowLimit);\n          break;\n\n        default:\n          Serial.println(\"Unknown command\");\n      }\n    }\n  }\n}\n\nvoid updateLCD() {\n  lcd.clear();\n  lcd.setCursor(0, 0);\n  lcd.print(\"SERVO ANGLE:\");\n  lcd.setCursor(0, 1);\n  lcd.print(currentPos);\n}\n\nvoid printSettings() {\n  Serial.println(\"\\n--- Current Settings ---\");\n  Serial.print(\"Current Position: \");\n  Serial.println(currentPos);\n  Serial.print(\"HOME Position: \");\n  Serial.println(homePos);\n  Serial.print(\"LOW Limit: \");\n  Serial.println(lowLimit);\n  Serial.print(\"UPPER Limit: \");\n  Serial.println(upperLimit);\n  Serial.print(\"Sweeping: \");\n  Serial.println(isSweeping ? \"YES\" : \"NO\");\n  Serial.println(\"------------------------\\n\");\n}\n</code></pre> <p>Below is some images and a video of how the electronics test was assembled. Note that it was not assembled on the actual prototype for two reasons:</p> <p>1) To make sure the concept actually works before fully assembling it and wiring it together.</p> <p>2) At the time of testing, I didn't have the necessary jumper cables to do a proof of concept test on the actual prototype. This meant that I couldn't assemble it on the actual product just yet, but I was able to test all electronics to see if it was working.</p> <p>It is also important to note that some may experience difficulties with assembly and/or testing. There are generally two types of issues, one of which is software issues, and the other of which is hardware issues. Common software issues usually fall under either a code that has bugs or code that has faulty logic, both of which can still occur despite using AI tools for coding. Common hardware issues include the following: damaged Arduino pins, faulty chip on the Arduino, loose connections, faulty wires, faulty wiring, faulty breadboard, etc. The only major problem I had with the wiring was actually a faulty breadboard, which meant I had to rewire the entire circuit on a different breadboard. </p> <p></p> <p></p> Video showing electronics and wiring <p>The way I approached testing was to show a proof of concept for all working systems, including mechanical and electrical. The code above was able to get the electronics working, which entailed getting the platform rotated. However, the prototype will only have a good proof of concept if it can theoretically send objects to any bin while also relaying information on the screen. Something important to note is that I am manually telling the servo to move to a certain angle, whereas in the final testing, it will be automated based on the objects fed, the user demands, and of course, the pytorch model loaded.</p> <p>Therefore, I decided to put it to the test by sending a small sample set of objects. Below are the exact objects I used while testing, and a ruler to give an idea of the general size of these objects:</p> <p></p> <p>And now, the test video below:</p> Video depicting test being carried out <p>Testing Observations:</p> <ul> <li>Using the code above, I figured out that the upper limit was 135 degrees and the lower limit was 55 degrees, which gives a sweeping motion of 80 degrees, or about 40 degrees on each side. This was more than I had expected from when I was modelling the prototype in CAD. The final tuning will be done before final testing if needed.</li> <li>All the electronics work as expected. The screen turns on, gives a welcome message, and relays the servo angles at all times when there is a change. The LCD also works as expected, and the potentiometer does, in fact, adjust the brightness as required. The LEDs alternate turning on and off while power is being given. The servo also turns as expected, which a relatively quick response time to any inputs.</li> </ul>"},{"location":"prototype_v2/#conclusion","title":"Conclusion","text":"<p>With all the success of the assembly and testing, I think this is a solid prototype to move forward with the project. </p> <p>Any changes that have to be made to the prototype are all considered minor, and will be documented and finalized in the integration stage.</p>"},{"location":"results/","title":"Reflections","text":""},{"location":"results/#general-remarks","title":"General Remarks","text":"<p>Overall, I am satisfied with both aspects of the prototype as is (hardware and software), and it does ultimately serve the purpose that it was designed for. A great proof of concept has been reached and this is something that can be tweaked and applied across various areas. Examples include detecting bullet casings, various kinds of beans, resistors, LEGOs, etc.</p> <p>If I were to iterate and make a new version, here is what I would do:</p> <ol> <li>Software<ul> <li>Do more user testing to fix all bugs</li> <li>Tweak Arduino code to ensure it counts total objects instead of total servo sweeps</li> <li>Include relative file paths to make the user experience of setting up the sorting session a lot faster</li> <li>Develop a system to better store data, as having the data stored in excel files is great for smaller scale projects and demos but horrible for large scale implementation</li> <li>Create a few performance modes: conservative, normal, and rapid, all of which adjust the necessary settings to easily speed up and slow down the whole system. As of right now, the user would have to go into the code and find those parameters to change.</li> <li>Create a mode that allows user easily do a dummy run to record a video of objects that need to be sorted (for the purposes of model training). This can be achieved by connecting a button to the Arduino, and if that gets pressed, then do the following: <ul> <li>Start servo from neutral position</li> <li>Sweep to Target in after 3 seconds</li> <li>Sweep back to neutral after 3 seconds</li> <li>Sweep to Not Target after 3 seconds</li> <li>Sweep back to neutral after 3 seconds</li> <li>Repeat until user hits button again</li> </ul> </li> </ul> </li> <li>Hardware<ul> <li>Create channels for wires to easily go through and stay hidden</li> <li>Design a place to hold all electronics that is out of the way from the bins, ideally underneath or somewhere off to the side in a separate 'black box'</li> <li>Redesign some aspects to make it easier to assemble, specifically for tool access</li> <li>Adjust mounting of the LCD to better fit the screen, and maybe hide away the green edge</li> <li>Find a way to mount the potentiometer on the shell to allow for an easy way to adjust screen dimming</li> <li>Design a flashlight mount or add a small strip of LED lights to better illuminate the platform</li> </ul> </li> </ol> <p>Here is what I might change if I had to do this all over again:</p> <ul> <li>Source a different camera: The camera used turned out to be pretty poor. The resolution wasn't the greatest, and that led to a harder time detecting complex objects such as coins. I would suggest either using a better camera or even allowing for smartphone compatibility.</li> <li>Design a Web App: This would allow for such a device to be run on much lower end devices at higher performances, but that would unlock new challenges with communication between the web interface and Arduino.</li> <li>Switch away from a pure binary concept: If the user knew the number of unique classes beforehand, then it would be entirely possible to have a modular system of bins that allows the number of bins to be specified. From there, only 1 pass would be required to sort through all objects, and would greatly speed up the sorting process. This has potential because during testing, the same working conditions between a human and the prototype always saw the prototype faster at sorting. However, a system with 10 bins would be hard to design. A middle ground is a 3 bin system, where 2 targets are being searched and the rest go to an other bin, which would halve the number of passes required.</li> <li>Conciously slim down the size of the prototype: While it is simple, the proptotype is rather large, and I think that the size of it can be trimmed down to help reduce filament usage and cost.</li> <li>Better overall camera housing module: The camera housing module was designed purely from an optimization point of view to use the least amount of filament. However, I would design an enclosed box with bright LED lights that illuminates the area where the objects are being viewed.</li> <li>Platform geometry/size: The platform itself is a restriction of what types of objects can be sorted. Bigger objects cannot be ran through simply because of the size of the platform.</li> <li>Experiement with a different microcontroller: Since the web app concept was shelved midway through the project, the need for a WebUSB board was not required. It might have not been a bad idea to experiement with a microcontroller that has an embedded camera to reduce some of the complexities in the design. This might also open up the path to try and use something like TinyML to optimize the sorting process and have it run directly on the microcontroller rather than using a laptop as the brain of the whole operation.</li> <li>Design a system for object feeding: To improve the user experience further, a system that can feed most kinds of objects should be introduced to make the process more hands-off.</li> </ul> <p>If I were to redesign or continue forth with the project development, I would use the above list as a way to establish a good path forward to continue forth with the development. </p>"},{"location":"results/#my-take-on-using-genai-for-such-projects","title":"My take on using GenAI for such projects","text":"<p>Overall, GenAI has been an incredible advancement in technology. The ability to put in what you want to do in words and have a computer translate that into an actual command is a huge leap. However, it does have its limitations, and to say this could be used to generate whole projects is not the best use of GenAI.</p> <p>GenAI is like a tool, but not a simple tool like a pencil or pen. It is like a swiss army knife, where there are a ton of tools that can be used within this larger tool. In the same way that swiss army knives have knives, screwdrivers, or pliers, GenAI has the ability to interpret long documents, perform deep research, and generate code. No matter how impressive any swiss army knife is, a general contractor won't ask all their employees to start building homes only using swiss army knives. That is exactly the way I see GenAI. </p> <p>Even if I had prompted any GenAI model to build a project such as this one, it would not give me a working output at once. I might have to spend time debugging, or tweaking some functions, or maybe I gave it too much freedom in one aspect and too little freedom in another. At the end of the day, whole projects are not built in one step, or one prompt. They require many tools and in most cases, many people along the way. </p> <p>I will be transparent and say that I did use GenAI to work through this project, and utilized a combination of OpenAI's ChatGPT and Anthropic's Claude models to work through the project. However, my use of GenAI was purely to help supplement areas where I am not as strong. I did all of the idea generation and CAD on my own, but I used it to help me work through code. Note that I spent the time learning about how to code during my undergrad and again at the start of the project, which helped me immensely with the debugging process as well as sometimes guiding the GenAI model towards a more correct path. </p>"},{"location":"software_development/","title":"Software Development Overview","text":"<p>This section of the website is dedicated to getting a minimum viable software developed, before truly getting it integrated in context to the whole system. The software was developed before any physical prototype was designed or assembled. </p> <p>View the progression through the software development via the collapsible menu on the left. </p>"},{"location":"software_v1/","title":"Version 1","text":""},{"location":"software_v1/#brief-intro-and-technical-details","title":"Brief Intro and Technical Details","text":"<p>This page outlines the first attempt at developing a python app to be controlled by the user via a GUI. </p> <p>Here is a quick overview of the software:</p> <ul> <li>Scanning Mode \u2192 Scans all objects that need to be sorted, with a list of unique objects stored in a .csv file.</li> <li>Sorting Mode \u2192 Sorts the objects</li> </ul> <p>Here is a quick overview of the key features:</p> <ul> <li>Object Detection \u2192 Done by utilizing webcam and YOLO; users can select a PyTorch model to be used</li> <li>Object Logging \u2192 Stores list of unique objects in csv to be read by Arduino; objects also stored in Arduino's EEPROM in case system powers off</li> <li>User Control \u2192 User dictates when the software does what</li> <li>Arduino Recognition \u2192 Software knows when Arduino is connected and will not start scanning or sorting until then</li> <li>Error Handling \u2192 Some error checking is in place</li> </ul> <p>How does this compare to the requirements laid out on the milestones page?</p> Requirement from Milestone 3 Status Notes (if needed) Be intuitive to use, and look somewhat polished \u274c GUI is intuitive, but very dated Allow user to perform basic functions \ud83d\udd04 Detection and scanning good, but sorting framework not set in place Allow user control over the process \u2705 User dictates entire process, minus the actual object detection At the minimum, recognize when an Arduino is connected via USB to laptop \ud83d\udd04 System can recognize AND communicate with Arduino, but framework to sort is not in place Leverage webcam to detect objects \u2705 Utilizes YOLO and webcam to detect objects, with bounding boxes serving as visual confirmation Have some error handling in place and prevent user from going too far out of order \u2705 Error handling present <p>What is missing with this version?</p> <ul> <li>Object Sorting Theory \u2192 Sorting Mode can be engaged but beyond that, there is not much structure for how the objects will be sorted. Binary sorting makes the most sense in this application and will be developed in the next version.</li> <li>User Interface \u2192 Interface using tkinter for Python was a great idea, but has a very dated appearance </li> <li>Arduino Functionality \u2192 Arduino is equipped to identify when sorting has started, but does not have the proper framework in place to be able to control motors.</li> </ul>"},{"location":"software_v1/#code","title":"Code","text":"<p>Since this is an intermediate version of the software, with a better version in place, the code for the GUI and Arduino will be provided here as well as screenshots of the appearance of the software. A video of the software working will be provided on the next version's page, with error handling, user control, etc on full display. </p> <p>Python Code: </p><pre><code>import tkinter as tk\nfrom tkinter import ttk, filedialog\nfrom PIL import Image, ImageTk\nimport cv2\nfrom ultralytics import YOLO\nimport csv\nimport os\nimport serial\nimport threading\nfrom datetime import datetime\nimport serial.tools.list_ports\nimport time\nimport csv\nfrom PIL import ImageDraw, ImageFont\n\n# ---------------------------\n# CONFIGURATION\n# ---------------------------\nCAMERA_INDEX = 0\nWINDOW_TITLE = \"YOLO-Based Binary Object Sorting System V1\"\nWINDOW_BG_COLOR = \"#1e1e1e\"\nFRAME_RATE_MS = 15\nLOG_DIR = \"logs\"\n\n# ---------------------------\n# Ensure Logs Folder Exists\n# ---------------------------\nos.makedirs(LOG_DIR, exist_ok=True)\n\ndef generate_csv_name():\n    now = datetime.now()\n    return f\"{LOG_DIR}/scan_log_{now.strftime('%Y-%m-%d_%H-%M-%S')}.csv\"\n\n# ---------------------------\n# Connection to Arduino\n# ---------------------------\n\ndef find_arduino_port():\n    ports = serial.tools.list_ports.comports()\n    for port in ports:\n        if \"Leonardo\" in port.description or (port.vid == 0x2341 and port.pid == 0x8036):\n            return port.device\n    return None\n\ndef reset_arduino_before_exit(port):\n    try:\n        ser = serial.Serial(port, 1200)\n        ser.close()\n        print(\"\ud83d\uded1 Arduino reset triggered\")\n        time.sleep(2)  # wait for Arduino to fully reset\n    except Exception as e:\n        print(f\"\u26a0\ufe0f Could not reset Arduino: {e}\")\n\ndef get_unique_classes_from_csv(path):\n    unique_classes = set()\n    try:\n        with open(path, newline='') as f:\n            reader = csv.reader(f)\n            for row in reader:\n                if len(row) &gt;= 2:\n                    unique_classes.add(row[1])\n    except Exception as e:\n        print(f\"Error reading CSV: {e}\")\n    return list(unique_classes)\n\ndef send_objects_to_eeprom(item_list, arduino_serial):\n    try:\n        # Create comma-separated string\n        object_string = \",\".join(item_list[:20])  # Limit to 20 items\n\n        # Send the command\n        command = f\"STORE_OBJECTS:{object_string}\\n\"\n        arduino_serial.write(command.encode())\n\n        print(f\"\u2705 Sent {len(item_list)} objects to Arduino EEPROM\")\n        return True\n\n    except Exception as e:\n        print(f\"\u274c Failed to send objects: {e}\")\n        return False\n\n# ---------------------------\n# GUI Class\n# ---------------------------\nclass YOLOApp:\n    def __init__(self, root):\n        self.root = root\n        self.root.title(WINDOW_TITLE)\n        self.root.configure(bg=WINDOW_BG_COLOR)\n        self.arduino = None\n\n        self.cap = cv2.VideoCapture(CAMERA_INDEX)\n        if not self.cap.isOpened():\n            raise RuntimeError(\"\u274c Cannot open webcam\")\n\n        self.is_running = False\n        self.mode = None  # 'scan' or 'sort'\n        self.csv_file = None\n        self.detected_classes = set()\n        self.model_path = \"\"\n        self.model = None\n        self.arduino_ready_to_sort = False\n\n        # Layout frames\n        main_frame = tk.Frame(root, bg=WINDOW_BG_COLOR)\n        main_frame.pack(fill=tk.BOTH, expand=True)\n\n        left_frame = tk.Frame(main_frame, bg=WINDOW_BG_COLOR)\n        left_frame.pack(side=tk.LEFT, padx=10, pady=10)\n\n        right_frame = tk.Frame(main_frame, bg=WINDOW_BG_COLOR)\n        right_frame.pack(side=tk.RIGHT, padx=10, pady=10, fill=tk.Y)\n\n        # Video Frame\n        self.video_frame = tk.Label(left_frame)\n        self.video_frame.pack()\n\n        # Create a black placeholder with text \"Camera Offline\"\n        placeholder = Image.new(\"RGB\", (640, 480), (0, 0, 0))\n        draw = ImageDraw.Draw(placeholder)\n\n        try:\n            font = ImageFont.truetype(\"arial.ttf\", 36)\n        except:\n            font = ImageFont.load_default()\n\n        text = \"CAMERA OFFLINE\"\n        bbox = draw.textbbox((0, 0), text, font=font)\n        text_width = bbox[2] - bbox[0]\n        text_height = bbox[3] - bbox[1]\n        position = ((640 - text_width) // 2, (480 - text_height) // 2)\n        draw.text(position, text, fill=(200, 200, 200), font=font)\n\n        self.placeholder_img = ImageTk.PhotoImage(placeholder)\n        self.video_frame.configure(image=self.placeholder_img)\n        self.video_frame.imgtk = self.placeholder_img\n\n        # Control Buttons\n        btn_frame = tk.Frame(left_frame, bg=WINDOW_BG_COLOR)\n        btn_frame.pack(pady=10)\n\n        self.choose_model_btn = ttk.Button(btn_frame, text=\"Choose PyTorch Model\", command=self.choose_model)\n        self.choose_model_btn.grid(row=0, column=0, padx=5)\n\n        self.arduino_btn = ttk.Button(btn_frame, text=\"Connect to Arduino\", command=self.connect_to_arduino)\n        self.arduino_btn.grid(row=0, column=1, padx=5)\n\n        self.scan_btn = ttk.Button(btn_frame, text=\"\ud83d\udcf8 Start Scanning Mode\", command=self.start_scanning_mode)\n        self.scan_btn.grid(row=0, column=2, padx=5)\n\n        self.sort_btn = ttk.Button(btn_frame, text=\"\u2699\ufe0f Start Sorting Mode\", command=self.start_sorting_mode)\n        self.sort_btn.grid(row=0, column=3, padx=5)\n\n        self.stop_btn = ttk.Button(btn_frame, text=\"\u23f9 Stop\", command=self.stop_detection)\n        self.stop_btn.grid(row=0, column=4, padx=5)\n\n        # Second row of buttons\n        self.send_list_btn = ttk.Button(btn_frame, text=\"\ud83d\udcc2 Send Object List to Arduino\", command=self.send_object_list)\n        self.send_list_btn.grid(row=1, column=0, columnspan=2, pady=10, padx=5)\n\n        self.list_objects_btn = ttk.Button(btn_frame, text=\"\ud83d\udccb List Stored Objects\", command=self.list_stored_objects)\n        self.list_objects_btn.grid(row=1, column=2, padx=5)\n\n        self.clear_objects_btn = ttk.Button(btn_frame, text=\"\ud83d\uddd1\ufe0f Clear Objects\", command=self.clear_stored_objects)\n        self.clear_objects_btn.grid(row=1, column=3, padx=5)\n\n        exit_button = ttk.Button(btn_frame, text=\"Exit\", command=self.exit_app)\n        exit_button.grid(row=1, column=4, padx=5)\n\n        # Output Log\n        self.log_text = tk.Text(right_frame, width=40, height=30, bg=\"black\", fg=\"white\", wrap=tk.WORD)\n        self.log_text.pack(fill=tk.BOTH, expand=True)\n        self.log(\"\ud83d\udfe2 GUI Initialized\")\n\n        # ---------------------------\n        # \ud83c\udfa8 Button Styling\n        # ---------------------------\n        style = ttk.Style()\n        style.theme_use(\"default\")\n        style.configure(\"TButton\", background=\"#444\", foreground=\"white\", padding=6, font=(\"Segoe UI\", 10, \"bold\"))\n        style.map(\"TButton\", background=[(\"active\", \"#777\")])\n\n    # ---------------------------\n    # \ud83e\uddfe Log Output\n    # ---------------------------\n    def log(self, message):\n        timestamp = datetime.now().strftime(\"[%H:%M:%S]\")\n        self.log_text.insert(tk.END, f\"{timestamp} {message}\\n\")\n        self.log_text.see(tk.END)\n\n    # ---------------------------\n    # \ud83d\udea6 MODE SWITCHING\n    # ---------------------------\n    def start_scanning_mode(self):\n        if self.mode == \"scan\":\n            self.stop_detection()\n            return\n\n        if self.model is None:\n            self.log(\"\u26a0\ufe0f No model selected\")\n            return\n        if self.arduino is None or not self.arduino.is_open:\n            self.log(\"\u26a0\ufe0f Arduino not connected\")\n            return\n\n        self.stop_detection()\n        self.mode = \"scan\"\n        self.scan_btn.config(text=\"\u23f9 Stop Scanning Mode\", state=tk.NORMAL)\n        self.sort_btn.config(state=tk.DISABLED)\n        self.csv_file = generate_csv_name()\n        self.detected_classes.clear()\n        self.log(f\"\ud83d\udcc4 Logging to: {self.csv_file}\")\n        self.is_running = True\n        self.update_frame()\n\n    def start_sorting_mode(self):\n        if self.mode == \"sort\":\n            self.stop_detection()\n            return\n        if self.model is None:\n            self.log(\"\u26a0\ufe0f No model selected\")\n            return\n        if self.arduino is None or not self.arduino.is_open:\n            self.log(\"\u26a0\ufe0f Arduino not connected\")\n            return\n        if not self.arduino_ready_to_sort:\n            self.log(\"\u274c Arduino is not ready. Send object list first.\")\n            return\n        self.stop_detection()\n        self.mode = \"sort\"\n        self.sort_btn.config(text=\"\u23f9 Stop Sorting Mode\", state=tk.NORMAL)\n        self.scan_btn.config(state=tk.DISABLED)\n        self.log(\"\u2699\ufe0f Sorting mode active\")\n        self.is_running = True\n        self.update_frame()\n\n    def stop_detection(self):\n        self.is_running = False\n        was_sorting = (self.mode == \"sort\")  # Remember if we were sorting\n        self.mode = None\n        self.video_frame.configure(image=self.placeholder_img)\n        self.video_frame.imgtk = self.placeholder_img\n        self.scan_btn.config(text=\"\ud83d\udcf8 Start Scanning Mode\", state=tk.NORMAL)\n        self.sort_btn.config(text=\"\u2699\ufe0f Start Sorting Mode\", state=tk.NORMAL)\n\n        # Send stop command to Arduino\n        self.send_to_arduino(\"stop\")\n\n        if was_sorting:\n            self.log(\"\ud83d\uded1 Detection stopped - Sorting mode disabled\")\n        else:\n            self.log(\"\ud83d\uded1 Detection stopped\")\n\n    def choose_model(self):\n        if self.is_running:\n            self.log(\"\u26a0\ufe0f Stop detection before loading a new model\")\n            return\n        path = filedialog.askopenfilename(filetypes=[(\"PyTorch Model\", \"*.pt\")])\n        if path:\n            self.model_path = path\n            self.model = YOLO(self.model_path)\n            self.log(f\"\u2705 Model loaded: {self.model_path}\")\n\n    # ---------------------------\n    # Frame Processing\n    # ---------------------------\n    def update_frame(self):\n        if not self.is_running:\n            return\n\n        ret, frame = self.cap.read()\n        if not ret:\n            self.log(\"\u274c Failed to grab frame - stopping detection\")\n            self.stop_detection()  # Auto-stop if camera fails\n            return\n\n        results = self.model(frame)[0]\n        annotated = results.plot()\n\n        if self.mode == \"scan\":\n            self.handle_scanning_mode(results)\n        elif self.mode == \"sort\":\n            self.handle_sorting_mode(results)\n\n        rgb_frame = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n        img = Image.fromarray(rgb_frame)\n        imgtk = ImageTk.PhotoImage(image=img)\n        self.video_frame.imgtk = imgtk\n        self.video_frame.configure(image=imgtk)\n\n        self.root.after(FRAME_RATE_MS, self.update_frame)\n\n    # ---------------------------\n    # Scanning Mode Logic\n    # ---------------------------\n    def handle_scanning_mode(self, results):\n        self.send_to_arduino(\"scan\")\n        for box in results.boxes:\n            cls_id = int(box.cls[0])\n            class_name = self.model.names[cls_id]\n            if class_name not in self.detected_classes:\n                self.detected_classes.add(class_name)\n                with open(self.csv_file, 'a', newline='') as f:\n                    writer = csv.writer(f)\n                    writer.writerow([datetime.now().isoformat(), class_name])\n                self.log(f\"\ud83d\udcdd Logged: {class_name}\")\n\n    # ---------------------------\n    # Sorting Mode Logic\n    # ---------------------------\n    def handle_sorting_mode(self, results):\n        self.send_to_arduino(\"sort\")\n        for box in results.boxes:\n            cls_id = int(box.cls[0])\n            class_name = self.model.names[cls_id]\n            self.log(f\"\ud83d\udce6 Detected for sorting: {class_name}\")\n            # Send the detected class to Arduino\n            self.send_to_arduino(class_name)\n            break\n\n    # ---------------------------\n    # Arduino Communication\n    # ---------------------------\n\n    def connect_to_arduino(self):\n        port = find_arduino_port()\n        if port:\n            try:\n                self.arduino = serial.Serial(port, 9600, timeout=2)\n                self.log(f\"\ud83d\udfe1 Connecting to Arduino on {port}...\")\n\n                time.sleep(2)  # Allow time for Arduino to reset and send handshake\n\n                # Wait for \"READY\"\n                start_time = time.time()\n                ready_line = \"\"\n                while time.time() - start_time &lt; 5:\n                    if self.arduino.in_waiting &gt; 0:\n                        ready_line = self.arduino.readline().decode().strip()\n                        if ready_line == \"READY\":\n                            break\n                        elif ready_line:  # Any other message from Arduino\n                            self.log(f\"Arduino: {ready_line}\")\n\n                if ready_line == \"READY\":\n                    self.log(\"\u2705 Arduino is ready!\")\n                    self.arduino_btn.config(text=\"Arduino Connected!\", state=tk.DISABLED)\n\n                    # Start listening thread for Arduino messages\n                    self.start_arduino_listener()\n                else:\n                    self.log(f\"\u274c Unexpected handshake message: {ready_line}\")\n            except serial.SerialException as e:\n                self.log(f\"\u274c Connection Failed: {str(e)}\")\n        else:\n            self.log(\"\u26a0\ufe0f No Arduino found!\")\n\n    def start_arduino_listener(self):\n        \"\"\"Start a background thread to listen for Arduino messages\"\"\"\n        def listen():\n            while self.arduino and self.arduino.is_open:\n                try:\n                    if self.arduino.in_waiting &gt; 0:\n                        message = self.arduino.readline().decode().strip()\n                        if message:\n                            if message == \"READY_TO_SORT\":\n                                self.arduino_ready_to_sort = True\n                                self.log(\"\ud83d\udfe2 Arduino ready to sort!\")\n                            else:\n                                self.log(f\"Arduino: {message}\")\n                    time.sleep(0.1)\n                except Exception as e:\n                    if self.arduino and self.arduino.is_open:\n                        self.log(f\"Error reading from Arduino: {e}\")\n                    break\n\n        listener_thread = threading.Thread(target=listen, daemon=True)\n        listener_thread.start()\n\n    def send_to_arduino(self, message):\n        try:\n            if self.arduino and self.arduino.is_open:\n                self.arduino.write((message + \"\\n\").encode())\n        except Exception as e:\n            self.log(f\"\u274c Error sending to Arduino: {e}\")\n\n    def send_object_list(self):\n        \"\"\"Send object list to Arduino EEPROM\"\"\"\n        if self.arduino is None or not self.arduino.is_open:\n            self.log(\"\u26a0\ufe0f Arduino must be connected before sending list\")\n            return\n\n        filepath = filedialog.askopenfilename(filetypes=[(\"CSV Files\", \"*.csv\")])\n        if not filepath:\n            self.log(\"\u26a0\ufe0f No file selected\")\n            return\n\n        classes = get_unique_classes_from_csv(filepath)\n        if not classes:\n            self.log(\"\u26a0\ufe0f No valid objects found in CSV\")\n            return\n\n        self.log(f\"\ud83d\udce4 Sending {len(classes)} objects to Arduino EEPROM...\")\n\n        if send_objects_to_eeprom(classes, self.arduino):\n            self.log(f\"\u2705 Sent {len(classes)} objects: {', '.join(classes)}\")\n        else:\n            self.log(\"\u274c Send failed\")\n\n    def list_stored_objects(self):\n        \"\"\"Ask Arduino to list stored objects\"\"\"\n        if self.arduino and self.arduino.is_open:\n            self.send_to_arduino(\"LIST_OBJECTS\")\n        else:\n            self.log(\"\u26a0\ufe0f Arduino not connected\")\n\n    def clear_stored_objects(self):\n        \"\"\"Clear objects from Arduino EEPROM\"\"\"\n        if self.arduino and self.arduino.is_open:\n            self.send_to_arduino(\"CLEAR_OBJECTS\")\n            self.arduino_ready_to_sort = False\n            self.log(\"\ud83d\uddd1\ufe0f Cleared stored objects\")\n        else:\n            self.log(\"\u26a0\ufe0f Arduino not connected\")\n\n    def exit_app(self):\n        if self.arduino and self.arduino.is_open:\n            port = self.arduino.port\n            self.arduino.close()\n            self.clear_stored_objects()\n            reset_arduino_before_exit(port)\n        self.root.destroy()\n\n# ---------------------------\n# Run GUI\n# ---------------------------\nif __name__ == \"__main__\":\n    root = tk.Tk()\n    app = YOLOApp(root)\n    root.mainloop()\n\n    if app.cap.isOpened():\n        app.cap.release()\n    cv2.destroyAllWindows()\n</code></pre> <p>Arduino Code: </p><pre><code>#include &lt;Arduino.h&gt;\n#include &lt;EEPROM.h&gt;\n\nconst uint8_t MAX_ITEMS = 30;\nconst uint8_t MAX_STR_LEN = 50;\nconst int EEPROM_START_ADDR = 0;\nconst int NUM_ITEMS_ADDR = 0;\nconst int ITEMS_START_ADDR = 1;\n\nString storedItems[MAX_ITEMS];\nuint8_t numStoredItems = 0;\nString currentMode = \"\";\nString lastModeMessage = \"\";\nunsigned long lastModeTime = 0;\nconst unsigned long MODE_MESSAGE_COOLDOWN = 5000; // 5 seconds between mode messages\nbool itemsLoaded = false;\n\nvoid storeObjectsInEEPROM(String objects[], uint8_t count) {\n  // Store number of items first\n  EEPROM.write(NUM_ITEMS_ADDR, count);\n\n  int addr = ITEMS_START_ADDR;\n\n  for (uint8_t i = 0; i &lt; count; i++) {\n    String item = objects[i];\n\n    // Store length of string\n    uint8_t len = min(item.length(), (unsigned int)(MAX_STR_LEN - 1));\n    EEPROM.write(addr, len);\n    addr++;\n\n    // Store the string characters\n    for (uint8_t j = 0; j &lt; len; j++) {\n      EEPROM.write(addr, item[j]);\n      addr++;\n    }\n\n    // Fill remaining space with zeros\n    for (uint8_t j = len; j &lt; MAX_STR_LEN - 1; j++) {\n      EEPROM.write(addr, 0);\n      addr++;\n    }\n  }\n\n  Serial.println(\"\u2705 Objects stored in EEPROM\");\n}\n\nvoid loadObjectsFromEEPROM() {\n  numStoredItems = EEPROM.read(NUM_ITEMS_ADDR);\n\n  // Sanity check\n  if (numStoredItems &gt; MAX_ITEMS) {\n    numStoredItems = 0;\n    Serial.println(\"\u26a0\ufe0f Invalid EEPROM data, resetting\");\n    return;\n  }\n\n  if (numStoredItems == 0) {\n    Serial.println(\"\ud83d\udced No objects stored in EEPROM\");\n    return;\n  }\n\n  int addr = ITEMS_START_ADDR;\n\n  for (uint8_t i = 0; i &lt; numStoredItems; i++) {\n    uint8_t len = EEPROM.read(addr);\n    addr++;\n\n    if (len &gt;= MAX_STR_LEN) len = 0; // Corrupted data\n\n    String item = \"\";\n    for (uint8_t j = 0; j &lt; len; j++) {\n      char c = EEPROM.read(addr);\n      if (c != 0) item += c;\n      addr++;\n    }\n\n    // Skip remaining bytes for this item\n    addr += (MAX_STR_LEN - 1 - len);\n\n    storedItems[i] = item;\n  }\n\n  if (numStoredItems &gt; 0) {\n    itemsLoaded = true;\n    Serial.println(\"\ud83d\udce5 Objects loaded from EEPROM:\");\n    for (uint8_t i = 0; i &lt; numStoredItems; i++) {\n      Serial.print(\"  \");\n      Serial.println(storedItems[i]);\n    }\n    Serial.println(\"READY_TO_SORT\");\n  }\n}\n\nString lastSortedItem = \"\";\nunsigned long lastSortTime = 0;\nconst unsigned long SORT_COOLDOWN = 2000; // 2 seconds between same item sorts\n\nvoid handleSorting(String itemClass) {\n  unsigned long currentTime = millis();\n\n  // Only process if it's a different item or enough time has passed\n  if (itemClass != lastSortedItem || (currentTime - lastSortTime) &gt; SORT_COOLDOWN) {\n    Serial.print(\"\ud83d\udd04 Sorting item: \");\n    Serial.println(itemClass);\n\n    if (itemClass == \"bottle\") {\n      // trigger servo for bottle\n      Serial.println(\"\u2192 Sorting bottle\");\n    } else if (itemClass == \"can\") {\n      // another action for can\n      Serial.println(\"\u2192 Sorting can\");\n    } else if (itemClass == \"apple\") {\n      // action for apple\n      Serial.println(\"\u2192 Sorting apple\");\n    } else {\n      Serial.println(\"\u2753 Unknown class, default action\");\n    }\n\n    lastSortedItem = itemClass;\n    lastSortTime = currentTime;\n  }\n}\n\nvoid processObjectList(String objectListString) {\n  // Parse comma-separated string\n  String tempItems[MAX_ITEMS];\n  uint8_t count = 0;\n\n  int startIdx = 0;\n  int commaIdx = objectListString.indexOf(',');\n\n  while (commaIdx != -1 &amp;&amp; count &lt; MAX_ITEMS) {\n    tempItems[count] = objectListString.substring(startIdx, commaIdx);\n    tempItems[count].trim();\n    count++;\n\n    startIdx = commaIdx + 1;\n    commaIdx = objectListString.indexOf(',', startIdx);\n  }\n\n  // Get the last item (or the only item if no commas)\n  if (startIdx &lt; objectListString.length() &amp;&amp; count &lt; MAX_ITEMS) {\n    tempItems[count] = objectListString.substring(startIdx);\n    tempItems[count].trim();\n    count++;\n  }\n\n  if (count &gt; 0) {\n    storeObjectsInEEPROM(tempItems, count);\n    loadObjectsFromEEPROM(); // Reload to confirm storage worked\n  }\n}\n\nvoid setup() {\n  Serial.begin(9600);\n  while (!Serial);\n  delay(1000);\n\n  Serial.println(\"\ud83e\udd16 Arduino Object Sorter Starting...\");\n\n  // Try to load existing objects from EEPROM\n  loadObjectsFromEEPROM();\n\n  Serial.println(\"READY\");\n}\n\nvoid loop() {\n  if (Serial.available()) {\n    String input = Serial.readStringUntil('\\n');\n    input.trim();\n\n    if (input.startsWith(\"STORE_OBJECTS:\")) {\n      // Extract the object list from the command\n      String objectList = input.substring(14); // Remove \"STORE_OBJECTS:\" prefix\n      Serial.print(\"\ud83d\udcdd Storing objects: \");\n      Serial.println(objectList);\n      processObjectList(objectList);\n\n    } else if (input == \"LOAD_OBJECTS\") {\n      loadObjectsFromEEPROM();\n\n    } else if (input == \"LIST_OBJECTS\") {\n      if (itemsLoaded &amp;&amp; numStoredItems &gt; 0) {\n        Serial.println(\"\ud83d\udccb Current object list:\");\n        for (uint8_t i = 0; i &lt; numStoredItems; i++) {\n          Serial.print(\"  \");\n          Serial.print(i + 1);\n          Serial.print(\": \");\n          Serial.println(storedItems[i]);\n        }\n      } else {\n        Serial.println(\"\ud83d\udced No objects stored\");\n      }\n\n    } else if (input == \"CLEAR_OBJECTS\") {\n      EEPROM.write(NUM_ITEMS_ADDR, 0);\n      numStoredItems = 0;\n      itemsLoaded = false;\n      Serial.println(\"\ud83d\uddd1\ufe0f Object list cleared\");\n\n    } else if (input == \"scan\") {\n      currentMode = \"scan\";\n      unsigned long currentTime = millis();\n      if (lastModeMessage != \"scan\" || (currentTime - lastModeTime) &gt; MODE_MESSAGE_COOLDOWN) {\n        Serial.println(\"\ud83d\udcf8 Scan mode active\");\n        lastModeMessage = \"scan\";\n        lastModeTime = currentTime;\n      }\n\n    } else if (input == \"sort\") {\n      currentMode = \"sort\";\n      unsigned long currentTime = millis();\n      if (itemsLoaded) {\n        if (lastModeMessage != \"sort\" || (currentTime - lastModeTime) &gt; MODE_MESSAGE_COOLDOWN) {\n          Serial.println(\"\u2699\ufe0f Sort mode active\");\n          lastModeMessage = \"sort\";\n          lastModeTime = currentTime;\n        }\n      } else {\n        Serial.println(\"\u274c Cannot sort - no objects loaded\");\n      }\n\n    } else if (input == \"stop\") {\n      currentMode = \"\";\n      Serial.println(\"\u23f9\ufe0f Stopped\");\n      lastModeMessage = \"\";  // Reset so next mode change shows message\n\n    } else if (currentMode == \"sort\" &amp;&amp; itemsLoaded) {\n      // This would be a detected object class from Python\n      handleSorting(input);\n\n    } else {\n      Serial.print(\"\u2753 Unknown command: \");\n      Serial.println(input);\n    }\n  }\n}\n</code></pre>"},{"location":"software_v1/#results","title":"Results","text":"<p>Image shown below, with appearance and some error handling shown:</p> <p></p>"},{"location":"software_v2/","title":"Version 2 (Minimum Viable Software Achieved)","text":""},{"location":"software_v2/#brief-intro-and-technical-details","title":"Brief Intro and Technical Details","text":"<p>Here is a quick overview of the software:</p> <ul> <li>Scanning Mode \u2192 Scans all objects that need to be sorted, with a list of unique objects stored in a .csv file.</li> <li>Sorting Mode \u2192 Sorts the objects in a binary fashion, which means that system looks for a target object in a set number of passes. Refer to video for demo of this.</li> </ul> <p>Here is a quick overview of the key features:</p> <ul> <li>Object Detection \u2192 Done by utilizing webcam and YOLO; users can select a PyTorch model to be used</li> <li>Object Logging \u2192 Stores list of unique objects in csv to be read by Arduino; objects also stored in Arduino's EEPROM in case system powers off</li> <li>User Control \u2192 User dictates when the software does what</li> <li>Arduino Recognition \u2192 Software knows when Arduino is connected and will not start scanning or sorting until then</li> <li>Arduino Echoing \u2192 Arduino send an echo of messages to log to provide updates to user, so that Serial Monitor doesn't have to be open</li> <li>Error Handling \u2192 More information below</li> </ul> <p>Error Handling:</p> <ul> <li>User must select PyTorch model to be able to enter sorting/scanning mode</li> <li>User must connect to an Arduino AND serial communication must be established to be able to enter sorting/scanning mode</li> <li>Sorting can only take place if a model has been selected and a list of objects has been sent</li> <li>etc...</li> </ul> <p>What is missing with this version?</p> <ul> <li>Motors \u2192 Motor selection not 100% finalized at this stage, values will be inputted once motors are finalized</li> </ul> <p>Note that software does not perform 100% perfectly. However, for the purposes of this project, it is enough to be able to proceed, as it performs basic functions up to a standard acceptable for a prototype. The best example of this is the fact that a sorting session has to be started BEFORE actually engaging sorting mode, which will take a bit of getting used to for an end user.</p> <p>How does this compare to the requirements laid out on the milestones page?</p> Requirement from Milestone 3 Status Notes (if needed) Be intuitive to use, and look somewhat polished \u2705 Used customtkinter to achieve a more modern look; mostly polished appearance Allow user to perform basic functions \u2705 System can be used to detect and scan, with framework in place to sort Allow user control over the process \u2705 User dictates entire process, minus the actual object detection At the minimum, recognize when an Arduino is connected via USB to laptop \u2705 System can recognize AND communicate with Arduino Leverage webcam to detect objects \u2705 Utilizes YOLO and webcam to detect objects, with bounding boxes serving as visual confirmation Have some error handling in place and prevent user from going too far out of order \u2705 Error handling talked about above"},{"location":"software_v2/#code","title":"Code","text":"appv2.py<pre><code>import customtkinter as ctk\nfrom tkinter import filedialog, messagebox\nfrom customtkinter import CTkImage\n# import tkinter as tk\n# from tkinter import ttk, filedialog, messagebox\nfrom PIL import Image, ImageTk\nimport cv2\nfrom ultralytics import YOLO\nimport csv\nimport os\nimport serial\nimport threading\nfrom datetime import datetime\nimport serial.tools.list_ports\nimport time\nimport csv\nfrom PIL import ImageDraw, ImageFont\n\n# ---------------------------\n# \u2699\ufe0f CONFIGURATION\n# ---------------------------\nCAMERA_INDEX = 0\nWINDOW_TITLE = \"YOLO-Based Binary Object Sorting System V2\"\nWINDOW_BG_COLOR = \"#1e1e1e\"\nFRAME_RATE_MS = 15\nLOG_DIR = \"logs\"\n\n# ---------------------------\n# \ud83d\udcc1 Ensure Logs Folder Exists\n# ---------------------------\nos.makedirs(LOG_DIR, exist_ok=True)\n\ndef generate_csv_name():\n    now = datetime.now()\n    return f\"{LOG_DIR}/scan_log_{now.strftime('%Y-%m-%d_%H-%M-%S')}.csv\"\n\n# ---------------------------\n# Connection to Arduino\n# ---------------------------\n\ndef find_arduino_port():\n    ports = serial.tools.list_ports.comports()\n    for port in ports:\n        if \"Leonardo\" in port.description or (port.vid == 0x2341 and port.pid == 0x8036):\n            return port.device\n    return None\n\ndef reset_arduino_before_exit(port):\n    try:\n        ser = serial.Serial(port, 1200)\n        ser.close()\n        print(\"\ud83d\uded1 Arduino reset triggered\")\n        time.sleep(2)  # wait for Arduino to fully reset\n    except Exception as e:\n        print(f\"\u26a0\ufe0f Could not reset Arduino: {e}\")\n\ndef get_unique_classes_from_csv(path):\n    unique_classes = set()\n    try:\n        with open(path, newline='') as f:\n            reader = csv.reader(f)\n            for row in reader:\n                if len(row) &gt;= 2:\n                    unique_classes.add(row[1])\n    except Exception as e:\n        print(f\"Error reading CSV: {e}\")\n    return list(unique_classes)\n\ndef send_objects_to_eeprom(item_list, arduino_serial):\n    \"\"\"\n    Send object list to Arduino for EEPROM storage\n    Much simpler than SerialTransfer!\n    \"\"\"\n    try:\n        # Create comma-separated string\n        object_string = \",\".join(item_list[:20])  # Limit to 20 items\n\n        # Send the command\n        command = f\"STORE_OBJECTS:{object_string}\\n\"\n        arduino_serial.write(command.encode())\n\n        print(f\"\u2705 Sent {len(item_list)} objects to Arduino EEPROM\")\n        return True\n\n    except Exception as e:\n        print(f\"\u274c Failed to send objects: {e}\")\n        return False\n\n# ---------------------------\n# \ud83d\uddbc GUI Class\n# ---------------------------\nclass YOLOApp:\n    def __init__(self, root):\n        self.root = root\n        self.root.title(WINDOW_TITLE)\n        self.root.configure(bg_color=WINDOW_BG_COLOR)\n        self.arduino = None\n\n        self.cap = cv2.VideoCapture(CAMERA_INDEX)\n        if not self.cap.isOpened():\n            raise RuntimeError(\"\u274c Cannot open webcam\")\n\n        self.is_running = False\n        self.mode = None  # 'scan' or 'sort'\n        self.csv_file = None\n        self.detected_classes = set()\n        self.model_path = \"\"\n        self.model = None\n        self.arduino_ready_to_sort = False\n\n        # Binary Sorting Algorithm Variables\n        self.sort_classes = []  # List of classes to sort through\n        self.current_sort_index = 0  # Which class we're currently sorting\n        self.current_target_class = None  # The class we're looking for in this pass\n        self.sorting_in_progress = False  # Whether we're actively sorting\n        self.waiting_for_next_pass = False  # Whether we're waiting for user to start next pass\n\n        # Layout frames\n        main_frame = ctk.CTkFrame(root, bg_color=WINDOW_BG_COLOR)\n        main_frame.pack(fill=ctk.BOTH, expand=True)\n\n        left_frame = ctk.CTkFrame(main_frame, bg_color=WINDOW_BG_COLOR)\n        left_frame.pack(side=ctk.LEFT, padx=10, pady=10)\n\n        right_frame = ctk.CTkFrame(main_frame, bg_color=WINDOW_BG_COLOR)\n        right_frame.pack(side=ctk.RIGHT, padx=10, pady=10, fill=ctk.BOTH, expand=True)\n\n        # Video Frame\n        self.video_frame = ctk.CTkLabel(left_frame)\n        self.video_frame.pack()\n\n        # Create a black placeholder with text \"Camera Offline\"\n        placeholder = Image.new(\"RGB\", (640, 480), (0, 0, 0))\n        draw = ImageDraw.Draw(placeholder)\n\n        try:\n            font = ImageFont.truetype(\"arial.ttf\", 36)\n        except:\n            font = ImageFont.load_default()\n\n        text = \"CAMERA OFFLINE\"\n        bbox = draw.textbbox((0, 0), text, font=font)\n        text_width = bbox[2] - bbox[0]\n        text_height = bbox[3] - bbox[1]\n        position = ((640 - text_width) // 2, (480 - text_height) // 2)\n        draw.text(position, text, fill=(200, 200, 200), font=font)\n\n        self.placeholder_img = CTkImage(light_image=placeholder, dark_image=placeholder, size=(640, 480))\n        self.video_frame.configure(image=self.placeholder_img, text=\"\")  # text=\"\" prevents text overlay\n        self.video_frame.imgtk = self.placeholder_img  # Keep a reference\n\n        # Control Buttons\n        btn_frame = ctk.CTkFrame(left_frame, bg_color=WINDOW_BG_COLOR)\n        btn_frame.pack(pady=10)\n\n        self.choose_model_btn = ctk.CTkButton(btn_frame, text=\"Choose PyTorch Model\", command=self.choose_model)\n        self.choose_model_btn.grid(row=0, column=0, padx=5)\n\n        self.arduino_btn = ctk.CTkButton(btn_frame, text=\"Connect to Arduino\", command=self.connect_to_arduino)\n        self.arduino_btn.grid(row=0, column=1, padx=5)\n\n        self.scan_btn = ctk.CTkButton(btn_frame, text=\"\ud83d\udcf8 Start Scanning Mode\", command=self.start_scanning_mode)\n        self.scan_btn.grid(row=0, column=2, padx=5)\n\n        self.sort_btn = ctk.CTkButton(btn_frame, text=\"\u2699\ufe0f Start Sorting Mode\", command=self.start_sorting_mode)\n        self.sort_btn.grid(row=0, column=3, padx=5)\n\n        self.stop_btn = ctk.CTkButton(btn_frame, text=\"\u23f9 Stop\", command=self.stop_detection)\n        self.stop_btn.grid(row=0, column=4, padx=5)\n\n        # Second row of buttons - MERGED FUNCTIONALITY\n        self.list_objects_btn = ctk.CTkButton(btn_frame, text=\"\ud83d\udccb List Stored Objects\", command=self.list_stored_objects)\n        self.list_objects_btn.grid(row=1, column=0, padx=5)\n\n        self.clear_objects_btn = ctk.CTkButton(btn_frame, text=\"\ud83d\uddd1\ufe0f Clear Objects\", command=self.clear_stored_objects)\n        self.clear_objects_btn.grid(row=1, column=1, padx=5)\n\n        # NEW: Merged sorting button that handles everything\n        self.start_sorting_session_btn = ctk.CTkButton(btn_frame, text=\"\ud83d\ude80 Start Sorting Session\", \n                                                   command=self.start_sorting_session)\n        self.start_sorting_session_btn.grid(row=1, column=2, columnspan=2, pady=10, padx=5)\n\n        exit_button = ctk.CTkButton(btn_frame, text=\"Exit\", command=self.exit_app)\n        exit_button.grid(row=1, column=4, padx=5)\n\n        # Third row - Binary Sorting Controls (simplified)\n        sort_control_frame = ctk.CTkFrame(btn_frame, bg_color=WINDOW_BG_COLOR)\n        sort_control_frame.grid(row=2, column=0, columnspan=5, pady=10)\n\n        self.next_pass_btn = ctk.CTkButton(sort_control_frame, text=\"\u27a1\ufe0f Next Pass\", command=self.start_next_pass, state=ctk.DISABLED)\n        self.next_pass_btn.grid(row=0, column=0, padx=5)\n\n        self.finish_sort_btn = ctk.CTkButton(sort_control_frame, text=\"\u2705 Finish Sorting\", command=self.finish_sorting, state=ctk.DISABLED)\n        self.finish_sort_btn.grid(row=0, column=1, padx=5)\n\n        # Sorting Status Display\n        self.sort_status_label = ctk.CTkLabel(\n            sort_control_frame,\n            text=\"Arduino not connected\",\n            text_color=\"red\",\n            fg_color=\"transparent\",\n            bg_color=WINDOW_BG_COLOR,\n            font=(\"Segoe UI\", 10, \"bold\")\n        )\n        self.sort_status_label.grid(row=1, column=0, columnspan=2, pady=5)\n\n        # Output Log\n        self.log_text = ctk.CTkTextbox(\n            right_frame,\n            width=400,         # Increased width\n            height=300,        # Increased height\n            fg_color=\"black\",  # Background color\n            text_color=\"white\",# Fix white-on-white issue\n            wrap=\"word\"\n        )       \n        self.log_text.pack(fill=ctk.BOTH, expand=True, padx=5, pady=5)\n        self.log(\"\ud83d\udfe2 GUI Initialized\")\n\n        # ---------------------------\n        # \ud83c\udfa8 Button Styling\n        # ---------------------------\n        # style = ttk.Style()\n        # style.theme_use(\"default\")\n        # style.configure(\"TButton\", background=\"#444\", foreground=\"white\", padding=6, font=(\"Segoe UI\", 10, \"bold\"))\n        # style.map(\"TButton\", background=[(\"active\", \"#777\")])\n\n    # ---------------------------\n    # \ud83e\uddfe Log Output\n    # ---------------------------\n    def log(self, message):\n        timestamp = datetime.now().strftime(\"[%H:%M:%S]\")\n        self.log_text.insert(ctk.END, f\"{timestamp} {message}\\n\")\n        self.log_text.see(ctk.END)\n\n    # ---------------------------\n    # \ud83d\ude80 NEW: Merged Sorting Session Function\n    # ---------------------------\n    def start_sorting_session(self):\n        \"\"\"\n        Merged function that handles:\n        1. Model validation\n        2. File selection (single dialog)\n        3. Sending objects to Arduino\n        4. Setting up binary sort\n        5. Starting camera/sorting mode\n        \"\"\"\n        # Validation checks\n        if self.model is None:\n            self.log(\"\u274c No model selected. Please choose a PyTorch model first.\")\n            messagebox.showerror(\"Error\", \"Please select a PyTorch model before starting sorting session.\")\n            return\n\n        if self.arduino is None or not self.arduino.is_open:\n            self.log(\"\u274c Arduino not connected. Please connect Arduino first.\")\n            messagebox.showerror(\"Error\", \"Please connect Arduino before starting sorting session.\")\n            return\n\n        # Single file dialog for CSV with detected objects\n        filepath = filedialog.askopenfilename(\n            title=\"Select CSV with detected objects for sorting\",\n            filetypes=[(\"CSV Files\", \"*.csv\")]\n        )\n        if not filepath:\n            self.log(\"\u26a0\ufe0f No file selected - sorting session cancelled\")\n            return\n\n        classes = get_unique_classes_from_csv(filepath)\n        if not classes:\n            self.log(\"\u26a0\ufe0f No valid classes found in CSV\")\n            messagebox.showerror(\"Error\", \"No valid object classes found in the selected CSV file.\")\n            return\n\n        self.log(f\"\ud83d\udcc2 Processing file: {os.path.basename(filepath)}\")\n        self.log(f\"\ud83d\udcca Found {len(classes)} unique classes: {', '.join(classes)}\")\n\n        # Send objects to Arduino EEPROM\n        self.log(f\"\ud83d\udce4 Sending {len(classes)} objects to Arduino EEPROM...\")\n        if not send_objects_to_eeprom(classes, self.arduino):\n            self.log(\"\u274c Failed to send objects to Arduino\")\n            messagebox.showerror(\"Error\", \"Failed to send object list to Arduino.\")\n            return\n\n        self.log(f\"\u2705 Successfully sent objects to Arduino\")\n\n        # Wait for Arduino to confirm it's ready\n        self.log(\"\u23f3 Waiting for Arduino to process objects...\")\n\n        # Setup binary sorting\n        self.sort_classes = classes\n        self.current_sort_index = 0\n        self.current_target_class = self.sort_classes[0] if self.sort_classes else None\n        self.sorting_in_progress = False\n        self.waiting_for_next_pass = False\n        self.arduino_ready_to_sort = True\n\n        self.log(f\"\ud83c\udfaf Binary sort setup complete!\")\n        self.log(f\"\ud83d\udd04 Total passes needed: {len(self.sort_classes)}\")\n\n        # Enable sorting controls\n        self.update_sort_status()\n        self.next_pass_btn.configure(state=ctk.NORMAL)\n        self.finish_sort_btn.configure(state=ctk.NORMAL)\n\n        # Start sorting mode automatically\n        self.start_sorting_mode()\n\n        self.log(\"\ud83d\ude80 Sorting session ready! Click 'Next Pass' to begin first sorting pass.\")\n\n    # ---------------------------\n    # \ud83c\udfaf Binary Sorting Functions (simplified)\n    # ---------------------------\n    def update_sort_status(self):\n        if not self.arduino_ready_to_sort:\n            self.sort_status_label.configure(text=\"\u274c Arduino not ready\", text_color=\"red\")\n            return\n\n        if not self.sort_classes:\n            self.sort_status_label.configure(text=\"\u2705 Ready to start sorting session\", text_color=\"green\")\n            return\n\n        if self.current_sort_index &gt;= len(self.sort_classes):\n            self.sort_status_label.configure(text=\"\ud83c\udf89 All sorting passes complete!\", text_color=\"green\")\n            return\n\n        # Status for in-progress session\n        status = f\"Pass {self.current_sort_index + 1}/{len(self.sort_classes)} - Target: '{self.current_target_class}'\"\n        if self.sorting_in_progress:\n            status += \" (ACTIVE)\"\n        elif self.waiting_for_next_pass:\n            status += \" (WAITING)\"\n        else:\n            status += \" (READY)\"\n\n        self.sort_status_label.configure(text=status, text_color=\"white\")\n\n    def start_next_pass(self):\n        if not self.sort_classes or self.current_sort_index &gt;= len(self.sort_classes):\n            self.log(\"\u2705 All sorting passes completed!\")\n            self.finish_sorting()\n            return\n\n        self.current_target_class = self.sort_classes[self.current_sort_index]\n        self.sorting_in_progress = True\n        self.waiting_for_next_pass = False\n\n        self.log(f\"\u25b6\ufe0f Starting Pass {self.current_sort_index + 1}: Sorting '{self.current_target_class}'\")\n        self.log(f\"\ud83d\udcdd Instructions: '{self.current_target_class}' \u2192 Target pile, All others \u2192 Other pile\")\n\n        # Send the target class to Arduino\n        self.send_to_arduino(f\"SET_TARGET:{self.current_target_class}\")\n\n        self.update_sort_status()\n        self.next_pass_btn.configure(text=\"\u23f8\ufe0f Pause Pass\", command=self.pause_current_pass)\n\n    def pause_current_pass(self):\n        if self.sorting_in_progress:\n            self.sorting_in_progress = False\n            self.waiting_for_next_pass = True\n            self.current_sort_index += 1\n\n            self.log(f\"\u23f8\ufe0f Pass paused. Ready for next pass.\")\n\n            if self.current_sort_index &lt; len(self.sort_classes):\n                self.log(f\"\ud83d\udccb Next pass will sort: '{self.sort_classes[self.current_sort_index]}'\")\n                self.next_pass_btn.configure(text=\"\u27a1\ufe0f Next Pass\", command=self.start_next_pass)\n            else:\n                self.log(\"\ud83c\udf89 All passes completed!\")\n                self.next_pass_btn.configure(state=ctk.DISABLED)\n\n            self.update_sort_status()\n            self.send_to_arduino(\"PAUSE_SORT\")\n\n    def finish_sorting(self):\n        self.sorting_in_progress = False\n        self.waiting_for_next_pass = False\n        self.current_sort_index = 0\n        self.sort_classes = []\n        self.current_target_class = None\n\n        self.log(\"\u2705 Sorting session finished\")\n        self.update_sort_status()\n\n        self.next_pass_btn.configure(text=\"\u27a1\ufe0f Next Pass\", command=self.start_next_pass, state=ctk.DISABLED)\n        self.finish_sort_btn.configure(state=ctk.DISABLED)\n\n        self.send_to_arduino(\"FINISH_SORT\")\n\n    # ---------------------------\n    # \ud83d\udea6 MODE SWITCHING\n    # ---------------------------\n    def start_scanning_mode(self):\n        if self.mode == \"scan\":\n            self.stop_detection()\n            return\n\n        if self.model is None:\n            self.log(\"\u26a0\ufe0f No model selected\")\n            return\n        if self.arduino is None or not self.arduino.is_open:\n            self.log(\"\u26a0\ufe0f Arduino not connected\")\n            return\n\n        self.stop_detection()\n        self.mode = \"scan\"\n        self.scan_btn.configure(text=\"\u23f9 Stop Scanning Mode\", state=ctk.NORMAL)\n        self.sort_btn.configure(state=ctk.DISABLED)\n        self.csv_file = generate_csv_name()\n        self.detected_classes.clear()\n        self.log(f\"\ud83d\udcc4 Logging to: {self.csv_file}\")\n        self.is_running = True\n        self.update_frame()\n\n    def start_sorting_mode(self):\n        if self.mode == \"sort\":\n            self.stop_detection()\n            return\n        if self.model is None:\n            self.log(\"\u26a0\ufe0f No model selected\")\n            return\n        if self.arduino is None or not self.arduino.is_open:\n            self.log(\"\u26a0\ufe0f Arduino not connected\")\n            return\n        if not self.arduino_ready_to_sort:\n            self.log(\"\u274c Arduino is not ready. Start sorting session first.\")\n            return\n        if not self.sort_classes:\n            self.log(\"\u274c No sorting session active. Use 'Start Sorting Session' first!\")\n            return\n\n        self.stop_detection()\n        self.mode = \"sort\"\n        self.sort_btn.configure(text=\"\u23f9 Stop Sorting Mode\", state=ctk.NORMAL)\n        self.scan_btn.configure(state=ctk.DISABLED)\n        self.log(\"\u2699\ufe0f Sorting mode active\")\n        self.is_running = True\n        self.update_frame()\n\n    def stop_detection(self):\n        self.is_running = False\n        was_sorting = (self.mode == \"sort\")\n        self.mode = None\n        self.video_frame.configure(image=self.placeholder_img)\n        self.video_frame.imgtk = self.placeholder_img\n        self.scan_btn.configure(text=\"\ud83d\udcf8 Start Scanning Mode\", state=ctk.NORMAL)\n        self.sort_btn.configure(text=\"\u2699\ufe0f Start Sorting Mode\", state=ctk.NORMAL)\n\n        # Send stop command to Arduino\n        self.send_to_arduino(\"stop\")\n\n        if was_sorting:\n            self.log(\"\ud83d\uded1 Detection stopped - Sorting mode disabled\")\n        else:\n            self.log(\"\ud83d\uded1 Detection stopped\")\n\n    def choose_model(self):\n        if self.is_running:\n            self.log(\"\u26a0\ufe0f Stop detection before loading a new model\")\n            return\n        path = filedialog.askopenfilename(filetypes=[(\"PyTorch Model\", \"*.pt\")])\n        if path:\n            self.model_path = path\n            self.model = YOLO(self.model_path)\n            self.log(f\"\u2705 Model loaded: {self.model_path}\")\n\n    # ---------------------------\n    # \ud83d\udd01 Frame Processing\n    # ---------------------------\n    def update_frame(self):\n        if not self.is_running:\n            return\n\n        ret, frame = self.cap.read()\n        if not ret:\n            self.log(\"\u274c Failed to grab frame - stopping detection\")\n            self.stop_detection()\n            return\n\n        results = self.model(frame)[0]\n        annotated = results.plot()\n\n        if self.mode == \"scan\":\n            self.handle_scanning_mode(results)\n        elif self.mode == \"sort\":\n            self.handle_sorting_mode(results)\n\n        rgb_frame = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n        img = Image.fromarray(rgb_frame)\n        img_size = img.size  # This returns (width, height)\n        ctk_img = CTkImage(light_image=img, dark_image=img, size=img_size)  # dynamic size\n        self.video_frame.imgtk = ctk_img\n        self.video_frame.configure(image=ctk_img, text=\"\")\n\n        self.root.after(FRAME_RATE_MS, self.update_frame)\n\n    # ---------------------------\n    # \ud83d\udcf8 Scanning Mode Logic\n    # ---------------------------\n    def handle_scanning_mode(self, results):\n        self.send_to_arduino(\"scan\")\n        for box in results.boxes:\n            cls_id = int(box.cls[0])\n            class_name = self.model.names[cls_id]\n            if class_name not in self.detected_classes:\n                self.detected_classes.add(class_name)\n                with open(self.csv_file, 'a', newline='') as f:\n                    writer = csv.writer(f)\n                    writer.writerow([datetime.now().isoformat(), class_name])\n                self.log(f\"\ud83d\udcdd Logged: {class_name}\")\n\n    # ---------------------------\n    # \u2699\ufe0f Enhanced Sorting Mode Logic\n    # ---------------------------\n    def handle_sorting_mode(self, results):\n        if not self.sorting_in_progress or not self.current_target_class:\n            return\n\n        self.send_to_arduino(\"sort\")\n\n        # Process all detected objects\n        for box in results.boxes:\n            cls_id = int(box.cls[0])\n            class_name = self.model.names[cls_id]\n\n            if class_name == self.current_target_class:\n                self.log(f\"\ud83c\udfaf TARGET FOUND: {class_name} \u2192 Target pile\")\n                self.send_to_arduino(f\"SORT_TARGET:{class_name}\")\n            else:\n                self.log(f\"\ud83d\udce6 OTHER: {class_name} \u2192 Other pile\")\n                self.send_to_arduino(f\"SORT_OTHER:{class_name}\")\n\n            # Only process the first detection to avoid spam\n            break\n\n    # ---------------------------\n    # \ud83d\udd0c Arduino Communication\n    # ---------------------------\n\n    def connect_to_arduino(self):\n        port = find_arduino_port()\n        self.update_sort_status()\n        if port:\n            try:\n                self.arduino = serial.Serial(port, 9600, timeout=2)\n                self.log(f\"\ud83d\udfe1 Connecting to Arduino on {port}...\")\n\n                time.sleep(2)  # Allow time for Arduino to reset and send handshake\n\n                # Wait for \"READY\"\n                start_time = time.time()\n                ready_line = \"\"\n                while time.time() - start_time &lt; 5:\n                    if self.arduino.in_waiting &gt; 0:\n                        ready_line = self.arduino.readline().decode().strip()\n                        if ready_line == \"READY\":\n                            break\n                        elif ready_line:  # Any other message from Arduino\n                            self.log(f\"Arduino: {ready_line}\")\n\n                if ready_line == \"READY\":\n                    self.log(\"\u2705 Arduino is ready!\")\n                    self.arduino_btn.configure(text=\"Arduino Connected!\", state=ctk.DISABLED)\n\n                    # Start listening thread for Arduino messages\n                    self.start_arduino_listener()\n                else:\n                    self.log(f\"\u274c Unexpected handshake message: {ready_line}\")\n            except serial.SerialException as e:\n                self.log(f\"\u274c Connection Failed: {str(e)}\")\n        else:\n            self.log(\"\u26a0\ufe0f No Arduino found!\")\n\n    def start_arduino_listener(self):\n        \"\"\"Start a background thread to listen for Arduino messages\"\"\"\n        def listen():\n            while self.arduino and self.arduino.is_open:\n                try:\n                    if self.arduino.in_waiting &gt; 0:\n                        message = self.arduino.readline().decode().strip()\n                        if message:\n                            if message == \"READY_TO_SORT\":\n                                self.arduino_ready_to_sort = True\n                                self.log(\"\ud83d\udfe2 Arduino ready to sort!\")\n                            else:\n                                self.log(f\"Arduino: {message}\")\n                    time.sleep(0.1)\n                except Exception as e:\n                    if self.arduino and self.arduino.is_open:\n                        self.log(f\"Error reading from Arduino: {e}\")\n                    break\n\n        listener_thread = threading.Thread(target=listen, daemon=True)\n        listener_thread.start()\n\n    def send_to_arduino(self, message):\n        try:\n            if self.arduino and self.arduino.is_open:\n                self.arduino.write((message + \"\\n\").encode())\n        except Exception as e:\n            self.log(f\"\u274c Error sending to Arduino: {e}\")\n\n    def list_stored_objects(self):\n        \"\"\"Ask Arduino to list stored objects\"\"\"\n        if self.arduino and self.arduino.is_open:\n            self.send_to_arduino(\"LIST_OBJECTS\")\n        else:\n            self.log(\"\u26a0\ufe0f Arduino not connected\")\n\n    def clear_stored_objects(self):\n        \"\"\"Clear objects from Arduino EEPROM\"\"\"\n        if self.arduino and self.arduino.is_open:\n            self.send_to_arduino(\"CLEAR_OBJECTS\")\n            self.arduino_ready_to_sort = False\n            self.log(\"\ud83d\uddd1\ufe0f Cleared stored objects\")\n        else:\n            self.log(\"\u26a0\ufe0f Arduino not connected\")\n        self.update_sort_status()\n\n    def exit_app(self):\n        if self.arduino and self.arduino.is_open:\n            port = self.arduino.port\n            self.arduino.close()\n            self.clear_stored_objects()\n            reset_arduino_before_exit(port)\n        self.root.destroy()\n\n# ---------------------------\n# \ud83d\ude80 Run GUI\n# ---------------------------\nif __name__ == \"__main__\":\n    root = ctk.CTk()\n    app = YOLOApp(root)\n    root.mainloop()\n\n    if app.cap.isOpened():\n        app.cap.release()\n    cv2.destroyAllWindows()\n</code></pre> arduino_v2.ino<pre><code>#include &lt;Arduino.h&gt;\n#include &lt;EEPROM.h&gt;\n\n// ===== MOTOR CONTROL INCLUDES =====\n// TODO: Add your servo/stepper motor library includes here\n// Example: #include &lt;Servo.h&gt;\n// Example: #include &lt;Stepper.h&gt;\n\n// ===== MOTOR CONTROL OBJECTS =====\n// TODO: Initialize your motor control objects here\n// Example: Servo sortingServo;\n// Example: Stepper conveyorMotor(stepsPerRevolution, motorPin1, motorPin2, motorPin3, motorPin4);\n\n// ===== MOTOR CONTROL PINS =====\n// TODO: Define your motor control pins here\n// Example: const int SERVO_PIN = 9;\n// Example: const int CONVEYOR_ENABLE_PIN = 8;\n// Example: const int CONVEYOR_DIR_PIN = 7;\n// Example: const int CONVEYOR_STEP_PIN = 6;\n\n// Storage constants\nconst uint8_t MAX_ITEMS = 30;\nconst uint8_t MAX_STR_LEN = 50;\nconst int EEPROM_START_ADDR = 0;\nconst int NUM_ITEMS_ADDR = 0;\nconst int ITEMS_START_ADDR = 1;\n\n// Object storage\nString storedItems[MAX_ITEMS];\nuint8_t numStoredItems = 0;\n\n// Mode tracking\nString currentMode = \"\";\nString lastModeMessage = \"\";\nunsigned long lastModeTime = 0;\nconst unsigned long MODE_MESSAGE_COOLDOWN = 5000; // 5 seconds between mode messages\nbool itemsLoaded = false;\n\n// Binary Sorting Variables\nString currentTargetClass = \"\";\nbool binarySortActive = false;\nString lastSortedItem = \"\";\nunsigned long lastSortTime = 0;\nconst unsigned long SORT_COOLDOWN = 2000; // 2 seconds between same item sorts\n\n// ===== MOTOR CONTROL POSITIONS =====\n// TODO: Define your sorting positions/angles here\n// Example: const int TARGET_POSITION = 90;    // Servo angle for target pile\n// Example: const int OTHER_POSITION = -90;    // Servo angle for other pile\n// Example: const int CENTER_POSITION = 0;     // Servo center/neutral position\n// Example: const int CONVEYOR_SPEED = 100;    // Conveyor belt speed\n\n// ===== FUNCTION DECLARATIONS =====\nvoid performTargetSortAction();\nvoid performOtherSortAction();\nvoid handleBinarySortTarget(String itemClass);\nvoid handleBinarySortOther(String itemClass);\nvoid processObjectList(String objectListString);\nvoid storeObjectsInEEPROM(String objects[], uint8_t count);\nvoid loadObjectsFromEEPROM();\n\nvoid storeObjectsInEEPROM(String objects[], uint8_t count) {\n  // Store number of items first\n  EEPROM.write(NUM_ITEMS_ADDR, count);\n\n  int addr = ITEMS_START_ADDR;\n  for (uint8_t i = 0; i &lt; count; i++) {\n    String item = objects[i];\n\n    // Store length of string\n    uint8_t len = min(item.length(), (unsigned int)(MAX_STR_LEN - 1));\n    EEPROM.write(addr, len);\n    addr++;\n\n    // Store the string characters\n    for (uint8_t j = 0; j &lt; len; j++) {\n      EEPROM.write(addr, item[j]);\n      addr++;\n    }\n\n    // Fill remaining space with zeros\n    for (uint8_t j = len; j &lt; MAX_STR_LEN - 1; j++) {\n      EEPROM.write(addr, 0);\n      addr++;\n    }\n  }\n\n  Serial.println(\"\u2705 Objects stored in EEPROM\");\n}\n\nvoid loadObjectsFromEEPROM() {\n  numStoredItems = EEPROM.read(NUM_ITEMS_ADDR);\n\n  // Sanity check\n  if (numStoredItems &gt; MAX_ITEMS) {\n    numStoredItems = 0;\n    Serial.println(\"\u26a0\ufe0f Invalid EEPROM data, resetting\");\n    return;\n  }\n\n  if (numStoredItems == 0) {\n    Serial.println(\"\ud83d\udced No objects stored in EEPROM\");\n    return;\n  }\n\n  int addr = ITEMS_START_ADDR;\n  for (uint8_t i = 0; i &lt; numStoredItems; i++) {\n    uint8_t len = EEPROM.read(addr);\n    addr++;\n\n    if (len &gt;= MAX_STR_LEN) len = 0; // Corrupted data\n\n    String item = \"\";\n    for (uint8_t j = 0; j &lt; len; j++) {\n      char c = EEPROM.read(addr);\n      if (c != 0) item += c;\n      addr++;\n    }\n\n    // Skip remaining bytes for this item\n    addr += (MAX_STR_LEN - 1 - len);\n    storedItems[i] = item;\n  }\n\n  if (numStoredItems &gt; 0) {\n    itemsLoaded = true;\n    Serial.println(\"\ud83d\udce5 Objects loaded from EEPROM:\");\n    for (uint8_t i = 0; i &lt; numStoredItems; i++) {\n      Serial.print(\" \");\n      Serial.println(storedItems[i]);\n    }\n    Serial.println(\"READY_TO_SORT\");\n  }\n}\n\nvoid handleBinarySortTarget(String itemClass) {\n  unsigned long currentTime = millis();\n\n  // Only process if it's a different item or enough time has passed\n  if (itemClass != lastSortedItem || (currentTime - lastSortTime) &gt; SORT_COOLDOWN) {\n    Serial.print(\"\ud83c\udfaf TARGET SORT: \");\n    Serial.println(itemClass);\n\n    // Perform target sorting action\n    performTargetSortAction();\n\n    lastSortedItem = itemClass;\n    lastSortTime = currentTime;\n  }\n}\n\nvoid handleBinarySortOther(String itemClass) {\n  unsigned long currentTime = millis();\n\n  // Only process if it's a different item or enough time has passed  \n  if (itemClass != lastSortedItem || (currentTime - lastSortTime) &gt; SORT_COOLDOWN) {\n    Serial.print(\"\ud83d\udce6 OTHER SORT: \");\n    Serial.println(itemClass);\n\n    // Perform other sorting action\n    performOtherSortAction();\n\n    lastSortedItem = itemClass;\n    lastSortTime = currentTime;\n  }\n}\n\nvoid performTargetSortAction() {\n  // ===== TARGET PILE MOTOR CONTROL =====\n  // TODO: Add your motor control code here for moving items to target pile\n\n  Serial.println(\"\u2192 Moving to TARGET pile\");\n\n  // Example servo control:\n  // sortingServo.write(TARGET_POSITION);  // Move to target pile position\n  // delay(1000);                          // Wait for movement\n  // sortingServo.write(CENTER_POSITION);  // Return to center\n\n  // Example stepper motor control:\n  // digitalWrite(CONVEYOR_DIR_PIN, HIGH); // Set direction to target pile\n  // for(int i = 0; i &lt; STEPS_TO_TARGET; i++) {\n  //   digitalWrite(CONVEYOR_STEP_PIN, HIGH);\n  //   delayMicroseconds(STEP_DELAY);\n  //   digitalWrite(CONVEYOR_STEP_PIN, LOW);\n  //   delayMicroseconds(STEP_DELAY);\n  // }\n\n  // Example pneumatic actuator control:\n  // digitalWrite(PNEUMATIC_TARGET_PIN, HIGH);  // Activate target actuator\n  // delay(500);                                // Hold position\n  // digitalWrite(PNEUMATIC_TARGET_PIN, LOW);   // Release\n\n  // TODO: Add any additional mechanical actions needed for target sorting\n  // Examples: conveyor belt control, pusher mechanisms, etc.\n}\n\nvoid performOtherSortAction() {\n  // ===== OTHER PILE MOTOR CONTROL =====\n  // TODO: Add your motor control code here for moving items to other pile\n\n  Serial.println(\"\u2192 Moving to OTHER pile\");\n\n  // Example servo control:\n  // sortingServo.write(OTHER_POSITION);   // Move to other pile position  \n  // delay(1000);                          // Wait for movement\n  // sortingServo.write(CENTER_POSITION);  // Return to center\n\n  // Example stepper motor control:\n  // digitalWrite(CONVEYOR_DIR_PIN, LOW);  // Set direction to other pile\n  // for(int i = 0; i &lt; STEPS_TO_OTHER; i++) {\n  //   digitalWrite(CONVEYOR_STEP_PIN, HIGH);\n  //   delayMicroseconds(STEP_DELAY);\n  //   digitalWrite(CONVEYOR_STEP_PIN, LOW);\n  //   delayMicroseconds(STEP_DELAY);\n  // }\n\n  // Example pneumatic actuator control:\n  // digitalWrite(PNEUMATIC_OTHER_PIN, HIGH);   // Activate other actuator\n  // delay(500);                                // Hold position\n  // digitalWrite(PNEUMATIC_OTHER_PIN, LOW);    // Release\n\n  // TODO: Add any additional mechanical actions needed for other sorting\n  // Examples: conveyor belt control, pusher mechanisms, etc.\n}\n\nvoid processObjectList(String objectListString) {\n  // Parse comma-separated string\n  String tempItems[MAX_ITEMS];\n  uint8_t count = 0;\n\n  int startIdx = 0;\n  int commaIdx = objectListString.indexOf(',');\n\n  while (commaIdx != -1 &amp;&amp; count &lt; MAX_ITEMS) {\n    tempItems[count] = objectListString.substring(startIdx, commaIdx);\n    tempItems[count].trim();\n    count++;\n    startIdx = commaIdx + 1;\n    commaIdx = objectListString.indexOf(',', startIdx);\n  }\n\n  // Get the last item (or the only item if no commas)\n  if (startIdx &lt; objectListString.length() &amp;&amp; count &lt; MAX_ITEMS) {\n    tempItems[count] = objectListString.substring(startIdx);\n    tempItems[count].trim();\n    count++;\n  }\n\n  if (count &gt; 0) {\n    storeObjectsInEEPROM(tempItems, count);\n    loadObjectsFromEEPROM(); // Reload to confirm storage worked\n  }\n}\n\nvoid setup() {\n  Serial.begin(9600);\n  while (!Serial);\n  delay(1000);\n\n  Serial.println(\"\ud83e\udd16 Arduino Binary Object Sorter Starting...\");\n\n  // ===== MOTOR CONTROL INITIALIZATION =====\n  // TODO: Initialize your motors and actuators here\n\n  // Example servo initialization:\n  // sortingServo.attach(SERVO_PIN);\n  // sortingServo.write(CENTER_POSITION);  // Start at center position\n\n  // Example stepper motor initialization:\n  // pinMode(CONVEYOR_ENABLE_PIN, OUTPUT);\n  // pinMode(CONVEYOR_DIR_PIN, OUTPUT);\n  // pinMode(CONVEYOR_STEP_PIN, OUTPUT);\n  // digitalWrite(CONVEYOR_ENABLE_PIN, HIGH);  // Enable stepper driver\n\n  // Example pneumatic initialization:\n  // pinMode(PNEUMATIC_TARGET_PIN, OUTPUT);\n  // pinMode(PNEUMATIC_OTHER_PIN, OUTPUT);\n  // digitalWrite(PNEUMATIC_TARGET_PIN, LOW);  // Ensure actuators start retracted\n  // digitalWrite(PNEUMATIC_OTHER_PIN, LOW);\n\n  // TODO: Add any sensor initialization here\n  // Example: proximity sensors, limit switches, etc.\n\n  // Try to load existing objects from EEPROM\n  loadObjectsFromEEPROM();\n\n  Serial.println(\"READY\");\n}\n\nvoid loop() {\n  if (Serial.available()) {\n    String input = Serial.readStringUntil('\\n');\n    input.trim();\n\n    if (input.startsWith(\"STORE_OBJECTS:\")) {\n      // Extract the object list from the command\n      String objectList = input.substring(14); // Remove \"STORE_OBJECTS:\" prefix\n      Serial.print(\"\ud83d\udcdd Storing objects: \");\n      Serial.println(objectList);\n      processObjectList(objectList);\n\n    } else if (input.startsWith(\"SET_TARGET:\")) {\n      // Set the target class for binary sorting\n      currentTargetClass = input.substring(11); // Remove \"SET_TARGET:\" prefix\n      binarySortActive = true;\n      Serial.print(\"\ud83c\udfaf Target class set to: \");\n      Serial.println(currentTargetClass);\n      Serial.println(\"\ud83d\udd04 Binary sort mode activated\");\n\n      // ===== MOTOR CONTROL: SORTING SESSION START =====\n      // TODO: Add any initialization needed when starting a new sorting session\n      // Examples: move servos to ready position, start conveyor belt, etc.\n\n    } else if (input.startsWith(\"SORT_TARGET:\")) {\n      // Handle target object detection\n      if (binarySortActive) {\n        String detectedClass = input.substring(12); // Remove \"SORT_TARGET:\" prefix\n        handleBinarySortTarget(detectedClass);\n      }\n\n    } else if (input.startsWith(\"SORT_OTHER:\")) {\n      // Handle non-target object detection  \n      if (binarySortActive) {\n        String detectedClass = input.substring(11); // Remove \"SORT_OTHER:\" prefix\n        handleBinarySortOther(detectedClass);\n      }\n\n    } else if (input == \"PAUSE_SORT\") {\n      Serial.println(\"\u23f8\ufe0f Sorting pass paused\");\n\n      // ===== MOTOR CONTROL: PAUSE ACTIONS =====\n      // TODO: Add pause actions here\n      // Examples: stop conveyor belt, move servos to safe position, etc.\n\n      currentTargetClass = \"\";\n      lastSortedItem = \"\"; // Reset to allow immediate sorting when resumed\n\n    } else if (input == \"FINISH_SORT\") {\n      binarySortActive = false;\n      currentTargetClass = \"\";\n      lastSortedItem = \"\";\n      Serial.println(\"\u2705 Binary sorting session finished\");\n\n      // ===== MOTOR CONTROL: SESSION END =====\n      // TODO: Add cleanup actions here\n      // Examples: return all servos to home position, stop conveyor, etc.\n\n    } else if (input == \"LOAD_OBJECTS\") {\n      loadObjectsFromEEPROM();\n\n    } else if (input == \"LIST_OBJECTS\") {\n      if (itemsLoaded &amp;&amp; numStoredItems &gt; 0) {\n        Serial.println(\"\ud83d\udccb Current object list:\");\n        for (uint8_t i = 0; i &lt; numStoredItems; i++) {\n          Serial.print(\" \");\n          Serial.print(i + 1);\n          Serial.print(\": \");\n          Serial.println(storedItems[i]);\n        }\n        if (binarySortActive) {\n          Serial.print(\"\ud83c\udfaf Current target: \");\n          Serial.println(currentTargetClass);\n        }\n      } else {\n        Serial.println(\"\ud83d\udced No objects stored\");\n      }\n\n    } else if (input == \"CLEAR_OBJECTS\") {\n      EEPROM.write(NUM_ITEMS_ADDR, 0);\n      numStoredItems = 0;\n      itemsLoaded = false;\n      binarySortActive = false;\n      currentTargetClass = \"\";\n      Serial.println(\"\ud83d\uddd1\ufe0f Object list cleared\");\n\n    } else if (input == \"scan\") {\n      currentMode = \"scan\";\n      unsigned long currentTime = millis();\n      if (lastModeMessage != \"scan\" || (currentTime - lastModeTime) &gt; MODE_MESSAGE_COOLDOWN) {\n        Serial.println(\"\ud83d\udcf8 Scan mode active\");\n        lastModeMessage = \"scan\";\n        lastModeTime = currentTime;\n      }\n\n      // ===== MOTOR CONTROL: SCAN MODE =====\n      // TODO: Add scan mode motor actions here\n      // Examples: position camera, start conveyor for scanning, etc.\n\n    } else if (input == \"sort\") {\n      currentMode = \"sort\";\n      unsigned long currentTime = millis();\n      if (itemsLoaded) {\n        if (lastModeMessage != \"sort\" || (currentTime - lastModeTime) &gt; MODE_MESSAGE_COOLDOWN) {\n          if (binarySortActive) {\n            Serial.println(\"\u2699\ufe0f Binary sort mode active\");\n          } else {\n            Serial.println(\"\u274c Binary sort not activated - use SET_TARGET first\");\n          }\n          lastModeMessage = \"sort\";\n          lastModeTime = currentTime;\n        }\n      } else {\n        Serial.println(\"\u274c Cannot sort - no objects loaded\");\n      }\n\n      // ===== MOTOR CONTROL: SORT MODE =====\n      // TODO: Add sort mode motor actions here  \n      // Examples: start conveyor belt, position sorting mechanisms, etc.\n\n    } else if (input == \"stop\") {\n      currentMode = \"\";\n      Serial.println(\"\u23f9\ufe0f Stopped\");\n      lastModeMessage = \"\"; // Reset so next mode change shows message\n      lastSortedItem = \"\"; // Reset sort cooldown\n\n      // ===== MOTOR CONTROL: STOP ALL =====\n      // TODO: Add emergency stop actions here\n      // Examples: stop all motors, return servos to safe positions, etc.\n\n    } else {\n      Serial.print(\"\u2753 Unknown command: \");\n      Serial.println(input);\n    }\n  }\n\n  // ===== MOTOR CONTROL: MAIN LOOP TASKS =====\n  // TODO: Add any continuous motor control tasks here\n  // Examples: sensor monitoring, position feedback, safety checks, etc.\n}\n</code></pre>"},{"location":"software_v2/#results","title":"Results","text":"<p>Note that there is a part in the video where a message pops up to show that the Arduino is not connected. This is another form of error checking that occurs because the Arduino was not plugged in at that point.</p>"},{"location":"software_v2/#conclusion","title":"Conclusion","text":"<p>Overall, it works as expected, and theoretically, any changes that have to be made will now be towards integrating the prototype, Arduino, and user interface. </p>"},{"location":"software_v3/","title":"Version 3 (Final Software)","text":""},{"location":"software_v3/#version-2-vs-version-3","title":"Version 2 vs Version 3","text":"<p>While the minimum software was already achieved in Version 2, there are some better features that can be included to make the prototype more robust:</p> Improvement Scope of Improvement from Version 2 (V2) to Version 3 (V3) More modernized appearance While V2 used customtkinter, it did not take full advantage of what customtkinter can do. The buttons are more modern but that's about all. In addition, V2 had a bunch of empty space that served no purpose.  In V3, I aim to modernize the appearance further while also making better use of the space available. Better button placement In V2, all buttons were laid out at the bottom, and some buttons did not serve much of a purpose beyond being used only once.  In V3, I aim to make better use of the buttons by moving them around and including menus to ensure that buttons that don't need to be accessible are hidden away once they are used. Statistic Tracking In V2, there was no way to track statistics.  In V3, I aim to add statistic tracking so that final results can be quantified. Some of the important stats include: how much of each object, how many objects, how long sorting takes, overall throughput, etc. This data can also be exported to compare against other sorting sessions. Object Sorting Adjustments In V2, there was no way to change the order of objects selected and no way to select a few of the objects to sort. What if someone had a bunch of items and were looking for a particular type of item and didn't care about the rest?  In V3, this edge case will be handled to allow more customizable usage. Logs Hidden Away In V2, the logs were visible to the end user. This was great to see if everything was functioning alright. However, that has potential to overwhelm the user.  In V3, the logs will be tucked away in a separate window to avoid overwhelming the user. Cameras In V2, the user was limited to using the in built webcam, as at the time, I had envisioned using the laptop's webcam. However, now that I am set on using an external camera, the system must check for all available cameras.  In V3, the system will scan for all cameras upon bootup and then the user can select the one they want. Scanning Mode Replacement In V2, the inclusion of scanning mode was there so that the system would scan through all objects. However, this has potential to slow workflow down by a lot, especially when there can be as much as 100 objects to sort.  In V3, the user will be able to upload an image with all unique classes of objects that gets scanned by YOLO to inform the system of what is expected to be sorted. This will speed up the workflow and also give the user more information about whether the objects are correctly sorted or not. <p>Note, to avoid being redundant, I won't compare Version 3 against the minimum benchmark required for the software, as this version satisfies all major requirements that were needed. This version goes beyond functional and improves on the usability while adding some 'nice to have' features.</p>"},{"location":"software_v3/#code","title":"Code","text":"<p>The complete source code is provided below in collapsible sections. Click to expand each section to view the full implementation.</p>"},{"location":"software_v3/#python-app","title":"Python App","text":"View Full Python Code (Click to Expand) appv3.py<pre><code>import customtkinter as ctk\nfrom tkinter import filedialog, messagebox\nfrom customtkinter import CTkImage\nfrom PIL import Image, ImageDraw, ImageFont\nimport cv2\nfrom ultralytics import YOLO\nimport csv\nimport os\nimport serial\nimport threading\nfrom datetime import datetime\nimport serial.tools.list_ports\nimport time\nimport pandas as pd\nfrom collections import defaultdict\nimport json\n\n# File for pass tracking\nPASS_DATA_FILE = \"logs/pass_data.json\"\n\n# ---------------------------\n# \ud83c\udfaf Window Centering Helper Function\n# ---------------------------\ndef center_window(window, width, height):\n    \"\"\"Calculate geometry string to center a window on screen\"\"\"\n    # Force the window to update and render\n    window.update()\n\n    # Get actual screen dimensions\n    screen_width = window.winfo_screenwidth()\n    screen_height = window.winfo_screenheight()\n\n    # Calculate center position\n    x = max(0, (screen_width - width) // 2)\n    y = max(0, (screen_height - height) // 2)\n\n    return f\"{width}x{height}+{x}+{y}\"\n\n# ---------------------------\n# \ud83c\udfac Splash Screen / Loading Window\n# ---------------------------\nclass SplashScreen(ctk.CTkToplevel):\n    def __init__(self, parent):\n        super().__init__(parent)\n        self.title(\"\")\n\n        # Remove window decorations\n        self.overrideredirect(True)\n\n        # Set initial size and position\n        width, height = 400, 250\n        self.geometry(f\"{width}x{height}\")\n\n        # Force multiple updates to ensure proper positioning\n        self.update()\n        self.update_idletasks()\n\n        # Now center it\n        screen_width = self.winfo_screenwidth()\n        screen_height = self.winfo_screenheight()\n        x = (screen_width - width) // 2\n        y = (screen_height - height) // 2\n\n        # Apply centered position\n        self.geometry(f\"{width}x{height}+{x}+{y}\")\n        self.update()\n\n        # Make it stay on top\n        self.lift()\n        self.attributes('-topmost', True)\n\n        # Main frame\n        main_frame = ctk.CTkFrame(self, fg_color=CARD_BG, corner_radius=15)\n        main_frame.pack(fill=ctk.BOTH, expand=True, padx=2, pady=2)\n\n        # Title\n        title = ctk.CTkLabel(main_frame, text=\"\ud83e\udd16 YOLO Binary Object Sorter\",\n                            font=(\"Segoe UI\", 24, \"bold\"), text_color=ACCENT_COLOR)\n        title.pack(pady=(30, 10))\n\n        subtitle = ctk.CTkLabel(main_frame, text=\"Intelligent Sorting System\",\n                            font=(\"Segoe UI\", 12), text_color=TEXT_COLOR)\n        subtitle.pack(pady=(0, 30))\n\n        # Progress bar\n        self.progress = ctk.CTkProgressBar(main_frame, width=300, \n                                        progress_color=ACCENT_COLOR)\n        self.progress.pack(pady=20)\n        self.progress.set(0)\n\n        # Status label\n        self.status_label = ctk.CTkLabel(main_frame, text=\"Initializing...\",\n                                        font=(\"Segoe UI\", 11), text_color=TEXT_COLOR)\n        self.status_label.pack(pady=10)\n\n    def update_progress(self, value, status):\n        self.progress.set(value)\n        self.status_label.configure(text=status)\n        self.update()\n\n    def close(self):\n        self.destroy()\n\n# ---------------------------\n# \ud83d\udccb Log Window (Separate)\n# ---------------------------\nclass LogWindow(ctk.CTkToplevel):\n    def __init__(self, parent):\n        super().__init__(parent)\n        self.title(\"System Logs\")\n        self.geometry(\"800x400\")\n\n        # Don't destroy on close, just hide\n        self.protocol(\"WM_DELETE_WINDOW\", self.hide_window)\n\n        main_frame = ctk.CTkFrame(self, fg_color=CARD_BG)\n        main_frame.pack(fill=ctk.BOTH, expand=True, padx=10, pady=10)\n\n        # Header\n        header = ctk.CTkFrame(main_frame, fg_color=CARD_BG)\n        header.pack(fill=ctk.X, pady=(0, 10))\n\n        title = ctk.CTkLabel(header, text=\"\ud83d\udccb System Logs\",\n                            font=(\"Segoe UI\", 18, \"bold\"), text_color=ACCENT_COLOR)\n        title.pack(side=ctk.LEFT)\n\n        clear_btn = ctk.CTkButton(header, text=\"Clear Logs\", width=100,\n                                command=self.clear_logs)\n        clear_btn.pack(side=ctk.RIGHT, padx=5)\n\n        # Log text area\n        self.log_text = ctk.CTkTextbox(main_frame, fg_color=WINDOW_BG,\n                                    text_color=TEXT_COLOR, wrap=\"word\")\n        self.log_text.pack(fill=ctk.BOTH, expand=True)\n\n        # Start hidden\n        self.withdraw()\n\n    def add_log(self, message):\n        self.log_text.insert(ctk.END, message + \"\\n\")\n        self.log_text.see(ctk.END)\n\n    def clear_logs(self):\n        self.log_text.delete(\"1.0\", ctk.END)\n\n    def show_window(self):\n        self.deiconify()\n        self.lift()\n\n    def hide_window(self):\n        self.withdraw()\n\n    def toggle(self):\n        if self.winfo_viewable():\n            self.hide_window()\n        else:\n            self.show_window()\n\n# ---------------------------\n# \u2699\ufe0f CONFIGURATION\n# ---------------------------\nWINDOW_TITLE = \"YOLO Binary Object Sorter\"\nWINDOW_BG = \"#0a0e27\"\nCARD_BG = \"#1a1f3a\"\nACCENT_COLOR = \"#00d9ff\"\nSUCCESS_COLOR = \"#00ff88\"\nWARNING_COLOR = \"#ffaa00\"\nERROR_COLOR = \"#ff4444\"\nTEXT_COLOR = \"#e0e0e0\"\nFRAME_RATE_MS = 100  # Slower frame rate for more stable detections (100ms = ~10 fps)\nLOG_DIR = \"logs\"\nSTATS_DIR = \"logs/stats\"\n\n# Performance settings\nYOLO_CONF_THRESHOLD = 0.65  # Confidence threshold for detections\nYOLO_IMG_SIZE = 416  # Smaller image size for faster inference (default is 640)\n\n# Detection cooldown (seconds between detections)\nDETECTION_COOLDOWN = 1.5  # Wait for servo to move object out of frame (800ms servo + buffer)\n\n# ---------------------------\n# \ud83d\udcc1 Ensure Folders Exist\n# ---------------------------\nos.makedirs(LOG_DIR, exist_ok=True)\nos.makedirs(STATS_DIR, exist_ok=True)\n\n# ---------------------------\n# \ud83c\udfa8 Set CustomTkinter Theme\n# ---------------------------\nctk.set_appearance_mode(\"dark\")\nctk.set_default_color_theme(\"blue\")\n\ndef generate_csv_name():\n    now = datetime.now()\n    return f\"{LOG_DIR}/scan_log_{now.strftime('%Y-%m-%d_%H-%M-%S')}.csv\"\n\ndef generate_stats_filename():\n    now = datetime.now()\n    return f\"{STATS_DIR}/session_stats_{now.strftime('%Y-%m-%d_%H-%M-%S')}.csv\"\n\n# ---------------------------\n# \ud83c\udfa5 Camera Detection\n# ---------------------------\ndef detect_cameras():\n    \"\"\"Detect all available cameras\"\"\"\n    cameras = []\n    # Suppress OpenCV warnings during detection\n    import logging\n    logging.getLogger('cv2').setLevel(logging.ERROR)\n\n    for i in range(5):  # Check first 5 indices (reduced to speed up)\n        try:\n            cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)  # Use DirectShow on Windows\n            if cap.isOpened():\n                ret, _ = cap.read()\n                if ret:\n                    cameras.append(i)\n                cap.release()\n                cv2.destroyAllWindows()  # Clean up\n        except:\n            pass\n\n    # If no cameras found with CAP_DSHOW, try default backend\n    if not cameras:\n        for i in range(3):\n            try:\n                cap = cv2.VideoCapture(i)\n                if cap.isOpened():\n                    ret, _ = cap.read()\n                    if ret:\n                        cameras.append(i)\n                    cap.release()\n                    cv2.destroyAllWindows()\n            except:\n                pass\n\n    return cameras\n\n# ---------------------------\n# \ud83d\udd0c Arduino Functions\n# ---------------------------\ndef find_arduino_port():\n    ports = serial.tools.list_ports.comports()\n    for port in ports:\n        if \"Leonardo\" in port.description or (port.vid == 0x2341 and port.pid == 0x8036):\n            return port.device\n    return None\n\ndef send_objects_to_eeprom(item_list, arduino_serial):\n    try:\n        object_string = \",\".join(item_list[:20])\n        command = f\"STORE_OBJECTS:{object_string}\\n\"\n        arduino_serial.write(command.encode())\n        return True\n    except Exception as e:\n        print(f\"\u274c Failed to send objects: {e}\")\n        return False\n\ndef get_unique_classes_from_csv(path):\n    unique_classes = set()\n    try:\n        with open(path, newline='') as f:\n            reader = csv.reader(f)\n            for row in reader:\n                if len(row) &gt;= 2:\n                    unique_classes.add(row[1])\n    except Exception as e:\n        print(f\"Error reading CSV: {e}\")\n    return list(unique_classes)\n\n# ---------------------------\n# \ud83d\udcf7 Camera Selection Dialog\n# ---------------------------\nclass CameraSelectionDialog(ctk.CTkToplevel):\n    def __init__(self, parent, cameras):\n        super().__init__(parent)\n        self.title(\"Select Camera\")\n        self.geometry(\"400x250\")\n        self.selected_camera = None\n        self.cameras = cameras\n\n        # Center the window\n        self.transient(parent)\n        self.grab_set()\n\n        # Main frame\n        main_frame = ctk.CTkFrame(self, fg_color=CARD_BG)\n        main_frame.pack(fill=ctk.BOTH, expand=True, padx=20, pady=20)\n\n        # Title\n        title = ctk.CTkLabel(main_frame, text=\"\ud83c\udfa5 Select Camera\", \n                            font=(\"Segoe UI\", 20, \"bold\"), text_color=ACCENT_COLOR)\n        title.pack(pady=(10, 20))\n\n        # Info text\n        info = ctk.CTkLabel(main_frame, \n                        text=\"Choose the camera for object detection:\",\n                        font=(\"Segoe UI\", 12))\n        info.pack(pady=(0, 15))\n\n        # Camera dropdown\n        if cameras:\n            self.camera_var = ctk.StringVar(value=f\"Camera {cameras[0]}\")\n            camera_options = [f\"Camera {idx}\" for idx in cameras]\n\n            self.camera_menu = ctk.CTkOptionMenu(\n                main_frame,\n                values=camera_options,\n                variable=self.camera_var,\n                width=250,\n                height=40,\n                font=(\"Segoe UI\", 14),\n                fg_color=ACCENT_COLOR,\n                button_color=ACCENT_COLOR,\n                button_hover_color=\"#00a8cc\"\n            )\n            self.camera_menu.pack(pady=10)\n        else:\n            error_label = ctk.CTkLabel(main_frame, \n                                    text=\"\u274c No cameras detected!\",\n                                    text_color=ERROR_COLOR,\n                                    font=(\"Segoe UI\", 14, \"bold\"))\n            error_label.pack(pady=20)\n\n        # Confirm button\n        confirm_btn = ctk.CTkButton(\n            main_frame,\n            text=\"Continue\",\n            command=self.confirm,\n            width=200,\n            height=40,\n            font=(\"Segoe UI\", 14, \"bold\"),\n            fg_color=SUCCESS_COLOR,\n            hover_color=\"#00cc66\"\n        )\n        confirm_btn.pack(pady=(20, 10))\n\n    def confirm(self):\n        if self.cameras:\n            selected_text = self.camera_var.get()\n            self.selected_camera = int(selected_text.split()[-1])\n        self.destroy()\n\n# ---------------------------\n# \ud83d\uddbc\ufe0f Image Detection &amp; Correction Window\n# ---------------------------\nclass ImageDetectionWindow(ctk.CTkToplevel):\n    def __init__(self, parent, model):\n        super().__init__(parent)\n        self.title(\"Object Detection Setup \")\n        self.geometry(\"1000x700\")  # Reduced from 1200x800\n        self.model = model\n        self.detected_objects = {}  # {class_name: count}\n        self.image_path = None\n\n        # Make modal\n        self.transient(parent)\n        self.grab_set()\n\n        # Main container\n        main_frame = ctk.CTkFrame(self, fg_color=WINDOW_BG)\n        main_frame.pack(fill=ctk.BOTH, expand=True)\n\n        # Top bar\n        top_bar = ctk.CTkFrame(main_frame, fg_color=CARD_BG, height=70)\n        top_bar.pack(fill=ctk.X, padx=10, pady=10)\n        top_bar.pack_propagate(False)\n\n        title = ctk.CTkLabel(top_bar, text=\"\ud83d\udcf8 Object Detection Setup\",\n                            font=(\"Segoe UI\", 24, \"bold\"), text_color=ACCENT_COLOR)\n        title.pack(side=ctk.LEFT, padx=20)\n\n        # Content area\n        content = ctk.CTkFrame(main_frame, fg_color=WINDOW_BG)\n        content.pack(fill=ctk.BOTH, expand=True, padx=10, pady=(0, 10))\n\n        # Left: Image display\n        left_frame = ctk.CTkFrame(content, fg_color=CARD_BG)\n        left_frame.pack(side=ctk.LEFT, fill=ctk.BOTH, expand=True, padx=(0, 5))\n\n        self.image_label = ctk.CTkLabel(left_frame, text=\"\")\n        self.image_label.pack(fill=ctk.BOTH, expand=True, padx=20, pady=20)\n\n        # Right: Detection list and controls\n        right_frame = ctk.CTkFrame(content, fg_color=CARD_BG, width=300)  # Reduced from 350\n        right_frame.pack(side=ctk.RIGHT, fill=ctk.BOTH, padx=(5, 0))\n        right_frame.pack_propagate(False)\n\n        # Detected objects title\n        det_title = ctk.CTkLabel(right_frame, text=\"\ud83d\udccb Detected Objects\",\n                                font=(\"Segoe UI\", 18, \"bold\"))\n        det_title.pack(pady=(10, 5))\n\n        # Info text\n        info_text = ctk.CTkLabel(right_frame, \n                                text=\"These objects will be used for sorting\",\n                                font=(\"Segoe UI\", 10),\n                                text_color=TEXT_COLOR)\n        info_text.pack(pady=(0, 10))\n\n        # Scrollable frame for detections\n        self.detection_frame = ctk.CTkScrollableFrame(right_frame, fg_color=WINDOW_BG)\n        self.detection_frame.pack(fill=ctk.BOTH, expand=True, padx=10, pady=10)\n\n        # Bottom buttons\n        btn_frame = ctk.CTkFrame(right_frame, fg_color=CARD_BG)\n        btn_frame.pack(fill=ctk.X, padx=10, pady=10)\n\n        upload_btn = ctk.CTkButton(btn_frame, text=\"\ud83d\udcc1 Upload Image\",\n                                command=self.upload_image,\n                                height=40, font=(\"Segoe UI\", 14, \"bold\"),\n                                fg_color=ACCENT_COLOR, hover_color=\"#00a8cc\")\n        upload_btn.pack(fill=ctk.X, pady=5)\n\n        self.confirm_btn = ctk.CTkButton(btn_frame, text=\"\u2705 Use These Objects\",\n                                        command=self.confirm,\n                                        height=40, font=(\"Segoe UI\", 14, \"bold\"),\n                                        fg_color=SUCCESS_COLOR, hover_color=\"#00cc66\",\n                                        state=ctk.DISABLED)\n        self.confirm_btn.pack(fill=ctk.X, pady=5)\n\n    def upload_image(self):\n        filepath = filedialog.askopenfilename(\n            title=\"Select Image with Objects\",\n            filetypes=[(\"Image Files\", \"*.jpg *.jpeg *.png *.bmp\")]\n        )\n        if not filepath:\n            return\n\n        self.image_path = filepath\n        self.run_detection()\n\n    def run_detection(self):\n        # Load and run YOLO with performance optimizations\n        img = cv2.imread(self.image_path)\n        results = self.model(img, conf=YOLO_CONF_THRESHOLD, imgsz=YOLO_IMG_SIZE, verbose=False)[0]\n        annotated = results.plot()\n\n        # Count detections\n        self.detected_objects.clear()\n        for box in results.boxes:\n            cls_id = int(box.cls[0])\n            class_name = self.model.names[cls_id]\n            self.detected_objects[class_name] = self.detected_objects.get(class_name, 0) + 1\n\n        # Display annotated image\n        rgb_frame = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n        pil_img = Image.fromarray(rgb_frame)\n\n        # Resize to fit (use FAST for better performance)\n        max_width, max_height = 800, 700\n        pil_img.thumbnail((max_width, max_height), Image.NEAREST)\n\n        ctk_img = CTkImage(light_image=pil_img, dark_image=pil_img, \n                        size=pil_img.size)\n        self.image_label.configure(image=ctk_img)\n        self.image_label.image = ctk_img\n\n        # Update detection list\n        self.update_detection_list()\n        self.confirm_btn.configure(state=ctk.NORMAL)\n\n    def update_detection_list(self):\n        # Clear existing\n        for widget in self.detection_frame.winfo_children():\n            widget.destroy()\n\n        if not self.detected_objects:\n            no_det = ctk.CTkLabel(self.detection_frame, \n                                text=\"No objects detected\",\n                                font=(\"Segoe UI\", 12))\n            no_det.pack(pady=20)\n            return\n\n        # Display detected objects (read-only)\n        for i, (class_name, count) in enumerate(self.detected_objects.items(), 1):\n            obj_frame = ctk.CTkFrame(self.detection_frame, fg_color=CARD_BG)\n            obj_frame.pack(fill=ctk.X, pady=5, padx=5)\n\n            # Position number\n            position = ctk.CTkLabel(obj_frame, \n                                text=f\"{i}.\",\n                                font=(\"Segoe UI\", 14, \"bold\"),\n                                width=30)\n            position.pack(side=ctk.LEFT, padx=10, pady=10)\n\n            # Object name and count\n            info = ctk.CTkLabel(obj_frame, \n                            text=f\"{class_name}\",\n                            font=(\"Segoe UI\", 13, \"bold\"),\n                            anchor=ctk.W)\n            info.pack(side=ctk.LEFT, padx=5, pady=10, fill=ctk.X, expand=True)\n\n            # Count badge\n            count_badge = ctk.CTkLabel(obj_frame,\n                                    text=f\"\u00d7{count}\",\n                                    font=(\"Segoe UI\", 11),\n                                    text_color=ACCENT_COLOR)\n            count_badge.pack(side=ctk.RIGHT, padx=10, pady=10)\n\n    def confirm(self):\n        if not self.detected_objects:\n            messagebox.showerror(\"Error\", \"No objects detected!\")\n            return\n        self.destroy()\n\n# ---------------------------\n# \ud83d\udcca Statistics Window\n# ---------------------------\nclass StatsWindow(ctk.CTkToplevel):\n    def __init__(self, parent, stats_data):\n        super().__init__(parent)\n        self.title(\"Sorting Session Statistics\")\n        self.geometry(\"800x600\")\n        self.stats_data = stats_data\n\n        # Make modal - forces user to interact with this window\n        self.transient(parent)\n        self.grab_set()\n        self.lift()\n        self.focus_force()\n\n        # Main frame\n        main_frame = ctk.CTkFrame(self, fg_color=WINDOW_BG)\n        main_frame.pack(fill=ctk.BOTH, expand=True)\n\n        # Title\n        title = ctk.CTkLabel(main_frame, text=\"\ud83d\udcca Session Statistics\",\n                            font=(\"Segoe UI\", 24, \"bold\"), text_color=ACCENT_COLOR)\n        title.pack(pady=20)\n\n        # Stats display\n        stats_frame = ctk.CTkScrollableFrame(main_frame, fg_color=CARD_BG)\n        stats_frame.pack(fill=ctk.BOTH, expand=True, padx=20, pady=(0, 20))\n\n        # Display stats\n        for key, value in stats_data.items():\n            row = ctk.CTkFrame(stats_frame, fg_color=WINDOW_BG)\n            row.pack(fill=ctk.X, pady=5, padx=10)\n\n            label = ctk.CTkLabel(row, text=f\"{key}:\", \n                                font=(\"Segoe UI\", 14, \"bold\"),\n                                anchor=ctk.W)\n            label.pack(side=ctk.LEFT, padx=10)\n\n            value_label = ctk.CTkLabel(row, text=str(value),\n                                    font=(\"Segoe UI\", 14),\n                                    text_color=SUCCESS_COLOR)\n            value_label.pack(side=ctk.RIGHT, padx=10)\n\n        # Buttons\n        btn_frame = ctk.CTkFrame(main_frame, fg_color=WINDOW_BG)\n        btn_frame.pack(fill=ctk.X, padx=20, pady=(0, 20))\n\n        save_btn = ctk.CTkButton(btn_frame, text=\"\ud83d\udcbe Save Full Report\",\n                                command=self.save_report,\n                                height=40, font=(\"Segoe UI\", 14, \"bold\"),\n                                fg_color=ACCENT_COLOR, hover_color=\"#00a8cc\")\n        save_btn.pack(side=ctk.LEFT, expand=True, padx=5)\n\n        close_btn = ctk.CTkButton(btn_frame, text=\"Close\",\n                                command=self.destroy,\n                                height=40, font=(\"Segoe UI\", 14, \"bold\"))\n        close_btn.pack(side=ctk.RIGHT, expand=True, padx=5)\n\n    def save_report(self):\n        filepath = generate_stats_filename()\n        try:\n            with open(filepath, 'w', newline='', encoding='utf-8') as f:\n                writer = csv.writer(f)\n                writer.writerow(['Metric', 'Value'])\n                for key, value in self.stats_data.items():\n                    writer.writerow([key, value])\n            messagebox.showinfo(\"Success\", f\"Report saved to:\\n{filepath}\")\n        except Exception as e:\n            messagebox.showerror(\"Error\", f\"Failed to save report:\\n{e}\")\n\n# ---------------------------\n# \ud83e\uddd9 Setup Wizard (Multi-Step)\n# ---------------------------\nclass SetupWizard(ctk.CTkToplevel):\n    def __init__(self, parent, app):\n        super().__init__(parent)\n        self.title(\"Setup Sorting Session\")\n        self.geometry(\"850x750\")\n        self.resizable(True, True)\n        self.app = app  # Reference to main app\n\n        # Make modal\n        self.transient(parent)\n        self.grab_set()\n        self.lift()\n        self.focus_force()\n\n        # Wizard state\n        self.current_step = 1\n        self.total_steps = 3\n\n        # Hardware selections\n        self.selected_camera = None\n        self.arduino_connected = False\n\n        # Main container\n        main_frame = ctk.CTkFrame(self, fg_color=WINDOW_BG)\n        main_frame.pack(fill=ctk.BOTH, expand=True)\n\n        # Header\n        self.create_header(main_frame)\n\n        # Content area (changes per step)\n        self.content_frame = ctk.CTkFrame(main_frame, fg_color=WINDOW_BG)\n        self.content_frame.pack(fill=ctk.BOTH, expand=True, padx=20, pady=10)\n\n        # Footer with navigation\n        self.create_footer(main_frame)\n\n        # Show first step\n        self.show_step(1)\n\n    def create_header(self, parent):\n        \"\"\"Create wizard header with progress indicator\"\"\"\n        header = ctk.CTkFrame(parent, fg_color=CARD_BG, height=80)\n        header.pack(fill=ctk.X, padx=10, pady=10)\n        header.pack_propagate(False)\n\n        # Title\n        self.title_label = ctk.CTkLabel(header, text=\"Step 1: Hardware Setup\",\n                                    font=(\"Segoe UI\", 22, \"bold\"),\n                                    text_color=ACCENT_COLOR)\n        self.title_label.pack(pady=10)\n\n        # Progress indicator\n        progress_frame = ctk.CTkFrame(header, fg_color=CARD_BG)\n        progress_frame.pack(fill=ctk.X, padx=40)\n\n        self.progress_bar = ctk.CTkProgressBar(progress_frame, \n                                            progress_color=ACCENT_COLOR,\n                                            height=8)\n        self.progress_bar.pack(fill=ctk.X, pady=5)\n        self.progress_bar.set(0.33)\n\n        self.progress_label = ctk.CTkLabel(progress_frame, \n                                        text=\"Step 1 of 3\",\n                                        font=(\"Segoe UI\", 10))\n        self.progress_label.pack()\n\n    def create_footer(self, parent):\n        \"\"\"Create footer with Back/Next buttons\"\"\"\n        footer = ctk.CTkFrame(parent, fg_color=CARD_BG, height=80)\n        footer.pack(fill=ctk.X, padx=10, pady=10)\n        footer.pack_propagate(False)\n\n        btn_frame = ctk.CTkFrame(footer, fg_color=CARD_BG)\n        btn_frame.pack(expand=True)\n\n        # Back button\n        self.back_btn = ctk.CTkButton(btn_frame, text=\"\u2190 Back\",\n                                    command=self.go_back,\n                                    width=150, height=45,\n                                    font=(\"Segoe UI\", 14),\n                                    state=ctk.DISABLED)\n        self.back_btn.pack(side=ctk.LEFT, padx=10)\n\n        # Next/Finish button\n        self.next_btn = ctk.CTkButton(btn_frame, text=\"Next \u2192\",\n                                    command=self.go_next,\n                                    width=150, height=45,\n                                    font=(\"Segoe UI\", 14, \"bold\"),\n                                    fg_color=SUCCESS_COLOR,\n                                    hover_color=\"#00cc66\",\n                                    state=ctk.DISABLED)\n        self.next_btn.pack(side=ctk.LEFT, padx=10)\n\n    def show_step(self, step):\n        \"\"\"Display the appropriate step content\"\"\"\n        self.current_step = step\n\n        # Clear content frame\n        for widget in self.content_frame.winfo_children():\n            widget.destroy()\n\n        # Update header\n        step_titles = {\n            1: \"Step 1: Hardware Setup\",\n            2: \"Step 2: Load Model\",\n            3: \"Step 3: Detect Objects\"\n        }\n        self.title_label.configure(text=step_titles[step])\n        self.progress_bar.set(step / self.total_steps)\n        self.progress_label.configure(text=f\"Step {step} of {self.total_steps}\")\n\n        # Show appropriate content\n        if step == 1:\n            self.show_hardware_step()\n        elif step == 2:\n            self.show_model_step()\n        elif step == 3:\n            self.show_objects_step()\n\n        # Update navigation buttons\n        self.back_btn.configure(state=ctk.NORMAL if step &gt; 1 else ctk.DISABLED)\n\n    def show_hardware_step(self):\n        \"\"\"Step 1: Arduino and Camera setup\"\"\"\n        # Arduino section\n        arduino_frame = ctk.CTkFrame(self.content_frame, fg_color=CARD_BG)\n        arduino_frame.pack(fill=ctk.X, pady=10)\n\n        arduino_title = ctk.CTkLabel(arduino_frame, text=\"\ud83d\udd0c Arduino Connection\",\n                                    font=(\"Segoe UI\", 18, \"bold\"))\n        arduino_title.pack(pady=10, padx=20, anchor=ctk.W)\n\n        arduino_status_frame = ctk.CTkFrame(arduino_frame, fg_color=WINDOW_BG)\n        arduino_status_frame.pack(fill=ctk.X, padx=20, pady=10)\n\n        self.arduino_status_label = ctk.CTkLabel(arduino_status_frame,\n                                                text=\"\ud83d\udd34 Not Connected\",\n                                                font=(\"Segoe UI\", 14),\n                                                text_color=ERROR_COLOR)\n        self.arduino_status_label.pack(side=ctk.LEFT, padx=10)\n\n        arduino_connect_btn = ctk.CTkButton(arduino_status_frame,\n                                        text=\"Connect Arduino\",\n                                        command=self.connect_arduino_wizard,\n                                        height=40,\n                                        font=(\"Segoe UI\", 12, \"bold\"))\n        arduino_connect_btn.pack(side=ctk.RIGHT, padx=10)\n\n        # Separator\n        separator1 = ctk.CTkFrame(self.content_frame, fg_color=CARD_BG, height=2)\n        separator1.pack(fill=ctk.X, pady=20)\n\n        # Camera section\n        camera_frame = ctk.CTkFrame(self.content_frame, fg_color=CARD_BG)\n        camera_frame.pack(fill=ctk.X, pady=10)\n\n        camera_title = ctk.CTkLabel(camera_frame, text=\"\ud83d\udcf7 Camera Selection\",\n                                    font=(\"Segoe UI\", 18, \"bold\"))\n        camera_title.pack(pady=10, padx=20, anchor=ctk.W)\n\n        camera_select_frame = ctk.CTkFrame(camera_frame, fg_color=WINDOW_BG)\n        camera_select_frame.pack(fill=ctk.X, padx=20, pady=10)\n\n        cam_label = ctk.CTkLabel(camera_select_frame, text=\"Select Camera:\",\n                                font=(\"Segoe UI\", 12))\n        cam_label.pack(side=ctk.LEFT, padx=10)\n\n        # Camera dropdown\n        if self.app.available_cameras:\n            self.camera_var = ctk.StringVar(value=f\"Camera {self.app.available_cameras[0]}\")\n            camera_options = [f\"Camera {idx}\" for idx in self.app.available_cameras]\n\n            self.camera_dropdown = ctk.CTkOptionMenu(\n                camera_select_frame,\n                values=camera_options,\n                variable=self.camera_var,\n                width=200,\n                font=(\"Segoe UI\", 12)\n            )\n            self.camera_dropdown.pack(side=ctk.LEFT, padx=10)\n        else:\n            no_cam_label = ctk.CTkLabel(camera_select_frame,\n                                        text=\"\u274c No cameras detected\",\n                                        text_color=ERROR_COLOR,\n                                        font=(\"Segoe UI\", 12, \"bold\"))\n            no_cam_label.pack(side=ctk.LEFT, padx=10)\n\n        test_cam_btn = ctk.CTkButton(camera_select_frame,\n                                    text=\"Test Camera\",\n                                    command=self.test_camera_wizard,\n                                    height=40,\n                                    font=(\"Segoe UI\", 12, \"bold\"))\n        test_cam_btn.pack(side=ctk.LEFT, padx=10)\n\n        self.camera_status_label = ctk.CTkLabel(camera_select_frame,\n                                                text=\"\",\n                                                font=(\"Segoe UI\", 11))\n        self.camera_status_label.pack(side=ctk.LEFT, padx=10)\n\n        # Check if both are already connected from previous session\n        self.check_hardware_ready()\n\n    def connect_arduino_wizard(self):\n        \"\"\"Connect to Arduino from wizard\"\"\"\n        self.app.connect_to_arduino()\n        # Wait a moment for connection\n        self.after(2500, self.check_arduino_status)\n\n    def check_arduino_status(self):\n        \"\"\"Check if Arduino connected successfully\"\"\"\n        if self.app.arduino and self.app.arduino.is_open:\n            self.arduino_connected = True\n            self.arduino_status_label.configure(text=\"\ud83d\udfe2 Connected\",\n                                            text_color=SUCCESS_COLOR)\n            self.app.update_checklist('arduino', True)  # \u2705 Update main checklist\n            self.check_hardware_ready()\n        else:\n            self.arduino_status_label.configure(text=\"\ud83d\udd34 Failed to Connect\",\n                                            text_color=ERROR_COLOR)\n            self.app.update_checklist('arduino', False)  # \u274c Update main checklist\n\n    def test_camera_wizard(self):\n        \"\"\"Test selected camera\"\"\"\n        if not self.app.available_cameras:\n            self.camera_status_label.configure(text=\"\u274c No cameras\",\n                                            text_color=ERROR_COLOR)\n            return\n\n        selected = self.camera_var.get()\n        cam_index = int(selected.split()[-1])\n\n        self.camera_status_label.configure(text=\"Testing...\",\n                                        text_color=WARNING_COLOR)\n        self.update()\n\n        # Test the camera (just verify it works, don't keep it running)\n        if self.app.test_camera(cam_index):\n            self.selected_camera = cam_index\n            self.camera_status_label.configure(text=\"\u2705 Working\",\n                                            text_color=SUCCESS_COLOR)\n            self.app.update_checklist('camera', True)\n            self.app.log(f\"\u2705 Camera {cam_index} tested successfully\")\n            self.check_hardware_ready()\n        else:\n            self.camera_status_label.configure(text=\"\u274c Not working\",\n                                            text_color=ERROR_COLOR)\n            self.app.update_checklist('camera', False)\n\n    def check_hardware_ready(self):\n        \"\"\"Enable Next button if both Arduino and Camera are ready\"\"\"\n        if self.arduino_connected and self.selected_camera is not None:\n            self.next_btn.configure(state=ctk.NORMAL)\n        else:\n            self.next_btn.configure(state=ctk.DISABLED)\n\n    def show_model_step(self):\n        \"\"\"Step 2: Model loading\"\"\"\n        info_frame = ctk.CTkFrame(self.content_frame, fg_color=CARD_BG)\n        info_frame.pack(fill=ctk.BOTH, expand=True, pady=20)\n\n        title = ctk.CTkLabel(info_frame, text=\"\ud83d\udcc1 Load YOLO Model\",\n                            font=(\"Segoe UI\", 18, \"bold\"))\n        title.pack(pady=20)\n\n        desc = ctk.CTkLabel(info_frame,\n                        text=\"Select your trained YOLO model file (.pt)\\n\"\n                                \"This model will be used to detect and classify objects.\",\n                        font=(\"Segoe UI\", 12),\n                        justify=ctk.CENTER)\n        desc.pack(pady=10)\n\n        # Model status\n        self.model_status_frame = ctk.CTkFrame(info_frame, fg_color=WINDOW_BG)\n        self.model_status_frame.pack(pady=20, padx=40, fill=ctk.X)\n\n        if self.app.model:\n            status_text = f\"\u2705 Model Loaded: {os.path.basename(self.app.model_path)}\"\n            status_color = SUCCESS_COLOR\n        else:\n            status_text = \"\u26a0\ufe0f No model loaded\"\n            status_color = WARNING_COLOR\n\n        self.model_status_label = ctk.CTkLabel(self.model_status_frame,\n                                            text=status_text,\n                                            font=(\"Segoe UI\", 13, \"bold\"),\n                                            text_color=status_color)\n        self.model_status_label.pack(pady=10)\n\n        # Browse button\n        browse_btn = ctk.CTkButton(info_frame,\n                                text=\"\ud83d\udcc1 Browse for Model\",\n                                command=self.load_model_wizard,\n                                width=250,\n                                height=50,\n                                font=(\"Segoe UI\", 14, \"bold\"),\n                                fg_color=ACCENT_COLOR,\n                                hover_color=\"#00a8cc\")\n        browse_btn.pack(pady=20)\n\n        # Enable next if model already loaded\n        if self.app.model:\n            self.next_btn.configure(state=ctk.NORMAL)\n        else:\n            self.next_btn.configure(state=ctk.DISABLED)\n\n    def load_model_wizard(self):\n        \"\"\"Load model from wizard\"\"\"\n        path = filedialog.askopenfilename(\n            title=\"Select YOLO Model\",\n            filetypes=[(\"PyTorch Model\", \"*.pt\")]\n        )\n        if path:\n            try:\n                self.app.model_path = path\n                self.app.model = YOLO(self.app.model_path)\n                self.app.log(f\"\u2705 Model loaded: {os.path.basename(self.app.model_path)}\")\n                self.app.update_checklist('model', True)\n\n                # Update display\n                self.model_status_label.configure(\n                    text=f\"\u2705 Model Loaded: {os.path.basename(path)}\",\n                    text_color=SUCCESS_COLOR\n                )\n                self.next_btn.configure(state=ctk.NORMAL)\n            except Exception as e:\n                self.app.log(f\"\u274c Failed to load model: {e}\")\n                messagebox.showerror(\"Error\", f\"Failed to load model:\\n{e}\")\n\n    def show_objects_step(self):\n        \"\"\"Step 3: Object detection and ordering\"\"\"\n        info_frame = ctk.CTkFrame(self.content_frame, fg_color=CARD_BG)\n        info_frame.pack(fill=ctk.BOTH, expand=True, pady=20)\n\n        title = ctk.CTkLabel(info_frame, text=\"\ud83d\udcf8 Detect Objects\",\n                            font=(\"Segoe UI\", 18, \"bold\"))\n        title.pack(pady=20)\n\n        desc = ctk.CTkLabel(info_frame,\n                        text=\"Upload an image containing all object types you want to sort.\\n\"\n                                \"Ensure your YOLO model is properly trained for accurate detection.\",\n                        font=(\"Segoe UI\", 12),\n                        justify=ctk.CENTER)\n        desc.pack(pady=10)\n\n        # Detection status\n        if self.app.sort_classes:\n            status_text = f\"\u2705 Detected {len(self.app.sort_classes)} object types\"\n            status_color = SUCCESS_COLOR\n            btn_text = \"\ud83d\udcf8 Re-detect Objects\"\n        else:\n            status_text = \"\u26a0\ufe0f No objects detected yet\"\n            status_color = WARNING_COLOR\n            btn_text = \"\ud83d\udcf8 Upload &amp; Detect\"\n\n        self.objects_status_label = ctk.CTkLabel(info_frame,\n                                                text=status_text,\n                                                font=(\"Segoe UI\", 13, \"bold\"),\n                                                text_color=status_color)\n        self.objects_status_label.pack(pady=10)\n\n        # Detect button\n        detect_btn = ctk.CTkButton(info_frame,\n                                text=btn_text,\n                                command=self.detect_objects_wizard,\n                                width=250,\n                                height=50,\n                                font=(\"Segoe UI\", 14, \"bold\"),\n                                fg_color=ACCENT_COLOR,\n                                hover_color=\"#00a8cc\")\n        detect_btn.pack(pady=20)\n\n        # Show detected objects if any\n        if self.app.sort_classes:\n            objects_frame = ctk.CTkFrame(info_frame, fg_color=WINDOW_BG)\n            objects_frame.pack(pady=10, padx=40, fill=ctk.BOTH, expand=True)\n\n            objects_label = ctk.CTkLabel(objects_frame,\n                                        text=\"Detected Objects:\",\n                                        font=(\"Segoe UI\", 12, \"bold\"))\n            objects_label.pack(pady=5)\n\n            for i, obj in enumerate(self.app.sort_classes, 1):\n                obj_label = ctk.CTkLabel(objects_frame,\n                                        text=f\"{i}. {obj}\",\n                                        font=(\"Segoe UI\", 11))\n                obj_label.pack(anchor=ctk.W, padx=20, pady=2)\n\n        # Enable finish button if objects detected\n        if self.app.sort_classes:\n            self.next_btn.configure(state=ctk.NORMAL, text=\"Finish Setup \u2192\")\n        else:\n            self.next_btn.configure(state=ctk.DISABLED, text=\"Finish Setup \u2192\")\n\n    def detect_objects_wizard(self):\n        \"\"\"Open object detection from wizard\"\"\"\n        if not self.app.model:\n            messagebox.showerror(\"Error\", \"Model not loaded!\")\n            return\n\n        # Open detection window (reuse existing)\n        detection_window = ImageDetectionWindow(self, self.app.model)\n        self.wait_window(detection_window)\n\n        if detection_window.detected_objects:\n            self.app.sort_classes = list(detection_window.detected_objects.keys())\n            self.app.log(f\"\u2705 Detected {len(self.app.sort_classes)} unique objects\")\n            self.app.log(f\"\ud83d\udccb Objects: {', '.join(self.app.sort_classes)}\")\n            self.app.update_checklist('objects', True)\n\n            # Show sorting order dialog\n            self.app.show_sorting_order_dialog()\n\n            # Refresh step 3 display\n            self.show_step(3)\n\n    def go_back(self):\n        \"\"\"Go to previous step\"\"\"\n        if self.current_step &gt; 1:\n            self.show_step(self.current_step - 1)\n\n    def go_next(self):\n        \"\"\"Go to next step or finish\"\"\"\n        if self.current_step &lt; self.total_steps:\n            self.show_step(self.current_step + 1)\n        else:\n            # Finish wizard\n            self.finish_wizard()\n\n    def finish_wizard(self):\n        \"\"\"Complete the wizard and prepare for sorting\"\"\"\n        # Verify everything is ready\n        if not (self.arduino_connected and self.selected_camera is not None \n                and self.app.model and self.app.sort_classes):\n            messagebox.showerror(\"Error\", \"Please complete all setup steps!\")\n            return\n\n        # Start the camera feed now (deferred until wizard completes)\n        self.app.log(f\"\ud83d\udcf7 Starting camera {self.selected_camera} for sorting...\")\n        if not self.app.start_camera_feed(self.selected_camera):\n            messagebox.showerror(\"Error\", \"Failed to start camera feed!\")\n            return\n\n        # Auto-send objects to Arduino\n        if self.app.arduino and self.app.arduino.is_open:\n            self.app.log(\"\ud83d\udce4 Auto-sending objects to Arduino...\")\n            if not send_objects_to_eeprom(self.app.sort_classes, self.app.arduino):\n                messagebox.showerror(\"Error\", \"Failed to send objects to Arduino!\")\n                return\n\n            self.app.log(f\"\u2705 Sent {len(self.app.sort_classes)} objects to Arduino\")\n            self.app.arduino_ready_to_sort = True\n\n            # Update progressive button to \"ready\" state\n            self.app.update_progressive_button(\"ready\")\n\n        messagebox.showinfo(\"Setup Complete\", \n                        \"All setup steps completed!\\n\\n\"\n                        \"Camera feed is now active.\\n\"\n                        \"Click 'Begin Sorting Session' to start.\")\n\n        self.destroy()\n\n# ---------------------------\n# \ud83d\udda5\ufe0f Main Application\n# ---------------------------\nclass YOLOApp:\n    def __init__(self, root, camera_index, available_cameras):\n        self.root = root\n        self.root.title(WINDOW_TITLE)\n        self.root.geometry(\"1500x950\")  # Slightly larger for 3-column layout\n\n        # FIXED: Convert camera integers to formatted strings\n        self.available_cameras = available_cameras if available_cameras else []\n        self.camera_options = [f\"Camera {i}\" for i in self.available_cameras] if self.available_cameras else [\"No Cameras Found\"]\n\n        self.camera_index = camera_index  # Can be None initially\n        self.cap = None  # No camera opened yet\n        self.camera_ready = False  # Track if camera is ready\n\n        self.arduino = None\n        self.is_running = False\n        self.feed_active = False  # Track if live feed is on\n        self.mode = None\n        self.model = None\n        self.model_path = \"\"\n\n        # Binary sorting\n        self.sort_classes = []\n        self.current_sort_index = 0\n        self.current_target_class = None\n        self.sorting_in_progress = False\n        self.arduino_ready_to_sort = False\n        self.waiting_for_pass_data = None  # Track which pass we're expecting data for\n\n        # ========================================\n        # SERVO-BASED COUNTING (ENHANCED)\n        # ========================================\n        # Per-pass counts stored to file\n        self.pass_counts = {}  # {pass_number: {'class': str, 'target_count': int}}\n        self.first_pass_total = 0  # Ground truth from first pass\n        self.current_pass_target_count = 0  # Target count for current pass\n        self.current_pass_number = 0  # Track which pass we're on\n\n        # Statistics tracking\n        self.session_start_time = None\n        self.objects_sorted = defaultdict(int)\n\n        # Logs - MUST BE INITIALIZED BEFORE init_pass_data_file()\n        self.log_visible = False\n        self.log_messages = []\n        self.log_window = None  # Will be created on first use\n\n        # Initialize pass data file (AFTER log_messages is created)\n        self.init_pass_data_file()\n\n        # Flag to prevent premature closing\n        self.initialized = False\n\n        # Checklist items (will be created in setup_ui)\n        self.check_arduino = None\n        self.check_camera = None\n        self.check_model = None\n        self.check_objects = None\n\n        # Status labels (for compatibility with existing code)\n        self.arduino_status = None\n        self.camera_status = None\n\n        # Multi-frame detection confirmation\n        self.detection_buffer = []  # Store recent detections\n        self.detection_confirmation_frames = 2  # Require 2 consecutive detections\n        self.last_confirmed_detection = None\n        self.last_confirmed_time = 0\n\n        try:\n            self.setup_ui()\n            self.log_window = LogWindow(self.root)  # Create log window\n            self.log(\"\ud83d\udfe2 System initialized\")\n            self.log(\"\ud83d\ude80 Click 'Setup New Sorting Session' to begin\")\n            self.initialized = True\n        except Exception as e:\n            import traceback\n            print(\"=\"*60)\n            print(\"INITIALIZATION ERROR:\")\n            traceback.print_exc()\n            print(\"=\"*60)\n            messagebox.showerror(\"Initialization Error\", f\"Failed to initialize UI:\\n{e}\")\n            root.quit()\n\n    def init_pass_data_file(self):\n        \"\"\"Initialize or clear the pass data file\"\"\"\n        try:\n            os.makedirs(LOG_DIR, exist_ok=True)\n            with open(PASS_DATA_FILE, 'w') as f:\n                json.dump({'passes': [], 'first_pass_total': 0}, f)\n            self.log(\"\ud83d\udcc4 Pass data file initialized\")\n        except Exception as e:\n            self.log(f\"\u274c Error initializing pass data file: {e}\")\n\n    def save_pass_data(self):\n        \"\"\"Save current pass data to file\"\"\"\n        try:\n            # Read existing data\n            if os.path.exists(PASS_DATA_FILE):\n                with open(PASS_DATA_FILE, 'r') as f:\n                    data = json.load(f)\n            else:\n                data = {'passes': [], 'first_pass_total': 0}\n\n            # Update data\n            data['first_pass_total'] = self.first_pass_total\n            data['passes'] = list(self.pass_counts.values())\n\n            # DEBUG\n            self.log(f\"\ud83d\udcbe Saving to file: {data}\")\n\n            # Write to file\n            with open(PASS_DATA_FILE, 'w') as f:\n                json.dump(data, f, indent=2)\n\n            self.log(f\"\u2705 Pass data saved: {len(data['passes'])} passes recorded\")\n        except Exception as e:\n            self.log(f\"\u274c Error saving pass data: {e}\")\n            import traceback\n            self.log(f\"\u274c Traceback: {traceback.format_exc()}\")\n\n    def load_pass_data(self):\n        \"\"\"Load pass data from file\"\"\"\n        try:\n            if os.path.exists(PASS_DATA_FILE):\n                with open(PASS_DATA_FILE, 'r') as f:\n                    data = json.load(f)\n                return data\n            return {'passes': [], 'first_pass_total': 0}\n        except Exception as e:\n            self.log(f\"\u274c Error loading pass data: {e}\")\n            return {'passes': [], 'first_pass_total': 0}\n\n    def clear_pass_data_file(self):\n        \"\"\"Clear pass data file after session ends\"\"\"\n        try:\n            if os.path.exists(PASS_DATA_FILE):\n                os.remove(PASS_DATA_FILE)\n                self.log(\"\ud83d\uddd1\ufe0f Pass data file cleared\")\n        except Exception as e:\n            self.log(f\"\u274c Error clearing pass data: {e}\")\n\n    def setup_ui(self):\n        # Main container\n        container = ctk.CTkFrame(self.root, fg_color=WINDOW_BG)\n        container.pack(fill=ctk.BOTH, expand=True)\n\n        # Top bar\n        self.create_top_bar(container)\n\n        # Main content area (3 columns: checklist + video + stats)\n        content = ctk.CTkFrame(container, fg_color=WINDOW_BG)\n        content.pack(fill=ctk.BOTH, expand=True, padx=10, pady=(0, 10))\n\n        # LEFT: Setup Checklist Sidebar\n        self.create_checklist_sidebar(content)\n\n        # CENTER: Video feed\n        video_container = ctk.CTkFrame(content, fg_color=CARD_BG)\n        video_container.pack(side=ctk.LEFT, fill=ctk.BOTH, expand=True, padx=5)\n\n        video_header = ctk.CTkFrame(video_container, fg_color=CARD_BG, height=50)\n        video_header.pack(fill=ctk.X)\n        video_header.pack_propagate(False)\n\n        video_title = ctk.CTkLabel(video_header, text=\"\ud83d\udcf9 Live Feed\",\n                                font=(\"Segoe UI\", 16, \"bold\"))\n        video_title.pack(side=ctk.LEFT, padx=20, pady=10)\n\n        self.video_frame = ctk.CTkLabel(video_container, text=\"\")\n        self.video_frame.pack(fill=ctk.BOTH, expand=True, padx=10, pady=(0, 10))\n\n        # Create placeholder\n        placeholder = Image.new(\"RGB\", (640, 480), (10, 14, 39))\n        draw = ImageDraw.Draw(placeholder)\n        try:\n            font = ImageFont.truetype(\"arial.ttf\", 24)\n        except:\n            font = ImageFont.load_default()\n        text = \"CAMERA STANDBY\"\n        bbox = draw.textbbox((0, 0), text, font=font)\n        tw = bbox[2] - bbox[0]\n        th = bbox[3] - bbox[1]\n        draw.text(((640-tw)//2, (480-th)//2), text, fill=(0, 217, 255), font=font)\n\n        self.placeholder_img = CTkImage(light_image=placeholder, dark_image=placeholder, size=(640, 480))\n        self.video_frame.configure(image=self.placeholder_img)\n        self.video_frame.image = self.placeholder_img\n\n        # RIGHT: Sidebar (stats)\n        self.create_sidebar(content)\n\n        # Progressive button (below video feed)\n        self.create_progressive_button(video_container)\n\n    def create_top_bar(self, parent):\n        self.topbar = ctk.CTkFrame(parent, fg_color=CARD_BG, height=70)\n        self.topbar.pack(fill=ctk.X, padx=10, pady=10)\n        self.topbar.pack_propagate(False)\n\n        # Title\n        title = ctk.CTkLabel(self.topbar, text=\"\ud83e\udd16 YOLO Binary Object Sorter\",\n                            font=(\"Segoe UI\", 24, \"bold\"), text_color=ACCENT_COLOR)\n        title.pack(side=ctk.LEFT, padx=20)\n\n        # Utility buttons (right side, icon-only)\n        utility_frame = ctk.CTkFrame(self.topbar, fg_color=CARD_BG)\n        utility_frame.pack(side=ctk.RIGHT, padx=20)\n\n        # Logs button\n        log_btn = ctk.CTkButton(utility_frame, text=\"\ud83d\udccb Logs\",\n                            command=self.open_log_window,\n                            width=100, height=50,\n                            font=(\"Segoe UI\", 20),\n                            fg_color=ACCENT_COLOR,\n                            hover_color=\"#00a8cc\")\n        log_btn.pack(side=ctk.LEFT, padx=5)\n\n        # Reset button\n        reset_btn = ctk.CTkButton(utility_frame, text=\"\ud83d\udd04 Reset\",\n                                command=self.reset_session,\n                                width=100, height=50,\n                                font=(\"Segoe UI\", 20),\n                                fg_color=WARNING_COLOR,\n                                hover_color=\"#cc8800\")\n        reset_btn.pack(side=ctk.LEFT, padx=5)\n\n        # Exit button\n        exit_btn = ctk.CTkButton(utility_frame, text=\"\ud83d\udeaa Exit\",\n                                command=self.exit_app,\n                                width=100, height=50,\n                                font=(\"Segoe UI\", 20),\n                                fg_color=ERROR_COLOR,\n                                hover_color=\"#cc0000\")\n        exit_btn.pack(side=ctk.LEFT, padx=5)\n\n    def create_checklist_sidebar(self, parent):\n        \"\"\"Left sidebar with setup progress checklist\"\"\"\n        checklist_sidebar = ctk.CTkFrame(parent, fg_color=CARD_BG, width=200)\n        checklist_sidebar.pack(side=ctk.LEFT, fill=ctk.Y, padx=(0, 5))\n        checklist_sidebar.pack_propagate(False)\n\n        # Title\n        checklist_title = ctk.CTkLabel(checklist_sidebar, text=\"\ud83d\udccb Setup\",\n                                    font=(\"Segoe UI\", 18, \"bold\"))\n        checklist_title.pack(pady=(20, 10))\n\n        # Checklist items\n        checklist_frame = ctk.CTkFrame(checklist_sidebar, fg_color=WINDOW_BG)\n        checklist_frame.pack(fill=ctk.BOTH, expand=True, padx=10, pady=10)\n\n        # Arduino\n        self.check_arduino = self.create_checklist_item(checklist_frame, \"Arduino\")\n\n        # Camera\n        self.check_camera = self.create_checklist_item(checklist_frame, \"Camera\")\n\n        # Model\n        self.check_model = self.create_checklist_item(checklist_frame, \"Model\")\n\n        # Objects\n        self.check_objects = self.create_checklist_item(checklist_frame, \"Objects\")\n\n    def create_progressive_button(self, parent):\n        \"\"\"Create the main progressive action button below video feed\"\"\"\n        btn_container = ctk.CTkFrame(parent, fg_color=CARD_BG, height=80)\n        btn_container.pack(fill=ctk.X, padx=10, pady=(0, 10))\n        btn_container.pack_propagate(False)\n\n        # The main progressive button\n        self.progressive_btn = ctk.CTkButton(\n            btn_container,\n            text=\"\ud83d\ude80 Setup New Sorting Session\",\n            command=self.progressive_btn_action,\n            height=60,\n            font=(\"Segoe UI\", 16, \"bold\"),\n            fg_color=ACCENT_COLOR,\n            hover_color=\"#00a8cc\"\n        )\n        self.progressive_btn.pack(fill=ctk.BOTH, expand=True, padx=20, pady=10)\n\n        # Track current state\n        self.btn_state = \"setup\"  # States: setup, ready, pass_N, complete_pass_N, finish\n\n    def progressive_btn_action(self):\n        \"\"\"Handle progressive button clicks based on current state\"\"\"\n        if self.btn_state == \"setup\":\n            self.open_setup_wizard()\n        elif self.btn_state == \"ready\":\n            self.begin_sorting_session()\n        elif self.btn_state.startswith(\"pass_\"):\n            # Extract pass number: \"pass_1\" -&gt; 1\n            pass_num = int(self.btn_state.split(\"_\")[1])\n            self.start_pass(pass_num)\n        elif self.btn_state.startswith(\"complete_pass_\"):\n            # Extract pass number: \"complete_pass_1\" -&gt; 1\n            pass_num = int(self.btn_state.split(\"_\")[2])\n            self.complete_pass(pass_num)\n        elif self.btn_state == \"finish\":\n            self.finish_sorting()\n\n    def update_progressive_button(self, state, text=None, color=None):\n        \"\"\"Update the progressive button's state, text, and color\"\"\"\n        self.btn_state = state\n\n        # Default text based on state\n        if text is None:\n            state_texts = {\n                \"setup\": \"\ud83d\ude80 Setup New Sorting Session\",\n                \"ready\": \"\u25b6\ufe0f Begin Sorting Session\",\n                \"finish\": \"\u2705 Finish Sorting Session\"\n            }\n\n            if state in state_texts:\n                text = state_texts[state]\n            elif state.startswith(\"pass_\"):\n                pass_num = int(state.split(\"_\")[1])\n                text = f\"\u25b6\ufe0f Begin Pass {pass_num}\"\n            elif state.startswith(\"complete_pass_\"):\n                pass_num = int(state.split(\"_\")[2])\n                text = f\"\u23f8\ufe0f Complete Pass {pass_num}\"\n\n        # Default color based on state\n        if color is None:\n            if state == \"setup\":\n                color = ACCENT_COLOR\n            elif state == \"ready\":\n                color = SUCCESS_COLOR\n            elif state.startswith(\"pass_\"):\n                color = SUCCESS_COLOR\n            elif state.startswith(\"complete_pass_\"):\n                color = WARNING_COLOR\n            elif state == \"finish\":\n                color = SUCCESS_COLOR\n\n        self.progressive_btn.configure(text=text, fg_color=color)\n\n    def open_setup_wizard(self):\n        \"\"\"Open the setup wizard modal\"\"\"\n        wizard = SetupWizard(self.root, self)\n        self.root.wait_window(wizard)\n\n    def begin_sorting_session(self):\n        \"\"\"Begin the sorting session after setup is complete\"\"\"\n        # Initialize the session\n        self.session_start_time = datetime.now()\n        self.objects_sorted.clear()\n        self.current_sort_index = 0\n        self.sorting_in_progress = False\n\n        # Reset servo-based counting\n        self.pass_counts = {}\n        self.current_pass_target_count = 0\n        self.current_pass_number = 0\n        self.first_pass_total = 0\n\n        # Initialize pass data file for this session\n        self.init_pass_data_file()\n\n        # Set mode\n        self.mode = \"sort\"\n\n        # Verify camera is active\n        if not self.feed_active:\n            messagebox.showerror(\"Error\", \"Camera feed must be active!\")\n            return\n\n        # Calculate passes\n        actual_passes = len(self.sort_classes) - 1 if len(self.sort_classes) &gt; 1 else len(self.sort_classes)\n        self.log(f\"\ud83d\ude80 Sorting session starting! ({actual_passes} pass(es) needed)\")\n        self.log(\"\ud83d\udca1 Click 'Begin Pass 1' to start first pass\")\n\n        # Update progressive button for first pass\n        self.update_progressive_button(\"pass_1\")\n\n        self.update_sidebar_stats()\n\n    def start_pass(self, pass_num):\n        \"\"\"Start a specific pass\"\"\"\n        self.start_next_pass()\n\n    def complete_pass(self, pass_num):\n        \"\"\"Complete a specific pass\"\"\"\n        self.pause_current_pass()\n\n    def create_checklist_item(self, parent, label_text):\n        \"\"\"Create a single checklist item with checkbox and label\"\"\"\n        item_frame = ctk.CTkFrame(parent, fg_color=CARD_BG, height=50)\n        item_frame.pack(fill=ctk.X, pady=5, padx=5)\n        item_frame.pack_propagate(False)\n\n        # Checkbox (we'll use a label that changes)\n        checkbox = ctk.CTkLabel(item_frame, text=\"\u2610\",\n                            font=(\"Segoe UI\", 20),\n                            text_color=TEXT_COLOR)\n        checkbox.pack(side=ctk.LEFT, padx=10)\n\n        # Label\n        label = ctk.CTkLabel(item_frame, text=label_text,\n                            font=(\"Segoe UI\", 12),\n                            anchor=ctk.W)\n        label.pack(side=ctk.LEFT, padx=5, fill=ctk.X, expand=True)\n\n        # Store both for easy updates\n        return {'checkbox': checkbox, 'label': label, 'frame': item_frame}\n\n    def update_checklist(self, item_name, is_complete):\n        \"\"\"Update a checklist item (check/uncheck)\"\"\"\n        checklist_map = {\n            'arduino': self.check_arduino,\n            'camera': self.check_camera,\n            'model': self.check_model,\n            'objects': self.check_objects\n        }\n\n        if item_name.lower() in checklist_map:\n            item = checklist_map[item_name.lower()]\n            if item is None:  # Safety check\n                return\n            if is_complete:\n                item['checkbox'].configure(text=\"\u2611\", text_color=SUCCESS_COLOR)\n                item['frame'].configure(fg_color=WINDOW_BG)\n            else:\n                item['checkbox'].configure(text=\"\u2610\", text_color=TEXT_COLOR)\n                item['frame'].configure(fg_color=CARD_BG)\n\n    def create_sidebar(self, parent):\n        sidebar = ctk.CTkFrame(parent, fg_color=CARD_BG, width=300)\n        sidebar.pack(side=ctk.RIGHT, fill=ctk.Y)\n        sidebar.pack_propagate(False)\n\n        # Sidebar title\n        sidebar_title = ctk.CTkLabel(sidebar, text=\"\ud83d\udcca Session Info\",\n                                    font=(\"Segoe UI\", 18, \"bold\"))\n        sidebar_title.pack(pady=(20, 10))\n\n        # Stats cards\n        self.create_stat_card(sidebar, \"\u23f1\ufe0f Session Time\", \"00:00:00\", \"time\")\n        self.create_stat_card(sidebar, \"\ud83d\udce6 Total Sorted\", \"0\", \"total\")\n        self.create_stat_card(sidebar, \"\ud83c\udfaf Current Target\", \"None\", \"target\")\n        self.create_stat_card(sidebar, \"\ud83d\udcc8 Throughput\", \"0 obj/min\", \"throughput\")\n\n        # Sorting progress\n        progress_frame = ctk.CTkFrame(sidebar, fg_color=WINDOW_BG)\n        progress_frame.pack(fill=ctk.X, padx=10, pady=10)\n\n        progress_label = ctk.CTkLabel(progress_frame, text=\"Sorting Progress\",\n                                    font=(\"Segoe UI\", 12, \"bold\"))\n        progress_label.pack(pady=5)\n\n        self.progress_bar = ctk.CTkProgressBar(progress_frame, \n                                            progress_color=SUCCESS_COLOR)\n        self.progress_bar.pack(fill=ctk.X, padx=10, pady=5)\n        self.progress_bar.set(0)\n\n        self.progress_text = ctk.CTkLabel(progress_frame, text=\"0/0 passes\",\n                                        font=(\"Segoe UI\", 10))\n        self.progress_text.pack()\n\n    def create_stat_card(self, parent, title, value, key):\n        card = ctk.CTkFrame(parent, fg_color=WINDOW_BG)\n        card.pack(fill=ctk.X, padx=10, pady=5)\n\n        title_label = ctk.CTkLabel(card, text=title, \n                                font=(\"Segoe UI\", 11),\n                                anchor=ctk.W)\n        title_label.pack(anchor=ctk.W, padx=10, pady=(5, 0))\n\n        value_label = ctk.CTkLabel(card, text=value,\n                                font=(\"Segoe UI\", 16, \"bold\"),\n                                text_color=ACCENT_COLOR,\n                                anchor=ctk.W)\n        value_label.pack(anchor=ctk.W, padx=10, pady=(0, 5))\n\n        # Store reference\n        setattr(self, f\"stat_{key}\", value_label)\n\n    def open_log_window(self):\n        \"\"\"Open the separate log window\"\"\"\n        if self.log_window:\n            self.log_window.show_window()\n\n    def clear_logs(self):\n        if self.log_window:\n            self.log_window.clear_logs()\n        self.log_messages.clear()\n\n    def log(self, message):\n        timestamp = datetime.now().strftime(\"[%H:%M:%S]\")\n        full_message = f\"{timestamp} {message}\"\n        self.log_messages.append(full_message)\n\n        # Add to log window if it exists\n        if self.log_window:\n            self.log_window.add_log(full_message)\n\n    def toggle_feed(self):\n        \"\"\"Stop live camera feed (used for cleanup)\"\"\"\n        if self.feed_active:\n            # Turn off feed\n            self.feed_active = False\n            self.is_running = False\n            if hasattr(self, \"cap\") and self.cap is not None and self.cap.isOpened():\n                try:\n                    self.cap.release()\n                except:\n                    pass\n                self.cap = None\n            self.video_frame.configure(image=self.placeholder_img)\n            self.video_frame.image = self.placeholder_img\n            if self.camera_status:\n                self.camera_status.configure(text=\"...\", text_color=...)\n            self.update_checklist('camera', False)  # \u274c Update checklist\n            self.log(\"\u23f8\ufe0f Live feed stopped\")\n\n    def test_camera(self, cam_index):\n        \"\"\"Test if a camera works and produces valid frames\"\"\"\n        try:\n            self.log(f\"\ud83d\udd0d Testing Camera {cam_index}...\")\n            test_cap = cv2.VideoCapture(cam_index, cv2.CAP_DSHOW if os.name == 'nt' else 0)\n\n            if test_cap is None or not test_cap.isOpened():\n                self.log(f\"\u274c Camera {cam_index}: Failed to open\")\n                if test_cap:\n                    test_cap.release()\n                return False\n\n            # Get camera properties\n            width = test_cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n            height = test_cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n            fps = test_cap.get(cv2.CAP_PROP_FPS)\n            self.log(f\"\ud83d\udcf9 Camera {cam_index} properties: {int(width)}x{int(height)} @ {fps:.1f}fps\")\n\n            # Try to read multiple frames to ensure camera is working\n            success_count = 0\n            frame_means = []\n            frame_sizes = []\n\n            for i in range(5):  # Test 5 frames\n                ret, test_frame = test_cap.read()\n\n                if ret and test_frame is not None and test_frame.size &gt; 0:\n                    mean_val = test_frame.mean()\n                    frame_means.append(mean_val)\n                    frame_sizes.append(test_frame.size)\n\n                    # Check if frame has variation (not static/frozen)\n                    std_val = test_frame.std()\n\n                    self.log(f\"  Frame {i+1}: mean={mean_val:.2f}, std={std_val:.2f}, size={test_frame.size}\")\n\n                    # Frame must have actual data AND some variation\n                    if mean_val &gt; 1.0 and std_val &gt; 1.0:  # Not blank AND not uniform\n                        success_count += 1\n                else:\n                    self.log(f\"  Frame {i+1}: Failed to read\")\n\n                time.sleep(0.1)  # Small delay between reads\n\n            test_cap.release()\n\n            # Check if frames are changing (live camera, not static image)\n            frames_vary = False\n            if len(frame_means) &gt;= 3:\n                mean_variation = max(frame_means) - min(frame_means)\n                self.log(f\"\ud83d\udcca Frame variation: {mean_variation:.2f}\")\n                if mean_variation &gt; 0.5:  # Frames are changing\n                    frames_vary = True\n\n            # Camera is valid if at least 3 out of 5 frames were good AND frames vary\n            if success_count &gt;= 3 and frames_vary:\n                self.log(f\"\u2705 Camera {cam_index} test PASSED ({success_count}/5 frames valid, variation detected)\")\n                return True\n            else:\n                self.log(f\"\u274c Camera {cam_index} test FAILED ({success_count}/5 frames valid, variation: {frames_vary})\")\n                return False\n\n        except Exception as e:\n            self.log(f\"\u274c Camera {cam_index} test error: {e}\")\n            return False\n\n    def start_camera_feed(self, cam_index):\n        \"\"\"Start camera feed with a specific camera index\"\"\"\n        # Stop existing feed if any\n        if self.feed_active:\n            self.toggle_feed()\n\n        # Update the camera index\n        self.camera_index = cam_index\n        # Note: camera_var is only in wizard, not main app anymore\n\n        # Open the camera\n        self.cap = cv2.VideoCapture(cam_index, cv2.CAP_DSHOW if os.name == 'nt' else 0)\n        if self.cap is None or not self.cap.isOpened():\n            if self.camera_status:\n                self.camera_status.configure(text=\"...\", text_color=...)\n            self.update_checklist('camera', False)\n            self.log(f\"\u274c Could not open Camera {cam_index}\")\n            self.cap = None\n            return False\n\n        # Verify camera works\n        ret, test_frame = self.cap.read()\n        if not ret or test_frame is None:\n            if self.camera_status:\n                self.camera_status.configure(text=\"...\", text_color=...)\n            self.update_checklist('camera', False)\n            self.log(f\"\u274c Camera {cam_index} opened but cannot read frames\")\n            self.cap.release()\n            self.cap = None\n            return False\n\n        # Success - start feed\n        self.feed_active = True\n        self.is_running = True\n        if self.camera_status:\n            self.camera_status.configure(text=\"...\", text_color=...)\n        self.update_checklist('camera', True)\n        self.log(f\"\u2705 Camera {cam_index} started successfully\")\n\n        # Start frame loop\n        self.update_frame()\n        return True\n\n    def update_sidebar_stats(self):\n        \"\"\"Update sidebar statistics\"\"\"\n        try:            \n            # Session time\n            if self.session_start_time:\n                elapsed = datetime.now() - self.session_start_time\n                hours = elapsed.seconds // 3600\n                minutes = (elapsed.seconds % 3600) // 60\n                seconds = elapsed.seconds % 60\n                self.stat_time.configure(text=f\"{hours:02d}:{minutes:02d}:{seconds:02d}\")\n\n                # Throughput (only calculate after first pass completes)\n                if elapsed.seconds &gt; 0 and self.first_pass_total &gt; 0:\n                    throughput = (self.first_pass_total / elapsed.seconds) * 60\n                    self.stat_throughput.configure(text=f\"{throughput:.1f} obj/min\")\n                else:\n                    self.stat_throughput.configure(text=\"--\")\n\n            # Total objects (from first pass)\n            if self.first_pass_total &gt; 0:\n                self.stat_total.configure(text=str(self.first_pass_total))\n            else:\n                self.stat_total.configure(text=\"--\")\n\n            # Current pass target count\n            if self.sorting_in_progress:\n                if self.current_pass_number == 1:\n                    # First pass shows total sweep count\n                    self.stat_pass_count.configure(text=f\"{self.current_pass_target_count} (all)\")\n                else:\n                    # Other passes show target count only\n                    self.stat_pass_count.configure(text=str(self.current_pass_target_count))\n            else:\n                self.stat_pass_count.configure(text=\"0\")\n\n            # Current target (with detection status indicator)\n            if self.current_target_class:\n                target_text = self.current_target_class\n\n                # Show detection buffer status\n                if len(self.detection_buffer) &gt; 0:\n                    confirmed = len(self.detection_buffer)\n                    needed = self.detection_confirmation_frames\n                    target_text = f\"{self.current_target_class} ({confirmed}/{needed})\"\n                elif hasattr(self, 'last_confirmed_time'):\n                    time_since = time.time() - self.last_confirmed_time\n                    if time_since &lt; DETECTION_COOLDOWN:\n                        target_text = f\"{self.current_target_class} \u23f1\ufe0f\"\n\n                self.stat_target.configure(text=target_text)\n            else:\n                self.stat_target.configure(text=\"None\")\n\n            # Force update\n            self.root.update_idletasks()\n\n        except Exception as e:\n            self.log(f\"\u274c Error updating stats: {e}\")\n\n        # Progress - show completed passes correctly\n        if self.sort_classes:\n            actual_passes = len(self.sort_classes) - 1 if len(self.sort_classes) &gt; 1 else len(self.sort_classes)\n            completed_passes = self.current_sort_index\n\n            progress = completed_passes / actual_passes if actual_passes &gt; 0 else 0\n            self.progress_bar.set(progress)\n\n            if self.sorting_in_progress:\n                self.progress_text.configure(text=f\"Pass {self.current_pass_number}/{actual_passes} active\")\n            else:\n                self.progress_text.configure(text=f\"{completed_passes}/{actual_passes} passes done\")\n        else:\n            self.progress_bar.set(0)\n            self.progress_text.configure(text=\"0/0 passes\")\n\n    def open_detection_window(self):\n        if self.model is None:\n            messagebox.showerror(\"Error\", \"Please load a model first!\")\n            return\n\n        detection_window = ImageDetectionWindow(self.root, self.model)\n        self.root.wait_window(detection_window)\n\n        if detection_window.detected_objects:\n            self.sort_classes = list(detection_window.detected_objects.keys())\n            self.log(f\"\u2705 Detected {len(self.sort_classes)} unique objects\")\n            self.log(f\"\ud83d\udccb Objects: {', '.join(self.sort_classes)}\")\n            self.update_checklist('objects', True)  # \u2705 Update checklist\n\n            # Show sorting order selection\n            self.show_sorting_order_dialog()\n\n    def show_sorting_order_dialog(self):\n        \"\"\"Allow user to customize sorting order with drag-and-drop\"\"\"\n        dialog = ctk.CTkToplevel(self.root)\n        dialog.title(\"Customize Sorting Order\")\n        dialog.geometry(\"500x650\")\n        dialog.transient(self.root)\n        dialog.grab_set()\n\n        main_frame = ctk.CTkFrame(dialog, fg_color=CARD_BG)\n        main_frame.pack(fill=ctk.BOTH, expand=True, padx=20, pady=20)\n\n        title = ctk.CTkLabel(main_frame, text=\"\ud83c\udfaf Customize Sorting Order\",\n                            font=(\"Segoe UI\", 20, \"bold\"), text_color=ACCENT_COLOR)\n        title.pack(pady=(10, 20))\n\n        info = ctk.CTkLabel(main_frame, \n                        text=\"Use \u2b06\ufe0f and \u2b07\ufe0f buttons to reorder. Uncheck to skip objects.\",\n                        font=(\"Segoe UI\", 12))\n        info.pack(pady=(0, 10))\n\n        # Scrollable frame for objects\n        scroll_frame = ctk.CTkScrollableFrame(main_frame, fg_color=WINDOW_BG, height=350)\n        scroll_frame.pack(fill=ctk.BOTH, expand=True, pady=10)\n\n        # Store references to object frames and their data\n        object_entries = []\n\n        def create_object_row(obj, index):\n            obj_frame = ctk.CTkFrame(scroll_frame, fg_color=CARD_BG)\n            obj_frame.pack(fill=ctk.X, pady=5, padx=5)\n\n            # Checkbox\n            var = ctk.BooleanVar(value=True)\n            cb = ctk.CTkCheckBox(obj_frame, text=\"\", variable=var, width=30)\n            cb.pack(side=ctk.LEFT, padx=10)\n\n            # Position number\n            position_label = ctk.CTkLabel(obj_frame, text=f\"{index+1}.\", \n                                        font=(\"Segoe UI\", 12, \"bold\"),\n                                        width=30)\n            position_label.pack(side=ctk.LEFT, padx=5)\n\n            # Object name entry\n            entry = ctk.CTkEntry(obj_frame, width=200, font=(\"Segoe UI\", 12))\n            entry.insert(0, obj)\n            entry.pack(side=ctk.LEFT, padx=10, fill=ctk.X, expand=True)\n\n            # Move buttons\n            btn_frame = ctk.CTkFrame(obj_frame, fg_color=CARD_BG)\n            btn_frame.pack(side=ctk.RIGHT, padx=5)\n\n            up_btn = ctk.CTkButton(btn_frame, text=\"\u2b06\ufe0f\", width=40, height=30,\n                                command=lambda: move_up(obj_frame))\n            up_btn.pack(side=ctk.LEFT, padx=2)\n\n            down_btn = ctk.CTkButton(btn_frame, text=\"\u2b07\ufe0f\", width=40, height=30,\n                                    command=lambda: move_down(obj_frame))\n            down_btn.pack(side=ctk.LEFT, padx=2)\n\n            return {\n                'frame': obj_frame,\n                'checkbox': var,\n                'entry': entry,\n                'position': position_label\n            }\n\n        def move_up(frame):\n            children = list(scroll_frame.winfo_children())\n            idx = children.index(frame)\n            if idx &gt; 0:\n                frame.pack_forget()\n                frame.pack(before=children[idx-1], fill=ctk.X, pady=5, padx=5)\n                update_positions()\n\n        def move_down(frame):\n            children = list(scroll_frame.winfo_children())\n            idx = children.index(frame)\n            if idx &lt; len(children) - 1:\n                frame.pack_forget()\n                children[idx+1].pack_forget()\n                frame.pack(fill=ctk.X, pady=5, padx=5)\n                children[idx+1].pack(fill=ctk.X, pady=5, padx=5)\n                update_positions()\n\n        def update_positions():\n            for i, child in enumerate(scroll_frame.winfo_children()):\n                # Find the position label in this frame\n                for widget in child.winfo_children():\n                    if isinstance(widget, ctk.CTkLabel) and widget.cget(\"text\").endswith(\".\"):\n                        widget.configure(text=f\"{i+1}.\")\n                        break\n\n        # Create all object rows\n        for i, obj in enumerate(self.sort_classes):\n            entry_data = create_object_row(obj, i)\n            object_entries.append(entry_data)\n\n        def confirm():\n            new_order = []\n            for child in scroll_frame.winfo_children():\n                # Extract data from each frame\n                checkbox_var = None\n                entry_widget = None\n\n                for widget in child.winfo_children():\n                    if isinstance(widget, ctk.CTkCheckBox):\n                        checkbox_var = widget.cget(\"variable\")\n                    elif isinstance(widget, ctk.CTkEntry):\n                        entry_widget = widget\n\n                if checkbox_var and entry_widget:\n                    if checkbox_var.get():  # If checked\n                        obj_name = entry_widget.get().strip()\n                        if obj_name:\n                            new_order.append(obj_name)\n\n            if not new_order:\n                messagebox.showerror(\"Error\", \"Please select at least one object!\")\n                return\n\n            self.sort_classes = new_order\n            actual_passes = len(self.sort_classes) - 1 if len(self.sort_classes) &gt; 1 else len(self.sort_classes)\n            self.log(f\"\u2705 Sorting order set: {', '.join(self.sort_classes)}\")\n            self.log(f\"\ud83d\udcca Will require {actual_passes} pass(es)\")\n\n            # Auto-send to Arduino after confirming order\n            # DISABLED - Wizard handles this in finish_wizard()\n            # if self.arduino and self.arduino.is_open:\n            #     self.send_objects_to_arduino()\n\n            dialog.destroy()\n\n        confirm_btn = ctk.CTkButton(main_frame, text=\"\u2705 Confirm Order\",\n                                command=confirm, height=40,\n                                font=(\"Segoe UI\", 14, \"bold\"),\n                                fg_color=SUCCESS_COLOR, hover_color=\"#00cc66\")\n        confirm_btn.pack(pady=10)\n\n    def send_objects_to_arduino(self):\n        \"\"\"Manual function to send detected objects to Arduino\"\"\"\n        if self.arduino is None or not self.arduino.is_open:\n            messagebox.showerror(\"Error\", \"Arduino not connected!\")\n            return\n\n        if not self.sort_classes:\n            messagebox.showerror(\"Error\", \"No objects detected! Please use 'Detect Objects' first.\")\n            return\n\n        self.log(\"\ud83d\udce4 Sending objects to Arduino EEPROM...\")\n        if not send_objects_to_eeprom(self.sort_classes, self.arduino):\n            messagebox.showerror(\"Error\", \"Failed to send objects to Arduino!\")\n            return\n\n        self.log(f\"\u2705 Sent {len(self.sort_classes)} objects to Arduino\")\n        self.log(\"\u23f3 Waiting for Arduino confirmation...\")\n        self.arduino_ready_to_sort = True  # Mark as ready\n\n        # Update progressive button to \"ready\" state\n        self.update_progressive_button(\"ready\")\n\n        messagebox.showinfo(\"Success\", f\"Sent {len(self.sort_classes)} objects to Arduino!\\n\\nObjects: {', '.join(self.sort_classes)}\")\n\n    def start_sorting_session(self):\n        if self.model is None:\n            messagebox.showerror(\"Error\", \"Please load a model first!\")\n            return\n\n        if self.arduino is None or not self.arduino.is_open:\n            messagebox.showerror(\"Error\", \"Arduino not connected!\")\n            return\n\n        if not self.sort_classes:\n            messagebox.showerror(\"Error\", \"Please detect objects first!\")\n            return\n\n        if not self.arduino_ready_to_sort:\n            messagebox.showerror(\"Error\", \"Please send objects to Arduino first!\\n\\nClick '\ud83d\udce4 Send Objects to Arduino' button.\")\n            return\n\n        # Initialize statistics\n        self.session_start_time = datetime.now()\n        self.objects_sorted.clear()\n        self.current_sort_index = 0\n        self.sorting_in_progress = False\n\n        # Reset servo-based counting\n        self.pass_servo_counts = {}\n        self.current_pass_servo_count = 0\n        self.total_servo_movements = 0\n        self.first_pass_total = 0\n\n        # Enable controls\n        self.next_pass_btn.configure(state=ctk.NORMAL)\n        self.finish_btn.configure(state=ctk.NORMAL)\n\n        # Set mode\n        self.mode = \"sort\"\n\n        # Ensure camera feed is running\n        if not self.feed_active:\n            messagebox.showerror(\"Error\", \"Camera feed must be active!\\n\\nPlease start camera from Setup Wizard first.\")\n            return\n\n        self.log(\"\ud83d\udcf9 Using active camera feed for sorting\")\n\n        actual_passes = len(self.sort_classes) - 1 if len(self.sort_classes) &gt; 1 else len(self.sort_classes)\n        self.log(f\"\ud83d\ude80 Sorting session ready! ({actual_passes} pass(es) needed)\")\n        self.log(\"\ud83d\udca1 Click 'Begin Pass 1' to start\")\n\n        # Update progressive button for first pass\n        self.update_progressive_button(\"pass_1\")\n\n        self.update_sidebar_stats()\n\n    def start_next_pass(self):\n        actual_passes = len(self.sort_classes) - 1 if len(self.sort_classes) &gt; 1 else len(self.sort_classes)\n\n        if self.current_sort_index &gt;= actual_passes:\n            self.log(\"\u2705 All passes completed!\")\n            self.finish_sorting()\n            return\n\n        # Reset counters for new pass\n        self.current_pass_target_count = 0\n        self.current_pass_number = self.current_sort_index + 1\n        self.last_detection_time = 0\n\n        # Reset detection buffer for new pass\n        self.detection_buffer = []\n        self.last_confirmed_detection = None\n        self.last_confirmed_time = 0\n\n        self.current_target_class = self.sort_classes[self.current_sort_index]\n        self.sorting_in_progress = True\n\n        pass_num = self.current_pass_number\n        self.log(f\"\u25b6\ufe0f Pass {pass_num}/{actual_passes}: Sorting '{self.current_target_class}'\")\n\n        if pass_num == 1:\n            self.log(f\"\ud83d\udcca FIRST PASS - Will count ALL objects (target + non-target)\")\n        else:\n            self.log(f\"\ud83c\udfaf Pass {pass_num} - Counting TARGET objects only\")\n\n        # Disable button during active sorting\n        self.progressive_btn.configure(state=ctk.DISABLED, text=f\"\u23f3 Pass {pass_num} Active...\")\n\n        self.log(f\"\ud83d\udfe2 GREEN LED: Feed objects now\")\n\n        # Send commands to Arduino in sequence\n        self.send_to_arduino(f\"SET_TARGET:{self.current_target_class}\")\n        time.sleep(0.1)  # Small delay between commands\n        self.send_to_arduino(\"GREEN_LED_ON\")\n        time.sleep(0.1)  # Small delay between commands\n\n        self.log(\"\ud83d\udd04 Starting new pass - Waiting for servo movements...\")\n\n        self.update_sidebar_stats()\n\n        # Update progressive button to \"Complete Pass N\" and re-enable\n        actual_passes = len(self.sort_classes) - 1 if len(self.sort_classes) &gt; 1 else len(self.sort_classes)\n\n        if self.current_sort_index + 1 == actual_passes:\n            # This is the LAST pass\n            self.update_progressive_button(f\"complete_pass_{pass_num}\", \n                                        text=f\"\u23f8\ufe0f Finish Pass {pass_num}\")\n        else:\n            # Not the last pass\n            self.update_progressive_button(f\"complete_pass_{pass_num}\",\n                                        text=f\"\u23f8\ufe0f Complete Pass {pass_num}\")\n\n        # Re-enable button now that sorting is active\n        self.progressive_btn.configure(state=ctk.NORMAL)\n\n        # Force sidebar update to show new target\n        self.update_sidebar_stats()\n\n    def pause_current_pass(self):\n        if self.sorting_in_progress:\n            self.sorting_in_progress = False\n\n            pass_num = self.current_sort_index + 1\n            self.log(f\"\u23f8\ufe0f Pausing pass {pass_num}...\")\n\n            # Calculate total passes needed (used throughout this method)\n            actual_passes = len(self.sort_classes) - 1 if len(self.sort_classes) &gt; 1 else len(self.sort_classes)\n\n            # Disable the progressive button immediately\n            self.progressive_btn.configure(state=ctk.DISABLED, text=\"\u23f3 Processing...\")\n\n            # Check Arduino connection\n            if not self.arduino or not self.arduino.is_open:\n                self.log(\"\u274c Arduino not connected! Cannot receive pass data.\")\n                messagebox.showerror(\"Arduino Error\", \"Arduino is not connected!\\n\\nPass data will not be recorded.\")\n            else:\n                # Mark which pass we're waiting for\n                self.waiting_for_pass_data = self.current_pass_number\n                initial_pass_count = len(self.pass_counts)\n\n                # Send PAUSE_SORT once\n                self.log(f\"\ud83d\udce4 Sending PAUSE_SORT to Arduino (Pass {self.current_pass_number})...\")\n                self.send_to_arduino(\"PAUSE_SORT\")\n\n                # Log what we're expecting\n                self.log(f\"\ud83d\udccb Expecting data for pass {self.current_pass_number} (target: {self.current_target_class})\")\n\n                # Wait for response with longer timeout\n                self.log(\"\u23f3 Waiting for PASS_COMPLETE message...\")\n                start_wait = time.time()\n                timeout = 3.0  # 3 second timeout (Arduino sends after 1s + delays)\n\n                while (time.time() - start_wait) &lt; timeout:\n                    # Check Arduino connection\n                    if not self.arduino or not self.arduino.is_open:\n                        self.log(\"\u274c Arduino disconnected!\")\n                        break\n\n                    # Check if we received new pass data\n                    if len(self.pass_counts) &gt; initial_pass_count:\n                        elapsed = time.time() - start_wait\n                        self.log(f\"\u2705 Pass data received after {elapsed:.2f}s\")\n                        break\n\n                    # Allow event loop to process messages\n                    self.root.update()\n                    time.sleep(0.05)  # Check every 50ms\n                else:\n                    # Timeout - FATAL ERROR\n                    self.log(f\"\u274c FATAL: No pass data received after {timeout}s\")\n                    self.log(f\"\u274c Arduino communication failed - aborting session\")\n\n                    # Stop everything\n                    self.sorting_in_progress = False\n                    self.is_running = False\n                    self.mode = None\n\n                    # Turn off LEDs\n                    self.send_to_arduino(\"RED_LED_OFF\")\n                    self.send_to_arduino(\"GREEN_LED_OFF\")\n\n                    # Show error and reset\n                    messagebox.showerror(\n                        \"Communication Failure\",\n                        f\"Arduino failed to respond for Pass {self.current_pass_number}!\\n\\n\"\n                        f\"Possible causes:\\n\"\n                        f\"\u2022 Arduino disconnected\\n\"\n                        f\"\u2022 Serial communication error\\n\"\n                        f\"\u2022 Arduino firmware issue\\n\\n\"\n                        f\"The sorting session has been aborted.\\n\"\n                        f\"Please check connections and restart.\"\n                    )\n\n                    # Reset to initial state\n                    self.video_frame.configure(image=self.placeholder_img)\n                    self.video_frame.image = self.placeholder_img\n                    self.update_progressive_button(\"setup\")\n                    self.progressive_btn.configure(state=ctk.NORMAL)\n\n                    return  # Exit - session is aborted\n\n            self.log(f\"\ud83d\udd34 RED LED: Stop feeding objects\")\n\n            # Increment AFTER pausing (actual_passes already calculated above)\n            self.current_sort_index += 1\n\n            # Update button state based on whether there are more passes\n            if self.current_sort_index &lt; actual_passes:\n                next_pass = self.current_sort_index + 1\n                self.log(f\"\ud83d\udccb Next pass will sort: '{self.sort_classes[self.current_sort_index]}'\")\n                self.update_progressive_button(f\"pass_{next_pass}\", text=f\"\u25b6\ufe0f Begin Pass {next_pass}\")\n                # Re-enable button NOW that data is received\n                self.progressive_btn.configure(state=ctk.NORMAL)\n            else:\n                self.log(\"\ud83c\udf89 All passes completed!\")\n                self.update_progressive_button(\"finish\", text=\"\u2705 Finish Sorting Session\")\n                # Re-enable button NOW that data is received\n                self.progressive_btn.configure(state=ctk.NORMAL)\n\n            # Force UI update\n            self.root.update_idletasks()\n\n    def finish_sorting(self):\n        self.sorting_in_progress = False\n        self.is_running = False\n        self.mode = None\n\n        # Final request for counts from Arduino\n        time.sleep(0.5)\n\n        # Load all pass data from file\n        pass_data = self.load_pass_data()\n\n        # DEBUG: Log what we loaded\n        self.log(f\"\ud83d\udd0d DEBUG: Loaded pass_data: {pass_data}\")\n        self.log(f\"\ud83d\udd0d DEBUG: self.pass_counts: {self.pass_counts}\")\n        self.log(f\"\ud83d\udd0d DEBUG: self.first_pass_total: {self.first_pass_total}\")\n        self.log(f\"\ud83d\udd0d DEBUG: self.sort_classes: {self.sort_classes}\")\n\n        # Calculate statistics\n        session_duration = datetime.now() - self.session_start_time if self.session_start_time else None\n\n        stats = {\n            \"Session Duration\": str(session_duration).split('.')[0] if session_duration else \"N/A\",\n            \"Total Objects Sorted\": str(self.first_pass_total) if self.first_pass_total &gt; 0 else \"N/A\",\n            \"Unique Object Types\": len(self.sort_classes),\n            \"Passes Completed\": len(pass_data['passes'])\n        }\n\n        # Object breakdown\n        stats[\"\"] = \"\"\n        stats[\"\ud83d\udce6 Object Breakdown:\"] = \"\"\n\n        # Calculate each object count\n        object_counts = {}\n\n        for pass_info in pass_data['passes']:\n            class_name = pass_info.get('class', 'Unknown')\n            target_count = pass_info.get('target_count', 0)\n            object_counts[class_name] = target_count\n\n        # For last object (if we completed all passes)\n        if len(self.sort_classes) &gt; 1 and self.first_pass_total &gt; 0:\n            total_accounted = sum(object_counts.values())\n            last_object = self.sort_classes[-1]\n\n            if last_object not in object_counts:\n                last_count = self.first_pass_total - total_accounted\n                object_counts[last_object] = last_count\n                self.log(f\"  Final object ({last_object}): {last_count} (calculated)\")\n\n        # Display object counts in order\n        for obj_class in self.sort_classes:\n            if obj_class in object_counts:\n                stats[f\"  \u2022 {obj_class}\"] = f\"{object_counts[obj_class]} objects\"\n\n        # Throughput\n        if session_duration and session_duration.seconds &gt; 0 and self.first_pass_total &gt; 0:\n            throughput = (self.first_pass_total / session_duration.seconds) * 60\n            stats[\"\"] = \"\"\n            stats[\"\u26a1 Average Throughput\"] = f\"{throughput:.2f} objects/min\"\n\n        self.log(\"\u2705 Sorting session finished\")\n        self.log(f\"\ud83d\udcca Final Statistics:\")\n        self.log(f\"   Total Objects: {self.first_pass_total}\")\n        for obj_class, count in object_counts.items():\n            self.log(f\"   \u2022 {obj_class}: {count}\")\n\n        # Cleanup Arduino\n        self.send_to_arduino(\"FINISH_SORT\")\n        self.send_to_arduino(\"RED_LED_OFF\")\n        self.send_to_arduino(\"GREEN_LED_OFF\")\n\n        # Clear pass data file\n        self.clear_pass_data_file()\n\n        # Reset UI\n        self.video_frame.configure(image=self.placeholder_img)\n        self.video_frame.image = self.placeholder_img\n        self.update_progressive_button(\"setup\")\n\n        # Show stats window\n        StatsWindow(self.root, stats)\n\n    def update_frame(self):\n        if not self.is_running or not self.feed_active:\n            return\n\n        ret, frame = self.cap.read()\n        if not ret:\n            self.log(\"\u274c Failed to grab frame\")\n            self.stop_detection()\n            return\n\n        # Only run YOLO if model is loaded and we're in sort mode\n        if self.model and self.mode == \"sort\" and self.sorting_in_progress:\n            # Run detection with performance settings\n            results = self.model(frame, conf=YOLO_CONF_THRESHOLD, imgsz=YOLO_IMG_SIZE, verbose=False)[0]\n            annotated = results.plot()\n            self.handle_sorting(results)\n        elif self.model:\n            # Just annotate without processing\n            results = self.model(frame, conf=YOLO_CONF_THRESHOLD, imgsz=YOLO_IMG_SIZE, verbose=False)[0]\n            annotated = results.plot()\n        else:\n            # No model, just show raw feed\n            annotated = frame\n\n        # Display frame (optimized)\n        rgb_frame = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n        img = Image.fromarray(rgb_frame)\n\n        # Resize for display (fixed size for performance)\n        display_width, display_height = 640, 480\n        img = img.resize((display_width, display_height), Image.NEAREST)\n\n        ctk_img = CTkImage(light_image=img, dark_image=img, size=(display_width, display_height))\n        self.video_frame.configure(image=ctk_img)\n        self.video_frame.image = ctk_img\n\n        # Update stats less frequently\n        if hasattr(self, '_frame_count'):\n            self._frame_count += 1\n            if self._frame_count % 10 == 0:  # Update stats every 10 frames\n                self.update_sidebar_stats()\n        else:\n            self._frame_count = 0\n\n        self.root.after(FRAME_RATE_MS, self.update_frame)\n\n    def handle_sorting(self, results):\n        \"\"\"\n        Multi-frame detection confirmation handler.\n        Requires consistent detection across multiple frames before acting.\n        This prevents false positives from shadows, lighting changes, or brief occlusions.\n        \"\"\"\n        if not self.current_target_class:\n            return\n\n        current_time = time.time()\n\n        # Check global cooldown (prevent processing same object multiple times)\n        if current_time - self.last_confirmed_time &lt; DETECTION_COOLDOWN:\n            return  # Still in cooldown from last confirmed detection\n\n        # Extract detected class from results\n        detected_class = None\n        if len(results.boxes) &gt; 0:\n            # Get highest confidence detection\n            best_box = max(results.boxes, key=lambda box: float(box.conf[0]))\n            cls_id = int(best_box.cls[0])\n            detected_class = self.model.names[cls_id]\n            confidence = float(best_box.conf[0])\n\n            # Log detection with confidence\n            if detected_class == self.current_target_class:\n                self.log(f\"\ud83d\udc41\ufe0f Detecting: {detected_class} (conf: {confidence:.2f})\")\n            else:\n                self.log(f\"\ud83d\udc41\ufe0f Detecting: {detected_class} (conf: {confidence:.2f})\")\n\n        # Add to detection buffer\n        self.detection_buffer.append({\n            'class': detected_class,\n            'time': current_time\n        })\n\n        # Keep only recent detections (last N frames)\n        buffer_window = self.detection_confirmation_frames\n        self.detection_buffer = self.detection_buffer[-buffer_window:]\n\n        # Check if we have enough frames\n        if len(self.detection_buffer) &lt; self.detection_confirmation_frames:\n            return  # Not enough data yet\n\n        # Check if all recent detections are the same class\n        detected_classes = [d['class'] for d in self.detection_buffer]\n\n        # All detections must be non-None and the same\n        if None in detected_classes:\n            return  # Some frames had no detection\n\n        if len(set(detected_classes)) == 1:\n            # All frames detected the same object!\n            confirmed_class = detected_classes[0]\n\n            # Prevent re-confirming the same object\n            if confirmed_class == self.last_confirmed_detection:\n                return  # Already processed this object\n\n            # CONFIRMED DETECTION - Send to Arduino\n            self.last_confirmed_detection = confirmed_class\n            self.last_confirmed_time = current_time\n\n            if confirmed_class == self.current_target_class:\n                self.log(f\"\u2705 CONFIRMED TARGET: {confirmed_class} ({self.detection_confirmation_frames} frames)\")\n                self.send_to_arduino(f\"SORT_TARGET:{confirmed_class}\")\n            else:\n                self.log(f\"\u2705 CONFIRMED OTHER: {confirmed_class} ({self.detection_confirmation_frames} frames)\")\n                self.send_to_arduino(f\"SORT_OTHER:{confirmed_class}\")\n\n            # Clear ALL detection state immediately\n            self.detection_buffer = []\n            self.last_confirmed_detection = None  # Allow same object to be detected again after it's sorted\n\n            self.log(f\"\u23f3 Waiting {DETECTION_COOLDOWN}s for object to move...\")\n        else:\n            # Inconsistent detections - keep waiting\n            unique_classes = set(d for d in detected_classes if d is not None)\n            if len(unique_classes) &gt; 1:\n                self.log(f\"\u26a0\ufe0f Inconsistent detections: {unique_classes}\")\n\n    def reset_session(self):\n        \"\"\"Reset the application to initial state without closing\"\"\"\n        # Confirm with user\n        confirm = messagebox.askyesno(\n            \"Reset Session\", \n            \"This will clear all current data:\\n\\n\"\n            \"\u2022 Loaded model\\n\"\n            \"\u2022 Detected objects\\n\"\n            \"\u2022 Session statistics\\n\"\n            \"\u2022 Arduino object list\\n\\n\"\n            \"Are you sure you want to reset?\"\n        )\n\n        if not confirm:\n            return\n\n        # Stop any active sorting/detection\n        self.is_running = False\n        self.feed_active = False\n        self.sorting_in_progress = False\n        self.mode = None\n\n        # Reset model\n        self.model = None\n        self.model_path = \"\"\n        self.update_checklist('model', False)  # \u274c Reset checklist\n        self.update_checklist('objects', False)  # \u274c Reset checklist\n\n        # Reset camera if feed is active\n        if self.feed_active:\n            self.toggle_feed()\n        self.update_checklist('camera', False)  # \u274c Reset checklist\n\n        # Reset sorting data\n        self.sort_classes = []\n        self.current_sort_index = 0\n        self.current_target_class = None\n        self.arduino_ready_to_sort = False\n\n        # Reset servo counting\n        self.pass_counts = {}\n        self.current_pass_target_count = 0\n        self.current_pass_number = 0\n        self.first_pass_total = 0\n\n        # Clear pass data file\n        self.init_pass_data_file()\n\n        # Reset statistics\n        self.session_start_time = None\n        self.objects_sorted.clear()\n\n        # Clear Arduino EEPROM\n        if self.arduino and self.arduino.is_open:\n            self.send_to_arduino(\"CLEAR_OBJECTS\")\n\n        # Reset UI\n        self.video_frame.configure(image=self.placeholder_img)\n        self.video_frame.image = self.placeholder_img\n\n        # Reset progressive button\n        self.update_progressive_button(\"setup\")\n\n        # Update sidebar\n        self.stat_time.configure(text=\"00:00:00\")\n        self.stat_total.configure(text=\"0\")\n        self.stat_target.configure(text=\"None\")\n        self.stat_throughput.configure(text=\"0 obj/min\")\n        self.progress_bar.set(0)\n        self.progress_text.configure(text=\"0/0 passes\")\n\n        # Turn off LEDs\n        self.send_to_arduino(\"RED_LED_OFF\")\n        self.send_to_arduino(\"GREEN_LED_OFF\")\n\n        self.log(\"\ud83d\udd04 Session reset - Ready for new sorting task\")\n        messagebox.showinfo(\"Reset Complete\", \"Application has been reset.\\n\\nYou can now start a new sorting session.\")\n\n    def stop_detection(self):\n        self.is_running = False\n        self.feed_active = False\n        self.mode = None\n        self.video_frame.configure(image=self.placeholder_img)\n        self.video_frame.image = self.placeholder_img\n        self.feed_toggle_btn.configure(text=\"\u25b6\ufe0f Start Feed\", fg_color=SUCCESS_COLOR)\n        self.send_to_arduino(\"stop\")\n        self.log(\"\ud83d\uded1 Detection stopped\")\n\n    def connect_to_arduino(self):\n        \"\"\"Connect or reconnect to Arduino\"\"\"\n        # Check if already connected\n        if self.arduino and self.arduino.is_open:\n            self.log(\"\u26a0\ufe0f Arduino already connected, skipping reconnect\")\n            return\n\n        port = find_arduino_port()\n        if port:\n            try:\n                self.arduino = serial.Serial(port, 9600, timeout=2)\n                self.log(f\"\ud83d\udfe1 Connecting to Arduino on {port}...\")\n\n                time.sleep(2)\n\n                start_time = time.time()\n                ready_line = \"\"\n                while time.time() - start_time &lt; 5:\n                    if self.arduino.in_waiting &gt; 0:\n                        ready_line = self.arduino.readline().decode().strip()\n                        if ready_line == \"READY\":\n                            break\n                        elif ready_line:\n                            self.log(f\"Arduino: {ready_line}\")\n\n                if ready_line == \"READY\":\n                    self.log(\"\u2705 Arduino connected!\")\n                    if self.arduino_status:\n                        self.arduino_status.configure(text=\"\ud83d\udfe2 Arduino\", text_color=SUCCESS_COLOR)\n                    self.update_checklist('arduino', True)  # \u2705 Update checklist\n                    self.log(\"\ud83c\udfa7 Starting Arduino listener thread...\")\n                    self.start_arduino_listener()\n                    self.log(\"\u2705 Arduino listener thread started\")\n                else:\n                    self.log(f\"\u26a0\ufe0f Unexpected response: {ready_line}\")\n                    if self.arduino_status:\n                        self.arduino_status.configure(text=\"\u26a0\ufe0f Arduino\", text_color=WARNING_COLOR)\n                    self.update_checklist('arduino', False)  # \u274c Update checklist\n            except Exception as e:\n                self.log(f\"\u274c Connection failed: {e}\")\n                if self.arduino_status:\n                    self.arduino_status.configure(text=\"\ud83d\udd34 Arduino\", text_color=ERROR_COLOR)\n                self.update_checklist('arduino', False)  # \u274c Update checklist\n        else:\n            self.log(\"\u26a0\ufe0f No Arduino detected\")\n            if self.arduino_status:\n                self.arduino_status.configure(text=\"\ud83d\udd34 Arduino\", text_color=ERROR_COLOR)\n            self.update_checklist('arduino', False)  # \u274c Update checklist\n\n            # Re-enable reconnect if it exists (for wizard compatibility)\n            if hasattr(self, 'reconnect_btn') and self.reconnect_btn:\n                self.reconnect_btn.configure(state=ctk.NORMAL, text=\"Reconnect\")\n\n    def start_arduino_listener(self):\n        def listen():\n            self.log(\"\ud83c\udfa7 Arduino listener thread started\")\n            while self.arduino and self.arduino.is_open:\n                try:\n                    if self.arduino.in_waiting &gt; 0:\n                        message = self.arduino.readline().decode().strip()\n                        if message:\n                            self.log(f\"\ud83d\udce5 Arduino raw: {message}\")  # Log EVERY message\n\n                            # Process message\n                            if message == \"READY_TO_SORT\":\n                                self.arduino_ready_to_sort = True\n                                self.log(\"\ud83d\udfe2 Arduino ready to sort\")\n                            elif message.startswith(\"SORTED_TARGET:\"):\n                                try:\n                                    count = int(message.split(\":\")[1])\n                                    self.current_pass_target_count = count\n                                    self.log(f\"\ud83c\udfaf TARGET servo movement detected (count: {count})\")\n                                    self.root.after_idle(self.update_sidebar_stats)\n                                except Exception as e:\n                                    self.log(f\"\u274c Error parsing SORTED_TARGET: {e}\")\n                            elif message.startswith(\"SORTED_OTHER:\"):\n                                try:\n                                    count = int(message.split(\":\")[1])\n                                    self.log(f\"\ud83d\udce6 OTHER servo movement detected\")\n                                except Exception as e:\n                                    self.log(f\"\u274c Error parsing SORTED_OTHER: {e}\")\n                            elif message.startswith(\"PASS_COMPLETE:\"):\n                                try:\n                                    parts = message.split(\":\")\n                                    target_count = int(parts[1]) if len(parts) &gt; 1 else 0\n                                    other_count = int(parts[2]) if len(parts) &gt; 2 else 0\n                                    total_count = target_count + other_count\n\n                                    # Check if we're waiting for pass data\n                                    if hasattr(self, 'waiting_for_pass_data') and self.waiting_for_pass_data is not None:\n                                        expected_pass = self.waiting_for_pass_data\n\n                                        # Check if we already processed this pass\n                                        if expected_pass in self.pass_counts:\n                                            # Duplicate - Arduino sends 3 times, ignore extras\n                                            continue\n\n                                        self.log(f\"\ud83d\udce5 PASS_COMPLETE received for pass {expected_pass}\")\n                                        self.log(f\"   \ud83c\udfaf Target: {target_count}\")\n                                        self.log(f\"   \ud83d\udce6 Other: {other_count}\")\n                                        self.log(f\"   \ud83d\udcc8 Total: {total_count}\")\n\n                                        # Clear the wait flag immediately\n                                        self.waiting_for_pass_data = None\n                                    else:\n                                        # Not waiting - ignore\n                                        continue\n\n                                    pass_num = self.current_pass_number\n                                    target_class = self.current_target_class\n\n                                    self.log(f\"\ud83d\udcca Pass {pass_num} complete:\")\n                                    self.log(f\"   \ud83c\udfaf Target ({target_class}): {target_count}\")\n                                    self.log(f\"   \ud83d\udce6 Non-target: {other_count}\")\n                                    self.log(f\"   \ud83d\udcc8 Total: {total_count}\")\n\n                                    if pass_num == 1:\n                                        self.first_pass_total = total_count\n                                        self.log(f\"\u2705 FIRST PASS TOTAL (Ground Truth): {total_count} objects\")\n\n                                        self.pass_counts[pass_num] = {\n                                            'pass': pass_num,\n                                            'class': target_class,\n                                            'target_count': target_count,\n                                            'other_count': other_count,\n                                            'total': total_count\n                                        }\n                                    else:\n                                        self.pass_counts[pass_num] = {\n                                            'pass': pass_num,\n                                            'class': target_class,\n                                            'target_count': target_count\n                                        }\n\n                                    self.log(f\"\ud83d\udcbe Saving pass_counts: {self.pass_counts}\")\n                                    self.save_pass_data()\n\n                                    self.current_pass_target_count = target_count\n                                    self.root.after(1, self.update_sidebar_stats)\n\n                                except Exception as e:\n                                    self.log(f\"\u274c Error processing pass completion: {e}\")\n                                    import traceback\n                                    self.log(f\"\u274c Traceback: {traceback.format_exc()}\")\n                            elif message.startswith(\"CURRENT_PASS_TARGET:\"):\n                                try:\n                                    count = int(message.split(\":\")[1])\n                                    self.current_pass_target_count = count\n                                    self.root.after_idle(self.update_sidebar_stats)\n                                except Exception as e:\n                                    self.log(f\"\u274c Error parsing CURRENT_PASS_TARGET: {e}\")\n                            elif message.startswith(\"CURRENT_PASS_OTHER:\"):\n                                pass  # Just for logging, we don't display this separately\n                            else:\n                                self.log(f\"Arduino: {message}\")\n\n                    # Small sleep to prevent CPU hogging\n                    time.sleep(0.01)\n                except Exception as e:\n                    if self.arduino and self.arduino.is_open:\n                        self.log(f\"\u274c Error reading Arduino: {e}\")\n                        import traceback\n                        self.log(f\"\u274c Traceback: {traceback.format_exc()}\")\n                    break\n\n            self.log(\"\ud83d\uded1 Arduino listener thread stopped\")\n\n        listener_thread = threading.Thread(target=listen, daemon=True)\n        listener_thread.start()\n\n    def send_to_arduino(self, message):\n        try:\n            if self.arduino and self.arduino.is_open:\n                self.arduino.write((message + \"\\n\").encode())\n                # Log every message we send\n                self.log(f\"\ud83d\udce4 TO ARDUINO: {message}\")\n                # Flush the serial buffer to ensure immediate send\n                self.arduino.flush()\n        except Exception as e:\n            self.log(f\"\u274c Error sending to Arduino: {e}\")\n\n    def exit_app(self):\n        \"\"\"Exit application with confirmation\"\"\"\n        # Check if sorting is active\n        if self.sorting_in_progress:\n            confirm = messagebox.askyesno(\n                \"Exit Application\",\n                \"Sorting session is currently active!\\n\\n\"\n                \"Are you sure you want to exit?\\n\"\n                \"All progress will be lost.\"\n            )\n        else:\n            confirm = messagebox.askyesno(\n                \"Exit Application\",\n                \"Are you sure you want to exit?\"\n            )\n\n        if not confirm:\n            return\n\n        self.log(\"\ud83d\udc4b Exiting application...\")\n        self.is_running = False\n\n        try:\n            if self.arduino and self.arduino.is_open:\n                self.send_to_arduino(\"CLEAR_OBJECTS\")\n                self.send_to_arduino(\"RED_LED_OFF\")\n                self.send_to_arduino(\"GREEN_LED_OFF\")\n                time.sleep(0.5)\n                self.arduino.close()\n        except:\n            pass\n\n        try:\n            if hasattr(self, 'cap') and self.cap and self.cap.isOpened():\n                self.cap.release()\n        except:\n            pass\n\n        try:\n            cv2.destroyAllWindows()\n        except:\n            pass\n\n        self.root.quit()\n        self.root.destroy()\n\n# ---------------------------\n# \ud83d\ude80 Main Entry Point\n# ---------------------------\nif __name__ == \"__main__\":\n    import os\n    import traceback\n    os.environ['OPENCV_LOG_LEVEL'] = 'ERROR'\n\n    try:\n        root = ctk.CTk()\n        root.withdraw()\n\n        # Show splash screen\n        splash = SplashScreen(root)\n        splash.update()\n\n        # Step 1: Detect cameras\n        splash.update_progress(0.2, \"\ud83d\udd0d Detecting cameras...\")\n        time.sleep(0.3)\n        cameras = detect_cameras()\n\n        # Step 2: Initialize UI (skip camera selection dialog)\n        splash.update_progress(0.6, \"\ud83c\udfa8 Building interface...\")\n        time.sleep(0.3)\n\n        root.deiconify()\n        root.update()\n\n        splash.update_progress(0.8, \"\ud83e\udd16 Initializing systems...\")\n        time.sleep(0.2)\n\n        # Pass the camera list but not a selected one yet\n        app = YOLOApp(root, None, cameras)\n\n        splash.update_progress(1.0, \"\u2705 Ready!\")\n        time.sleep(0.3)\n\n        splash.close()\n\n        # Start app\n        if app.initialized:\n            root.protocol(\"WM_DELETE_WINDOW\", app.exit_app)\n            root.mainloop()\n        else:\n            root.quit()\n\n    except Exception as e:\n        try:\n            splash.close()\n        except:\n            pass\n        print(f\"\\n{'='*60}\")\n        print(f\"FATAL ERROR: {type(e).__name__}\")\n        print(f\"{'='*60}\")\n        print(f\"Error message: {e}\")\n        print(f\"\\nFull traceback:\")\n        traceback.print_exc()\n        print(f\"{'='*60}\\n\")\n\n        try:\n            messagebox.showerror(\"Fatal Error\", f\"Application crashed:\\n{type(e).__name__}: {e}\\n\\nCheck console for details\")\n        except:\n            pass\n        try:\n            root.quit()\n        except:\n            pass\n</code></pre>"},{"location":"software_v3/#arduino","title":"Arduino","text":"View Full Arduino Code (Click to Expand) arduino_v3.ino<pre><code>#include &lt;Arduino.h&gt;\n#include &lt;EEPROM.h&gt;\n#include &lt;Servo.h&gt;\n#include &lt;LiquidCrystal.h&gt;\n\n// ===== HARDWARE CONFIGURATION =====\n// TODO: Update these pin numbers to match your wiring\n\n// Servo Configuration - change angle values as needed\nconst int SERVO_PIN = 3;              // PWM pin for servo\nconst int TARGET_ANGLE = 135;          // Servo angle for target pile\nconst int NOT_TARGET_ANGLE = 53;       // Servo angle for other pile  \nconst int NEUTRAL_ANGLE = 93;         // Servo neutral/center position\n\n// LED Configuration\nconst int GREEN_LED_PIN = 10;          // Green LED (ready to sort)\nconst int RED_LED_PIN = 11;            // Red LED (stop/processing)\n\n// LCD Configuration (1602 Display)\n// LCD RS, E, D4, D5, D6, D7\nconst int LCD_RS = 13;\nconst int LCD_E = 12;\nconst int LCD_D4 = 4;\nconst int LCD_D5 = 5;\nconst int LCD_D6 = 6;\nconst int LCD_D7 = 7;\n\n// ===== HARDWARE OBJECTS =====\nServo sortingServo;\nLiquidCrystal lcd(LCD_RS, LCD_E, LCD_D4, LCD_D5, LCD_D6, LCD_D7);\n\n// ===== STORAGE CONSTANTS =====\nconst uint8_t MAX_ITEMS = 30;\nconst uint8_t MAX_STR_LEN = 50;\nconst int EEPROM_START_ADDR = 0;\nconst int NUM_ITEMS_ADDR = 0;\nconst int ITEMS_START_ADDR = 1;\n\n// ===== STATE VARIABLES =====\nString storedItems[MAX_ITEMS];\nuint8_t numStoredItems = 0;\nbool itemsLoaded = false;\n\n// Binary Sorting State\nString currentTargetClass = \"\";\nbool binarySortActive = false;\n\n// ========================================\n// SERVO-BASED COUNTING (GROUND TRUTH)\n// ========================================\nint currentPassTargetCount = 0;     // Target objects in current pass\nint currentPassOtherCount = 0;      // Non-target objects in current pass\nint totalSessionServoCount = 0;     // Total across all passes\nString lastSortedItem = \"\";\nunsigned long lastSortTime = 0;\nconst unsigned long SORT_COOLDOWN = 1500; // 1.5 seconds between operations\n\n// Mode tracking\nString currentMode = \"\";\nString lastModeMessage = \"\";\nunsigned long lastModeTime = 0;\nconst unsigned long MODE_MESSAGE_COOLDOWN = 5000;\n\n// LCD State\nString currentLCDMessage = \"\";\nunsigned long lastLCDUpdate = 0;\nconst unsigned long LCD_UPDATE_INTERVAL = 500; // Update LCD every 500ms\n\n// ===== FUNCTION DECLARATIONS =====\nvoid performTargetSortAction();\nvoid performOtherSortAction();\nvoid updateLCD(String line1, String line2);\nvoid setLEDState(bool greenOn, bool redOn);\nvoid returnServoToNeutral();\nvoid incrementServoCount();\n\n// ===== EEPROM FUNCTIONS =====\nvoid storeObjectsInEEPROM(String objects[], uint8_t count) {\nEEPROM.write(NUM_ITEMS_ADDR, count);\n\nint addr = ITEMS_START_ADDR;\nfor (uint8_t i = 0; i &lt; count; i++) {\n    String item = objects[i];\n    uint8_t len = min(item.length(), (unsigned int)(MAX_STR_LEN - 1));\n    EEPROM.write(addr, len);\n    addr++;\n\n    for (uint8_t j = 0; j &lt; len; j++) {\n    EEPROM.write(addr, item[j]);\n    addr++;\n    }\n\n    for (uint8_t j = len; j &lt; MAX_STR_LEN - 1; j++) {\n    EEPROM.write(addr, 0);\n    addr++;\n    }\n}\n\nSerial.println(\"\u2705 Objects stored in EEPROM\");\nupdateLCD(\"Objects Stored\", String(count) + \" items\");\n}\n\nvoid loadObjectsFromEEPROM() {\nnumStoredItems = EEPROM.read(NUM_ITEMS_ADDR);\n\nif (numStoredItems &gt; MAX_ITEMS) {\n    numStoredItems = 0;\n    Serial.println(\"\u26a0\ufe0f Invalid EEPROM data\");\n    updateLCD(\"EEPROM Error\", \"Data invalid\");\n    return;\n}\n\nif (numStoredItems == 0) {\n    Serial.println(\"\ud83d\udced No objects in EEPROM\");\n    updateLCD(\"Ready\", \"No objects\");\n    return;\n}\n\nint addr = ITEMS_START_ADDR;\nfor (uint8_t i = 0; i &lt; numStoredItems; i++) {\n    uint8_t len = EEPROM.read(addr);\n    addr++;\n\n    if (len &gt;= MAX_STR_LEN) len = 0;\n\n    String item = \"\";\n    for (uint8_t j = 0; j &lt; len; j++) {\n    char c = EEPROM.read(addr);\n    if (c != 0) item += c;\n    addr++;\n    }\n\n    addr += (MAX_STR_LEN - 1 - len);\n    storedItems[i] = item;\n}\n\nif (numStoredItems &gt; 0) {\n    itemsLoaded = true;\n    Serial.println(\"\ud83d\udce5 Objects loaded:\");\n    for (uint8_t i = 0; i &lt; numStoredItems; i++) {\n    Serial.print(\"  \");\n    Serial.println(storedItems[i]);\n    }\n    updateLCD(\"Objects Loaded\", String(numStoredItems) + \" items\");\n    Serial.println(\"READY_TO_SORT\");\n}\n}\n\nvoid processObjectList(String objectListString) {\nString tempItems[MAX_ITEMS];\nuint8_t count = 0;\n\nint startIdx = 0;\nint commaIdx = objectListString.indexOf(',');\n\nwhile (commaIdx != -1 &amp;&amp; count &lt; MAX_ITEMS) {\n    tempItems[count] = objectListString.substring(startIdx, commaIdx);\n    tempItems[count].trim();\n    count++;\n    startIdx = commaIdx + 1;\n    commaIdx = objectListString.indexOf(',', startIdx);\n}\n\nif (startIdx &lt; (int)objectListString.length() &amp;&amp; count &lt; MAX_ITEMS) {  // Cast to int\n    tempItems[count] = objectListString.substring(startIdx);\n    tempItems[count].trim();\n    count++;\n}\n\nif (count &gt; 0) {\n    storeObjectsInEEPROM(tempItems, count);\n    loadObjectsFromEEPROM();\n}\n}\n\n// ===== LCD CONTROL =====\nvoid updateLCD(String line1, String line2) {\nlcd.clear();\nlcd.setCursor(0, 0);\nlcd.print(line1.substring(0, 16)); // Limit to 16 chars\nlcd.setCursor(0, 1);\nlcd.print(line2.substring(0, 16));\ncurrentLCDMessage = line1 + \"|\" + line2;\n}\n\n// ===== LED CONTROL =====\nvoid setLEDState(bool greenOn, bool redOn) {\ndigitalWrite(GREEN_LED_PIN, greenOn ? HIGH : LOW);\ndigitalWrite(RED_LED_PIN, redOn ? HIGH : LOW);\n}\n\n// ===== SERVO CONTROL =====\nvoid returnServoToNeutral() {\nsortingServo.write(NEUTRAL_ANGLE);\ndelay(300); // Allow servo to reach position\n}\n\n// ========================================\n// SERVO COUNTING FUNCTIONS\n// ========================================\nvoid performTargetSortAction() {\nSerial.println(\"\ud83c\udfaf \u2192 TARGET pile\");\n\n// Move servo\nsortingServo.write(TARGET_ANGLE);\ndelay(800);\nreturnServoToNeutral();\n\n// INCREMENT COUNTERS\ncurrentPassTargetCount++;\ntotalSessionServoCount++;\n\n// Update LCD\nint total = currentPassTargetCount + currentPassOtherCount;\nupdateLCD(\"Sorting: T\" + String(currentPassTargetCount), \"Total: \" + String(total));\n\n// Send count back to Python\nSerial.print(\"SORTED_TARGET:\");\nSerial.println(currentPassTargetCount);\n}\n\nvoid performOtherSortAction() {\nSerial.println(\"\ud83d\udce6 \u2192 OTHER pile\");\n\n// Move servo\nsortingServo.write(NOT_TARGET_ANGLE);\ndelay(800);\nreturnServoToNeutral();\n\n// INCREMENT COUNTERS\ncurrentPassOtherCount++;\ntotalSessionServoCount++;\n\n// Update LCD\nint total = currentPassTargetCount + currentPassOtherCount;\nupdateLCD(\"Sorting: O\" + String(currentPassOtherCount), \"Total: \" + String(total));\n\n// Send count back to Python\nSerial.print(\"SORTED_OTHER:\");\nSerial.println(currentPassOtherCount);\n}\n\n// ===== SORTING LOGIC =====\nvoid handleBinarySortTarget(String itemClass) {\nunsigned long currentTime = millis();\n\n// Cooldown to prevent duplicate sorts\nif (itemClass != lastSortedItem || (currentTime - lastSortTime) &gt; SORT_COOLDOWN) {\n    Serial.print(\"\ud83c\udfaf TARGET: \");\n    Serial.println(itemClass);\n\n    performTargetSortAction();\n\n    lastSortedItem = itemClass;\n    lastSortTime = currentTime;\n} else {\n    Serial.println(\"\u23f1\ufe0f Cooldown active, skipping duplicate\");\n}\n}\n\nvoid handleBinarySortOther(String itemClass) {\nunsigned long currentTime = millis();\n\n// Cooldown to prevent duplicate sorts\nif (itemClass != lastSortedItem || (currentTime - lastSortTime) &gt; SORT_COOLDOWN) {\n    Serial.print(\"\ud83d\udce6 OTHER: \");\n    Serial.println(itemClass);\n\n    performOtherSortAction();\n\n    lastSortedItem = itemClass;\n    lastSortTime = currentTime;\n} else {\n    Serial.println(\"\u23f1\ufe0f Cooldown active, skipping duplicate\");\n}\n}\n\n// ===== SETUP =====\nvoid setup() {\nSerial.begin(9600);\nwhile (!Serial);\ndelay(1000);\n\nSerial.println(\"\ud83e\udd16 Arduino Binary Sorter V3 - Servo Counting\");\n\n// Initialize LCD\nlcd.begin(16, 2);\nupdateLCD(\"System Starting\", \"Please wait...\");\n\n// Initialize LEDs\npinMode(GREEN_LED_PIN, OUTPUT);\npinMode(RED_LED_PIN, OUTPUT);\nsetLEDState(false, true); // Red LED on during startup\n\n// Initialize Servo\nsortingServo.attach(SERVO_PIN);\nsortingServo.write(NEUTRAL_ANGLE);\ndelay(500);\n\nSerial.println(\"\u2705 Hardware initialized\");\n\n// Load existing objects\nloadObjectsFromEEPROM();\n\n// Ready state\nupdateLCD(\"System Ready\", \"Waiting...\");\nsetLEDState(false, false); // All LEDs off\n\nSerial.println(\"READY\");\n}\n\n// ===== MAIN LOOP =====\nvoid loop() {\nif (Serial.available()) {\n    String input = Serial.readStringUntil('\\n');\n    input.trim();\n\n    if (input.startsWith(\"STORE_OBJECTS:\")) {\n    String objectList = input.substring(14);\n    Serial.print(\"\ud83d\udce5 Storing: \");\n    Serial.println(objectList);\n    processObjectList(objectList);\n\n    } else if (input.startsWith(\"SET_TARGET:\")) {\n        currentTargetClass = input.substring(11);\n        currentPassTargetCount = 0;  // Reset target counter\n        currentPassOtherCount = 0;   // Reset other counter\n        binarySortActive = true;\n\n        Serial.print(\"\ud83c\udfaf Target set: \");\n        Serial.println(currentTargetClass);\n        Serial.println(\"PASS_COUNTER_RESET:0\");\n\n        updateLCD(\"Target: \" + currentTargetClass.substring(0, 8), \"Count: 0\");\n\n    } else if (input.startsWith(\"SORT_TARGET:\")) {\n    if (binarySortActive) {\n        String detectedClass = input.substring(12);\n        handleBinarySortTarget(detectedClass);\n    }\n\n    } else if (input.startsWith(\"SORT_OTHER:\")) {\n    if (binarySortActive) {\n        String detectedClass = input.substring(11);\n        handleBinarySortOther(detectedClass);\n    }\n\n    } else if (input == \"GREEN_LED_ON\") {\n    setLEDState(true, false);\n    Serial.println(\"\ud83d\udfe2 Green LED ON - Ready to feed\");\n\n    } else if (input == \"RED_LED_ON\") {\n    setLEDState(false, true);\n    Serial.println(\"\ud83d\udd34 Red LED ON - Stop feeding\");\n\n    } else if (input == \"GREEN_LED_OFF\") {\n    setLEDState(false, false);\n    Serial.println(\"\ud83d\udfe2 Green LED OFF\");\n\n    } else if (input == \"RED_LED_OFF\") {\n    setLEDState(false, false);\n    Serial.println(\"\ud83d\udd34 Red LED OFF\");\n\n    } else if (input == \"PAUSE_SORT\") {\n        Serial.println(\"\ud83d\uded1 PAUSE_SORT received\");\n        Serial.print(\"\ud83d\udcca Current counts - Target: \");\n        Serial.print(currentPassTargetCount);\n        Serial.print(\", Other: \");\n        Serial.println(currentPassOtherCount);\n\n        // Stop sorting immediately\n        binarySortActive = false;\n        setLEDState(false, true);  // Red LED on\n\n        Serial.println(\"\u23f3 Waiting for servo to settle...\");\n        // Wait for any in-progress servo movements to complete\n        delay(1000);\n\n        Serial.println(\"\ud83d\udce4 Sending PASS_COMPLETE...\");\n        // Send complete pass information THREE TIMES to ensure receipt\n        for (int i = 0; i &lt; 3; i++) {\n            Serial.print(\"PASS_COMPLETE:\");\n            Serial.print(currentPassTargetCount);\n            Serial.print(\":\");\n            Serial.println(currentPassOtherCount);\n            delay(100);  // Small delay between sends\n        }\n        Serial.println(\"\u2705 PASS_COMPLETE sent 3 times\");\n\n        int total = currentPassTargetCount + currentPassOtherCount;\n        updateLCD(\"Pass Complete\", \"Total: \" + String(total));\n        Serial.println(\"\u2705 Pass data sent\");\n\n        currentTargetClass = \"\";\n        lastSortedItem = \"\";\n        returnServoToNeutral();\n\n    } else if (input == \"FINISH_SORT\") {\n    binarySortActive = false;\n    currentTargetClass = \"\";\n    lastSortedItem = \"\";\n    Serial.print(\"\u2705 Session finished - Total movements: \");\n    Serial.println(totalSessionServoCount);\n    updateLCD(\"Session Done\", String(totalSessionServoCount) + \" total\");\n    setLEDState(false, false);\n    returnServoToNeutral();\n    delay(2000);\n\n    // Reset counters for next session\n    currentPassTargetCount = 0;\n    currentPassOtherCount = 0;\n    totalSessionServoCount = 0;\n\n    updateLCD(\"System Ready\", \"Waiting...\");\n\n    } else if (input == \"LOAD_OBJECTS\") {\n    loadObjectsFromEEPROM();\n\n    } else if (input == \"LIST_OBJECTS\") {\n    if (itemsLoaded &amp;&amp; numStoredItems &gt; 0) {\n        Serial.println(\"\ud83d\udccb Object list:\");\n        for (uint8_t i = 0; i &lt; numStoredItems; i++) {\n        Serial.print(\"  \");\n        Serial.print(i + 1);\n        Serial.print(\": \");\n        Serial.println(storedItems[i]);\n        }\n        if (binarySortActive) {\n        Serial.print(\"\ud83c\udfaf Current target: \");\n        Serial.println(currentTargetClass);\n        Serial.print(\"\ud83d\udd27 Pass target count: \");\n        Serial.println(currentPassTargetCount);\n        Serial.print(\"\ud83d\udd27 Pass other count: \");\n        Serial.println(currentPassOtherCount);\n        int total = currentPassTargetCount + currentPassOtherCount;\n        Serial.print(\"\ud83d\udd27 Pass total: \");\n        Serial.println(total);\n        }\n    } else {\n        Serial.println(\"\ud83d\udd2d No objects stored\");\n    }\n\n    } else if (input == \"CLEAR_OBJECTS\") {\n    EEPROM.write(NUM_ITEMS_ADDR, 0);\n    numStoredItems = 0;\n    itemsLoaded = false;\n    binarySortActive = false;\n    currentTargetClass = \"\";\n    currentPassTargetCount = 0;\n    currentPassOtherCount = 0;\n    totalSessionServoCount = 0;\n    Serial.println(\"\ud83d\uddd1\ufe0f Objects cleared &amp; counters reset\");\n    updateLCD(\"Objects Cleared\", \"Memory empty\");\n    } else if (input == \"stop\") {\n    binarySortActive = false;\n    Serial.println(\"\ud83d\uded1 Stopped\");\n    updateLCD(\"System Stopped\", \"Standby mode\");\n    setLEDState(false, false);\n    returnServoToNeutral();\n    lastSortedItem = \"\";\n\n    } else {\n    Serial.print(\"\u2753 Unknown: \");\n    Serial.println(input);\n    }\n}\n\n// Periodic LCD updates during active sorting\nunsigned long currentTime = millis();\nif (binarySortActive &amp;&amp; currentTargetClass != \"\" &amp;&amp; \n    (currentTime - lastLCDUpdate) &gt; LCD_UPDATE_INTERVAL) {\n\n    String statusLine1 = \"Tgt:\" + currentTargetClass.substring(0, 12);\n    int totalPass = currentPassTargetCount + currentPassOtherCount;\n    String statusLine2 = \"T:\" + String(currentPassTargetCount) + \" O:\" + String(currentPassOtherCount);\n\n    if (currentLCDMessage != (statusLine1 + \"|\" + statusLine2)) {\n    updateLCD(statusLine1, statusLine2);\n    }\n\n    lastLCDUpdate = currentTime;\n}\n}\n</code></pre>"},{"location":"software_v3/#software-features","title":"Software Features","text":""},{"location":"software_v3/#core-features","title":"Core Features","text":""},{"location":"software_v3/#intelligent-multi-pass-sorting","title":"Intelligent Multi-Pass Sorting","text":"<ul> <li>Binary sorting algorithm that separates objects into categories through multiple passes</li> <li>Automatic pass calculation - system determines the optimal number of passes needed (n-1 passes for n object types)</li> <li>First-pass ground truth - establishes total object count in the initial pass for accurate tracking</li> <li>Sequential processing - each pass isolates one object type until all are sorted</li> </ul>"},{"location":"software_v3/#advanced-object-detection","title":"Advanced Object Detection","text":"<ul> <li>YOLO-based real-time detection with customizable confidence thresholds</li> <li>Multi-frame confirmation system - requires consistent detection across multiple frames to prevent false positives</li> <li>Shadow and lighting compensation - filters out inconsistent detections caused by environmental factors</li> <li>Configurable detection parameters:</li> <li>Confidence threshold</li> <li>Frame confirmation count</li> <li>Detection cooldown period</li> <li>Frame processing rate</li> </ul>"},{"location":"software_v3/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Adjustable speed settings - balance between accuracy and throughput:</li> <li>Frame rate: 75-150ms per frame (6.7-13.3 fps)</li> <li>Confirmation frames: 2-3 frames required</li> <li>Detection cooldown: 1.0-2.5 seconds</li> <li>YOLO image size: Configurable for speed vs accuracy trade-off</li> <li>One-way communication protocol - eliminates serial communication overhead</li> <li>Async Arduino listener - non-blocking serial communication in separate thread</li> </ul>"},{"location":"software_v3/#comprehensive-statistics-tracking","title":"Comprehensive Statistics &amp; Tracking","text":"<ul> <li>Real-time session monitoring:</li> <li>Session duration timer</li> <li>Total objects sorted counter</li> <li>Current target display</li> <li>Throughput calculation (objects/minute)</li> <li>Pass-by-pass breakdown</li> <li>Servo-based ground truth counting - Arduino tracks physical servo movements for 100% accuracy</li> <li>Persistent session data - JSON file storage for post-session analysis</li> <li>Detailed logging system - separate log window with timestamped events</li> </ul>"},{"location":"software_v3/#user-interface","title":"User Interface","text":"<ul> <li>Modern CustomTkinter interface with dark theme</li> <li>Three-panel layout:</li> <li>Setup checklist sidebar (Arduino, Camera, Model, Objects)</li> <li>Live video feed with YOLO annotations</li> <li>Real-time statistics panel</li> <li>Progressive action button - guides user through workflow step-by-step</li> <li>Setup wizard - multi-step guided configuration process</li> <li>Visual feedback - detection confirmation indicators, progress bars, status updates</li> </ul>"},{"location":"software_v3/#hardware-integration","title":"Hardware Integration","text":"<ul> <li>Arduino Leonardo communication via serial (9600 baud)</li> <li>Automatic port detection - finds Arduino automatically</li> <li>Multi-camera support - detects and tests available cameras</li> <li>Servo control integration - precise object manipulation</li> <li>LCD display feedback - real-time status on Arduino</li> <li>LED indicators - green (ready to feed) and red (stop feeding)</li> </ul>"},{"location":"software_v3/#data-management","title":"Data Management","text":"<ul> <li>Automatic CSV logging - timestamped session logs</li> <li>Session statistics export - detailed breakdown of each sorting session</li> <li>Pass-by-pass data tracking - JSON storage for granular analysis</li> <li>Object detection setup - upload reference image to detect object types</li> </ul>"},{"location":"software_v3/#error-handling-reliability","title":"Error Handling &amp; Reliability","text":"<ul> <li>Communication timeout detection - automatic session abort on Arduino failure</li> <li>Connection monitoring - real-time Arduino and camera connection status</li> <li>Fatal error recovery - clean shutdown and system reset on failures</li> <li>Duplicate message filtering - prevents double-counting from repeated Arduino responses</li> <li>Validation checks - ensures all components ready before sorting begins</li> </ul>"},{"location":"software_v3/#customization-options","title":"Customization Options","text":"<ul> <li>Custom object ordering - drag-and-drop interface to set sorting priority</li> <li>Object filtering - checkbox system to enable/disable specific objects</li> <li>Detection parameter tuning - adjust confidence, frame rate, cooldown for specific use cases</li> <li>Visual themes - modern dark mode interface with customizable colors</li> </ul>"},{"location":"software_v3/#speed-configuration-guide","title":"Speed Configuration Guide","text":"<p>The system's processing speed can be adjusted by modifying these parameters in the Python application:</p> Parameter Impact <code>FRAME_RATE_MS</code> Camera responsiveness <code>detection_confirmation_frames</code> Detection time <code>DETECTION_COOLDOWN</code> Time between objects <code>YOLO_CONF_THRESHOLD</code> False positive rate"},{"location":"software_v3/#technical-specifications","title":"Technical Specifications","text":"<ul> <li>Language: Python 3.11+</li> <li>GUI Framework: CustomTkinter</li> <li>Computer Vision: Ultralytics YOLO</li> <li>Image Processing: OpenCV (cv2), PIL</li> <li>Arduino Communication: PySerial</li> <li>Data Storage: JSON, CSV</li> <li>Supported Cameras: Any OpenCV-compatible camera (USB, webcam)</li> <li>Supported Arduino: Leonardo (or compatible with Serial)</li> </ul>"},{"location":"software_v3/#system-flow","title":"System Flow","text":""},{"location":"software_v3/#high-level-system-architecture","title":"High-Level System Architecture","text":"<pre><code>    graph TB\n        Start([User Starts Application]) --&gt; Init[Initialize System]\n        Init --&gt; Splash[Show Splash Screen]\n        Splash --&gt; DetectHW[Detect Hardware]\n        DetectHW --&gt; MainUI[Display Main Interface]\n\n        MainUI --&gt; Wizard[User Clicks Setup Wizard]\n        Wizard --&gt; Step1[Step 1: Connect Hardware]\n        Step1 --&gt; Step2[Step 2: Load YOLO Model]\n        Step2 --&gt; Step3[Step 3: Detect Objects]\n        Step3 --&gt; Ready[System Ready]\n\n        Ready --&gt; BeginSort[Begin Sorting Session]\n        BeginSort --&gt; Pass1[Start Pass 1]\n        Pass1 --&gt; Feed1[Feed Objects]\n        Feed1 --&gt; Detect1[Detect &amp; Sort]\n        Detect1 --&gt; Complete1{Pass Complete?}\n        Complete1 --&gt;|No| Feed1\n        Complete1 --&gt;|Yes| MorePasses{More Passes?}\n\n        MorePasses --&gt;|Yes| PassN[Start Next Pass]\n        PassN --&gt; FeedN[Feed Objects]\n        FeedN --&gt; DetectN[Detect &amp; Sort]\n        DetectN --&gt; CompleteN{Pass Complete?}\n        CompleteN --&gt;|No| FeedN\n        CompleteN --&gt;|Yes| MorePasses\n\n        MorePasses --&gt;|No| Stats[Display Statistics]\n        Stats --&gt; End([Session Complete])</code></pre>"},{"location":"software_v3/#detailed-sorting-flow","title":"Detailed Sorting Flow","text":"<pre><code>    sequenceDiagram\n        participant User\n        participant Python\n        participant Camera\n        participant YOLO\n        participant Arduino\n        participant Servo\n\n        User-&gt;&gt;Python: Click \"Begin Pass N\"\n        Python-&gt;&gt;Arduino: SET_TARGET:ObjectClass\n        Arduino--&gt;&gt;Python: Target set confirmation\n        Python-&gt;&gt;Arduino: GREEN_LED_ON\n        Arduino--&gt;&gt;Python: LED status\n\n        loop Object Detection &amp; Sorting\n            Camera-&gt;&gt;Python: Capture Frame\n            Python-&gt;&gt;YOLO: Process Frame\n            YOLO--&gt;&gt;Python: Detection Results\n\n            alt Detected Object (Frame 1)\n                Python-&gt;&gt;Python: Add to buffer [1/3]\n            end\n\n            alt Detected Object (Frame 2)\n                Python-&gt;&gt;Python: Add to buffer [2/3]\n            end\n\n            alt Detected Object (Frame 3)\n                Python-&gt;&gt;Python: Confirm detection [3/3]\n\n                alt Target Object\n                    Python-&gt;&gt;Arduino: SORT_TARGET:Class\n                    Arduino-&gt;&gt;Servo: Move to TARGET position\n                    Servo--&gt;&gt;Arduino: Movement complete\n                    Arduino--&gt;&gt;Python: SORTED_TARGET:count\n                else Other Object\n                    Python-&gt;&gt;Arduino: SORT_OTHER:Class\n                    Arduino-&gt;&gt;Servo: Move to OTHER position\n                    Servo--&gt;&gt;Arduino: Movement complete\n                    Arduino--&gt;&gt;Python: SORTED_OTHER:count\n                end\n\n                Python-&gt;&gt;Python: Clear buffer\n                Python-&gt;&gt;Python: Wait cooldown (2.5s)\n            end\n        end\n\n        User-&gt;&gt;Python: Click \"Complete Pass N\"\n        Python-&gt;&gt;Arduino: PAUSE_SORT\n        Arduino-&gt;&gt;Arduino: Wait for servo settle (1s)\n        Arduino--&gt;&gt;Python: PASS_COMPLETE:target:other (x3)\n        Python-&gt;&gt;Python: Save pass data to JSON\n        Python-&gt;&gt;Python: Update statistics\n\n        alt More passes needed\n            Python-&gt;&gt;User: Show \"Begin Pass N+1\" button\n        else All passes complete\n            Python-&gt;&gt;User: Show \"Finish Session\" button\n            User-&gt;&gt;Python: Click Finish\n            Python-&gt;&gt;Python: Generate statistics\n            Python-&gt;&gt;User: Display statistics window\n        end</code></pre>"},{"location":"software_v3/#setup-wizard-flow","title":"Setup Wizard Flow","text":"<pre><code>    stateDiagram-v2\n        [*] --&gt; Step1_Hardware\n\n        state Step1_Hardware {\n            [*] --&gt; ConnectArduino\n            ConnectArduino --&gt; TestCamera\n            TestCamera --&gt; HardwareReady\n            HardwareReady --&gt; [*]\n        }\n\n        Step1_Hardware --&gt; Step2_Model: Next\n\n        state Step2_Model {\n            [*] --&gt; BrowseModel\n            BrowseModel --&gt; LoadModel\n            LoadModel --&gt; ModelReady\n            ModelReady --&gt; [*]\n        }\n\n        Step2_Model --&gt; Step3_Objects: Next\n\n        state Step3_Objects {\n            [*] --&gt; UploadImage\n            UploadImage --&gt; RunYOLO\n            RunYOLO --&gt; DetectObjects\n            DetectObjects --&gt; CustomizeOrder\n            CustomizeOrder --&gt; ObjectsReady\n            ObjectsReady --&gt; [*]\n        }\n\n        Step3_Objects --&gt; ReadyToSort: Finish\n        ReadyToSort --&gt; [*]</code></pre>"},{"location":"software_v3/#object-detection-state-machine","title":"Object Detection State Machine","text":"<pre><code>    stateDiagram-v2\n        [*] --&gt; Idle\n\n        Idle --&gt; Detecting: Object enters frame\n\n        Detecting --&gt; Frame1: Detection conf &gt; 0.65\n        Frame1 --&gt; Frame2: Same object detected\n        Frame2 --&gt; Frame3: Same object detected\n        Frame3 --&gt; Confirmed: Same object detected\n\n        Frame1 --&gt; Idle: Different object / No detection\n        Frame2 --&gt; Idle: Different object / No detection\n\n        Confirmed --&gt; SendCommand: Classification\n\n        state SendCommand {\n            [*] --&gt; CheckTarget\n            CheckTarget --&gt; Target: Matches target class\n            CheckTarget --&gt; Other: Different class\n\n            Target --&gt; SendSortTarget\n            Other --&gt; SendSortOther\n\n            SendSortTarget --&gt; [*]\n            SendSortOther --&gt; [*]\n        }\n\n        SendCommand --&gt; Cooldown\n        Cooldown --&gt; Idle: 2.5s elapsed</code></pre>"},{"location":"software_v3/#pass-calculation-logic","title":"Pass Calculation Logic","text":"<p>For N objects, N-1 passes are required, per calcuations in Python Code:</p> <p></p><pre><code>actual_passes = len(sort_classes) - 1 if len(sort_classes) &gt; 1 else len(sort_classes)\n</code></pre> Example with 4 objects Pass Target Object Objects Present Servo Movements Result 1 A A, B, C, D 50 total15 to Target 15 of 'A' sorted35 others remian 2 B B, C, D 35 total12 to Target 12 of 'B' sorted23 others remian 3 C C, D 23 total8 to Target 8 of 'C' sorted15 others remian - D D - 15 of 'D' already isolated <p>Stats:</p> Statistic Info Total Objects 50 (calculated from Pass 1) Object 'A' 15 objects Object 'B' 12 objects Object 'C' 8 objects Object 'D' 15 objects (calculated from: 50-15-12-8) <p>Servo Movement Counting:</p> <p>The system tracks complete sorting operations, not servo angles:</p> <ul> <li>1 servo movement = 1 object sorted (regardless of bin direction)</li> <li>The servo angle and amount travelled does not affect the count</li> <li>Each movement consists of: Detect \u2192 Sort (move servo) \u2192 Return to neutral \u2192 Increment counter by 1</li> </ul>"},{"location":"software_v3/#communication-protocol","title":"Communication Protocol","text":""},{"location":"software_v3/#overview","title":"Overview","text":"<p>The system uses one-way command-response serial communication at 9600 baud between Python (master) and Arduino (slave). Python sends commands, Arduino executes and reports results.</p>"},{"location":"software_v3/#serial-configuration","title":"Serial Configuration","text":"Parameter Value Baud Rate 9600 Data Bits 8 Stop Bits 1 Parity None Timeout 2 seconds"},{"location":"software_v3/#communication-architecture","title":"Communication Architecture","text":"<pre><code>graph LR\n    subgraph Python Application\n        A[Main Thread] --&gt; B[Serial TX]\n        C[Listener Thread] --&gt; D[Serial RX]\n    end\n\n    subgraph Arduino\n        E[Serial RX] --&gt; F[Command Handler]\n        F --&gt; G[Servo Controller]\n        F --&gt; H[LED Controller]\n        F --&gt; I[Counter Logic]\n        G --&gt; J[Serial TX]\n        I --&gt; J\n    end\n\n    B --&gt;|Commands| E\n    J --&gt;|Responses| C</code></pre>"},{"location":"software_v3/#command-reference","title":"Command Reference","text":""},{"location":"software_v3/#python-arduino-commands","title":"Python \u2192 Arduino Commands","text":"Command Format Description Example STORE_OBJECTS <code>STORE_OBJECTS:obj1,obj2,obj3</code> Store object list in Arduino EEPROM <code>STORE_OBJECTS:Quarter,Penny,Dime</code> SET_TARGET <code>SET_TARGET:ClassName</code> Set current target object for pass <code>SET_TARGET:Penny</code> SORT_TARGET <code>SORT_TARGET:ClassName</code> Detected target object - sort to target pile <code>SORT_TARGET:Penny</code> SORT_OTHER <code>SORT_OTHER:ClassName</code> Detected non-target - sort to other pile <code>SORT_OTHER:Quarter</code> PAUSE_SORT <code>PAUSE_SORT</code> Complete current pass and send statistics <code>PAUSE_SORT</code> FINISH_SORT <code>FINISH_SORT</code> End sorting session <code>FINISH_SORT</code> GREEN_LED_ON <code>GREEN_LED_ON</code> Turn on green LED (ready to feed) <code>GREEN_LED_ON</code> GREEN_LED_OFF <code>GREEN_LED_OFF</code> Turn off green LED <code>GREEN_LED_OFF</code> RED_LED_ON <code>RED_LED_ON</code> Turn on red LED (stop feeding) <code>RED_LED_ON</code> RED_LED_OFF <code>RED_LED_OFF</code> Turn off red LED <code>RED_LED_OFF</code> LOAD_OBJECTS <code>LOAD_OBJECTS</code> Load objects from EEPROM <code>LOAD_OBJECTS</code> LIST_OBJECTS <code>LIST_OBJECTS</code> Print stored objects to serial <code>LIST_OBJECTS</code> CLEAR_OBJECTS <code>CLEAR_OBJECTS</code> Clear EEPROM and reset counters <code>CLEAR_OBJECTS</code>"},{"location":"software_v3/#arduino-python-responses","title":"Arduino \u2192 Python Responses","text":"Response Format Description Example READY <code>READY</code> Arduino initialized and ready <code>READY</code> READY_TO_SORT <code>READY_TO_SORT</code> Objects loaded, ready to begin sorting <code>READY_TO_SORT</code> SORTED_TARGET <code>SORTED_TARGET:count</code> Target object sorted (current pass count) <code>SORTED_TARGET:5</code> SORTED_OTHER <code>SORTED_OTHER:count</code> Other object sorted (current pass count) <code>SORTED_OTHER:3</code> PASS_COMPLETE <code>PASS_COMPLETE:target:other</code> Pass finished - send final counts (sent 3x) <code>PASS_COMPLETE:4:2</code> PASS_COUNTER_RESET <code>PASS_COUNTER_RESET:0</code> Counter reset for new pass <code>PASS_COUNTER_RESET:0</code>"},{"location":"software_v3/#arduino-status-messages-informational","title":"Arduino Status Messages (Informational)","text":"<p>These messages are logged but don't trigger specific Python actions:</p> <ul> <li><code>\ud83c\udfaf Target set: ClassName</code></li> <li><code>\ud83d\udfe2 Green LED ON - Ready to feed</code></li> <li><code>\ud83d\udd34 Red LED OFF</code></li> <li><code>\ud83d\uded1 PAUSE_SORT received</code></li> <li><code>\ud83d\udcca Current counts - Target: X, Other: Y</code></li> <li><code>\u23f3 Waiting for servo to settle...</code></li> <li><code>\ud83d\udce4 Sending PASS_COMPLETE...</code></li> <li><code>\u2705 PASS_COMPLETE sent 3 times</code></li> <li><code>\u2705 Session finished - Total movements: X</code></li> </ul>"},{"location":"software_v3/#communication-flow-examples","title":"Communication Flow Examples","text":""},{"location":"software_v3/#example-1-starting-a-pass","title":"Example 1: Starting a Pass","text":"<pre><code>sequenceDiagram\n    Python-&gt;&gt;Arduino: SET_TARGET:Quarter\n    Arduino--&gt;&gt;Python: \ud83c\udfaf Target set: Quarter\n    Arduino--&gt;&gt;Python: PASS_COUNTER_RESET:0\n\n    Python-&gt;&gt;Arduino: GREEN_LED_ON\n    Arduino--&gt;&gt;Python: \ud83d\udfe2 Green LED ON - Ready to feed\n\n    Note over Python,Arduino: System ready to accept objects</code></pre>"},{"location":"software_v3/#example-2-sorting-an-object","title":"Example 2: Sorting an Object","text":"<pre><code>sequenceDiagram\n    Note over Python: Camera detects Quarter (3 frames)\n\n    Python-&gt;&gt;Arduino: SORT_TARGET:Quarter\n\n    Note over Arduino: Servo moves to TARGET position\n    Note over Arduino: Increment target counter\n\n    Arduino--&gt;&gt;Python: \ud83c\udfaf TARGET: Quarter\n    Arduino--&gt;&gt;Python: \ud83c\udfaf \u2192 TARGET pile\n    Arduino--&gt;&gt;Python: SORTED_TARGET:1\n\n    Note over Python: Update UI statistics\n    Note over Python: Wait 2.5s cooldown</code></pre>"},{"location":"software_v3/#example-3-completing-a-pass","title":"Example 3: Completing a Pass","text":"<pre><code>sequenceDiagram\n    Python-&gt;&gt;Arduino: PAUSE_SORT\n\n    Arduino--&gt;&gt;Python: \ud83d\uded1 PAUSE_SORT received\n    Arduino--&gt;&gt;Python: \ud83d\udcca Current counts - Target: 4, Other: 2\n    Arduino--&gt;&gt;Python: \u23f3 Waiting for servo to settle...\n\n    Note over Arduino: delay(1000) - servo settle time\n\n    Arduino--&gt;&gt;Python: \ud83d\udce4 Sending PASS_COMPLETE...\n    Arduino--&gt;&gt;Python: PASS_COMPLETE:4:2\n    Arduino--&gt;&gt;Python: PASS_COMPLETE:4:2\n    Arduino--&gt;&gt;Python: PASS_COMPLETE:4:2\n    Arduino--&gt;&gt;Python: \u2705 PASS_COMPLETE sent 3 times\n\n    Note over Python: Process data (first non-duplicate message)\n    Note over Python: Save to JSON file\n    Note over Python: Update statistics display</code></pre>"},{"location":"software_v3/#error-handling","title":"Error Handling","text":""},{"location":"software_v3/#communication-timeout","title":"Communication Timeout","text":"<pre><code>sequenceDiagram\n    Python-&gt;&gt;Arduino: PAUSE_SORT\n\n    Note over Python: Start 3s timeout timer\n\n    loop Every 50ms\n        Python-&gt;&gt;Python: Check for PASS_COMPLETE\n        Python-&gt;&gt;Python: Update UI (allow events)\n    end\n\n    alt Response Received\n        Arduino--&gt;&gt;Python: PASS_COMPLETE:X:Y\n        Note over Python: Success - Continue\n    else Timeout (3s)\n        Note over Python: FATAL ERROR\n        Python-&gt;&gt;Arduino: RED_LED_OFF\n        Python-&gt;&gt;Arduino: GREEN_LED_OFF\n        Note over Python: Abort session\n        Note over Python: Display error message\n        Note over Python: Reset to initial state\n    end</code></pre>"},{"location":"software_v3/#arduino-disconnection","title":"Arduino Disconnection","text":"<pre><code>graph TD\n    A[Listener Thread Active] --&gt; B{Arduino.is_open?}\n    B --&gt;|Yes| C[Read Serial Data]\n    B --&gt;|No| D[Log Disconnection]\n    D --&gt; E[Exit Listener Thread]\n\n    C --&gt; F{Data Available?}\n    F --&gt;|Yes| G[Process Message]\n    F --&gt;|No| H[Sleep 10ms]\n\n    G --&gt; A\n    H --&gt; A</code></pre>"},{"location":"software_v3/#protocol-design-principles","title":"Protocol Design Principles","text":""},{"location":"software_v3/#1-one-way-communication","title":"1. One-Way Communication","text":"<ul> <li>Python sends commands only when needed (no polling)</li> <li>Arduino sends updates only when state changes</li> <li>No request-response loops that cause serial buffer buildup</li> </ul>"},{"location":"software_v3/#2-triple-redundancy-for-critical-data","title":"2. Triple Redundancy for Critical Data","text":"<ul> <li><code>PASS_COMPLETE</code> sent 3 times to ensure receipt</li> <li>Python accepts first message, ignores duplicates</li> <li>Prevents data loss from serial buffer issues</li> </ul>"},{"location":"software_v3/#3-explicit-state-management","title":"3. Explicit State Management","text":"<ul> <li>Each pass has clear START (SET_TARGET) and END (PAUSE_SORT) markers</li> <li>Arduino resets counters on SET_TARGET</li> <li>Python tracks expected pass number to validate responses</li> </ul>"},{"location":"software_v3/#4-graceful-degradation","title":"4. Graceful Degradation","text":"<ul> <li>Timeouts trigger clean session abort (not manual entry)</li> <li>Connection checks before critical operations</li> <li>All LEDs turned off on error/exit</li> </ul>"},{"location":"software_v3/#5-human-readable-messages","title":"5. Human-Readable Messages","text":"<ul> <li>Emoji indicators for visual parsing in logs</li> <li>Clear action descriptions</li> <li>Consistent format across all messages</li> </ul>"},{"location":"software_v3/#debugging-tips","title":"Debugging Tips","text":""},{"location":"software_v3/#enable-verbose-logging","title":"Enable Verbose Logging","text":"<p>Both systems include detailed logging:</p> <p>Python: - All commands sent: <code>\ud83d\udce4 TO ARDUINO: COMMAND</code> - All responses received: <code>\ud83d\udce5 Arduino raw: RESPONSE</code> - Open logs window during operation</p> <p>Arduino: - All commands received echoed with emoji - State changes logged (LED, servo, counters) - Open Serial Monitor at 9600 baud</p>"},{"location":"software_v3/#common-issues","title":"Common Issues","text":"Symptom Likely Cause Solution Timeout on PAUSE_SORT Arduino not connected Check USB connection, restart wizard No servo movement Wrong pin configuration Verify SERVO_PIN in Arduino code Double counting Cooldown too short Increase DETECTION_COOLDOWN Objects stuck Servo angles wrong Adjust TARGET_ANGLE and NOT_TARGET_ANGLE No camera feed Camera not selected Run setup wizard, test camera <p>Serial Monitor Output Example </p><pre><code>\ud83e\udd16 Arduino Binary Sorter V3 - Servo Counting\n\u2705 Hardware initialized\n\ud83d\udced No objects in EEPROM\nREADY\n\ud83d\udce5 Storing: Quarter,Penny,Dime\n\u2705 Objects stored in EEPROM\n\ud83d\udce5 Objects loaded:\nREADY_TO_SORT\n\ud83c\udfaf Target set: Quarter\nPASS_COUNTER_RESET:0\n\ud83d\udfe2 Green LED ON - Ready to feed\n\ud83d\udce6 OTHER: Penny\n\ud83d\udce6 \u2192 OTHER pile\nSORTED_OTHER:1\n\ud83d\uded1 PAUSE_SORT received\n\ud83d\udcca Current counts - Target: 0, Other: 1\n\u23f3 Waiting for servo to settle...\n\ud83d\udce4 Sending PASS_COMPLETE...\nPASS_COMPLETE:0:1\nPASS_COMPLETE:0:1\nPASS_COMPLETE:0:1\n\u2705 PASS_COMPLETE sent 3 times\n</code></pre>"},{"location":"software_v3/#libraries","title":"Libraries","text":""},{"location":"software_v3/#python-dependencies","title":"Python Dependencies","text":"<pre><code>customtkinter&gt;=5.2.0\nopencv-python&gt;=4.8.0\nultralytics&gt;=8.0.0\npillow&gt;=10.0.0\npyserial&gt;=3.5\npandas&gt;=2.0.0\n</code></pre> <p>Install with: </p><pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"software_v3/#arduino-libraries","title":"Arduino Libraries","text":"<p>Required libraries (install via Arduino Library Manager):</p> <ul> <li>Servo (built-in)</li> <li>EEPROM (built-in)</li> <li>LiquidCrystal (built-in)</li> </ul>"},{"location":"software_v3/#yolo-models","title":"YOLO Models","text":"<p>In the Integration section of this website, I have created a page on training models. Feel free to view it there or reference it here: Training Models</p>"},{"location":"software_v3/#demo-video","title":"Demo Video","text":"<p>Note: The video includes a misdetection. This is something that isn't unusual and can be as a result of how the model was trained.</p> <p>Overall, video shows how to start up the sorting process, featuring a screen recording of the Python App as well as how it looks when a small sample of objects are sorted. Per Milestone #5, this is the small scale test that was carried out, that featured three unique classes (pennies, quarters, and dimes), with 15 objects total detected. For reference, the requirements were to use at least 3 unique classes and 10-20 objects. Overall, there was only 1 mistake, which can probably be attributed to the lighting conditions, and mistakes that can be found with the model.</p>"},{"location":"training_models/","title":"Training Models","text":""},{"location":"training_models/#overview","title":"Overview","text":"<p>There are 2 general ways to go about training models for this kind of project. Before going into those ways, I will briefly explain the general workflow for what is required to train a computer vision model, such as a YOLO model. Note that I will do most of my training and models on YOLOv8, as that has abundant documentation and datasets online.</p> <p>First, a foundational model is required to begin training. A foundational model refers to a pretrained checkpoint (on COCO or similar datasets) that is fine-tuned using your custom dataset. Below is the list of foundational models for YOLOv8:</p> <ul> <li>YOLOv8n (nano): Smallest and most lightweight model, and designed for use in devices where computational resources are limited.</li> <li>YOLOv8s (small): A good balance between speed and accuracy for most applications, and suitable for general inference tasks on CPUs and GPUs.</li> <li>YOLOv8m (medium): Mid-tier model with more extensive network architecture, allowing for higher precision. Suitable for applications that require more precision.</li> <li>YOLOv8l (large): Designed for applications where high precision is important, with the ability to extract complex features from high-resolution images.</li> <li>YOLOv8x (extra large): Largest and most powerful model, and useful for situations that require the highest accuracy where precision is critical. However, it does require high-end GPUs for efficient operation.</li> </ul> <p>It is important to note that it is not advisable to go for the largest model every time because of something known as overfitting. Basically, the model gets very good at picking up complex details such as noise, blur, etc that it performs exceptionally well on the validation and test set, but does not work the best when it comes to the real-world application, especially if the deployment condition has the potential to change. The best analogy for this would be a student that studies for an exam by memorizing practice exam questions and their answers, but doesn't perform as well on the actual exam. In this scenario, the model would memorize information rather than figure out patterns in the objects. </p> <p>However, it is important to consider that the datasets or custom dataset used MUST be somewhat relevant to what is being sorted. This is especially true for many complex objects that have some important details that have to be captured.</p> <p>Criteria for Selecting a Good Baseline Model A good baseline selection process considers project requirements and available resources: </p> <ul> <li>Hardware Availability:<ul> <li>Limited Resources (CPU only, edge device, low VRAM GPU): Start with YOLOv8n (nano) or YOLOv8s (small). These are designed for efficiency on constrained hardware.</li> <li>High-End Resources (powerful GPU server): Start with YOLOv8m (medium) or YOLOv8l (large) to aim for maximum accuracy.</li> </ul> </li> <li>Performance Requirements:<ul> <li>Real-time applications (high FPS is essential): Prioritize 'n' or 's' models.</li> <li>High accuracy is paramount (medical imaging, security): Prioritize 'l' or 'x' models, as speed is less critical than precision.</li> </ul> </li> <li>Dataset Characteristics:<ul> <li>Small or less varied datasets: A smaller model ('s' or 'm') might be less prone to overfitting and can be a better starting point.</li> <li>Large and diverse datasets: Larger models can better leverage the extensive data to learn complex patterns and achieve higher accuracy. </li> </ul> </li> </ul> <p>A good general baseline is to start with the YOLOv8s or YOLOv8m model. This provides a solid balance of speed and accuracy, and from there, you can scale up to a larger model (if more accuracy is needed and resources allow) or scale down to a smaller one (if faster inference or less VRAM is required) after observing the initial performance on your specific data. </p> <p>Alongside selecting a foundational model, a set of annotated images must be prepared. Depending on the complexity of the classes of objects being sorted, anywhere from 30-100 images per class should be chosen. Once a foundational model is selected and images are either selected or taken, then the dataset being used has to be split into train, validation, and test categories. The train category is where the foundational model will take the images and the annotations and try to learn more about each object type and recognize patterns. The validation category will be used by the model to see if it is doing a good job at detecting objects, almost like a mock exam, where the model will take a guess and then see what the answer is. The test category will be used by the model as a final exam to evaluate the model performance. </p> <p>As mentioned before here are the two ways to go about training a model:</p> <ol> <li>Start by finding a dataset on a website like Roboflow that has preannotated images, and an adequate amount of images per unique class of object in the dataset. It may also be valuable to combine a few datasets together or supplement the dataset with your own images. From there, a model can be trained.</li> <li>If there are little to no datasets online, start by taking pictures of the objects that need to be sorted and from there, use a website like Roboflow to help annotate the images. Augmentations should also be applied so that the model can handle cases like a blurry feed or a rotated camera. From there, a model can be trained.</li> </ol> <p>YOLOv8 models can be trained for object detection (.pt), segmentation (-seg.pt), or classification (-cls.pt). For object sorting tasks like this one, we use the detection model type.</p> <p>YOLOv8 expects a data.yaml file in the dataset root that defines paths for train/val/test and the class names:</p> <pre><code>train: ./train/images\nval: ./valid/images\ntest: ./test/images\nnc: 5\nnames: ['coin', 'washer', 'bolt', 'nut', 'other']\n</code></pre> <p>Below is a sample training command (I will go more in depth later):</p> <p></p><pre><code>yolo detect train data=data.yaml model=yolov8s.pt epochs=50 imgsz=640\n</code></pre> This command initializes the YOLOv8s model, uses the specified dataset, and trains for 50 epochs at 640\u00d7640 resolution."},{"location":"training_models/#code-jupyter-notebook","title":"Code (Jupyter Notebook)","text":"<p>Note, the following code cells was made to import image data from Roboflow, which would work for either of the two pathways mentioned before. It is possible to run this locally, but I used Google Colab to run this so I can connect to a GPU (which will greatly speed up the process).</p> <p>This is the EXACT code I ran to get the model that I used for my testing. View the Google Colab</p>"},{"location":"training_models/#workflow","title":"Workflow","text":"<p>While it may be tempting to pull a model from online or to use a dataset that from online, it is best to train the model. I personally found more success with training my own models than I did with using datasets from online. This can be due to the fact that the camera I have elected to use is not very high resolution, so a model will have to be trained off of that. </p> <p>However, the biggest reason that it makes sense is because the environment with which the prototype exists in NEVER changes. The same camera, backdrop, and lighting conditions are being used no matter the object type, so it makes sense to train in that environment. </p> <p>Here's a quick guide on how to train the model:</p> <ol> <li>Upload the electronics tester code onto the Arduino.</li> <li>Grab a subset of objects that require training, and ensure that there is a variety of objects and that all classes of objects are included.</li> <li>Record a video using the external webcam used for sorting and manually enter commands into the Serial Monitor to move the servo to simulate object sorting. This is for video purposes only, so no need to be concerned with where the objects go. Make sure the video is adequately long and features a variety of objects. Also, ensure lighting is optimal.</li> <li>Create a new project on Roboflow and select Object Detection. You may have to specify the classes of objects being used. Note that I extracted 1 frame every 0.25 seconds.</li> <li>Allow Roboflow to create bounding boxes on the video using prompts that you give it. I went with Grounding DINO, but any other type of segmentation model can be used to create the bounding boxes. You may have to manually enter the values in.</li> <li>Apply augmentations on the dataset. Augmentations are changes to the images captured that may occur during deployment. Common examples include: rotation, flip horizontally, flip vertically, noise, blur, etc.</li> <li>Allow Roboflow to apply augmentations and ensure a good train/val/test split. Most of the images should be training to ensure that the model has enough examples to train off of.</li> <li>Now, download the dataset from Roboflow, and select the code snippet option. Copy the code.</li> <li>Open up the Google Colab used to train the model and paste the relevant information to the appropriate cell.</li> <li>Train model by going through Google Colab and make sure that the model gets downloaded to a safe place.</li> <li>Model should now be ready for deployment.</li> </ol> <p>What not to do: It is not really useful from my testing to take pictures with a phone and then manually go through and label images. While that was great for the model statistics, it had no representation of the actual operating environment. This was especially true because the hardware that was used was subpar at best, and it was best to train everything as close to the operating environment as possible.</p>"},{"location":"training_models/#sample-model-information-statistics","title":"Sample Model Information / Statistics","text":"<p>I ended up choosing US Coins to test the object sorter on. This is down to a few reasons. First, it is something that can be abundantly found, so it is is relatively easy to get a hold of an adequate number to sort through. Second, coins are relatively complex to detect, especially the intricate differences between dimes, quarters, and nickels. If I can get coins to work, even moderately successfully, then it can serve as a great proof of concept to apply towards other sorting situations.</p> <p>Below are some pieces of information of the model I used during testing:</p> <p></p> <p></p> <p></p> <p>Note: this model is not optimal. There could have been a LOT more data points used (i.e. more objects). I recorded a video that was around 2-3 minutes long, and I should have maybe done 6-7 minutes. This would have given more data to work with and will greatly reduce any misdetections that were seen (as shown throughout the testing).</p>"},{"location":"troubleshooting/","title":"Troubleshooting and FAQ","text":""},{"location":"troubleshooting/#troubleshooting-and-faq","title":"Troubleshooting and FAQ","text":""},{"location":"troubleshooting/#troubleshooting-guide","title":"Troubleshooting Guide","text":""},{"location":"troubleshooting/#hardware-issues","title":"Hardware Issues","text":""},{"location":"troubleshooting/#arduino-not-detected","title":"Arduino Not Detected","text":"<p>Symptoms: \"No Arduino detected\" error during setup</p> <p>Solutions:</p> <ol> <li>Verify Arduino Leonardo is connected via USB</li> <li>Install Arduino drivers if on Windows</li> <li>Check Device Manager for COM port</li> <li>Try different USB cable/port</li> <li>Restart application after connecting Arduino</li> </ol>"},{"location":"troubleshooting/#camera-not-working","title":"Camera Not Working","text":"<p>Symptoms: Black screen or \"Camera test FAILED\"</p> <p>Solutions:</p> <ol> <li>Close other applications using camera (Zoom, Teams, etc.)</li> <li>Try different camera index in wizard</li> <li>Check camera permissions in Windows/macOS settings</li> <li>Verify camera works in another application first</li> <li>Use USB 2.0 port instead of USB 3.0 (sometimes more stable)</li> <li>Unplug and replug the webcam</li> </ol>"},{"location":"troubleshooting/#servo-not-moving","title":"Servo Not Moving","text":"<p>Symptoms: Objects detected but not physically sorted</p> <p>Solutions:</p> <ol> <li>Check servo is connected to correct pin (default: pin 3)</li> <li>Verify 5V power supply to servo</li> <li>Test servo with simple Arduino sketch first</li> <li>Check TARGET_ANGLE and NOT_TARGET_ANGLE values</li> <li>Ensure servo isn't mechanically blocked</li> </ol>"},{"location":"troubleshooting/#software-issues","title":"Software Issues","text":""},{"location":"troubleshooting/#model-not-loading","title":"Model Not Loading","text":"<p>Symptoms: Error when selecting .pt file</p> <p>Solutions:</p> <ol> <li>Verify file is a valid YOLO .pt model</li> <li>Check Python has ultralytics package installed</li> <li>Ensure model is trained for object detection (not classification)</li> <li>Try re-training model with latest Ultralytics YOLO</li> </ol>"},{"location":"troubleshooting/#objects-not-detected","title":"Objects Not Detected","text":"<p>Symptoms: Camera shows feed but no detections</p> <p>Solutions:</p> <ol> <li>Lower YOLO_CONF_THRESHOLD (try 0.50)</li> <li>Verify model is trained on your object classes</li> <li>Improve lighting conditions</li> <li>Ensure objects are in frame and clearly visible</li> <li>Check object names match exactly (case-sensitive)</li> </ol>"},{"location":"troubleshooting/#communication-timeouts","title":"Communication Timeouts","text":"<p>Symptoms: \"FATAL: No pass data received\" error</p> <p>Solutions:</p> <ol> <li>Increase timeout value (currently 3s)</li> <li>Check Arduino Serial Monitor for errors</li> <li>Verify Arduino code uploaded correctly</li> <li>Reset Arduino and reconnect</li> <li>Check for loose USB connection</li> </ol>"},{"location":"troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"troubleshooting/#slow-detection","title":"Slow Detection","text":"<p>Symptoms: Long delays between object detections</p> <p>Solutions:</p> <ol> <li>Reduce FRAME_RATE_MS to 100ms</li> <li>Reduce detection_confirmation_frames to 2</li> <li>Lower YOLO_IMG_SIZE to 320 (faster inference)</li> <li>Use CPU with better single-core performance</li> <li>Close other applications</li> </ol>"},{"location":"troubleshooting/#high-cpu-usage","title":"High CPU Usage","text":"<p>Symptoms: Computer fans loud, system laggy</p> <p>Solutions:</p> <ol> <li>Increase FRAME_RATE_MS to 200ms</li> <li>Reduce YOLO_IMG_SIZE to 320</li> <li>Close unnecessary applications</li> <li>Use dedicated GPU if available (CUDA)</li> </ol>"},{"location":"troubleshooting/#false-positives","title":"False Positives","text":"<p>Symptoms: Shadows or wrong objects being detected</p> <p>Solutions:</p> <ol> <li>Increase YOLO_CONF_THRESHOLD to 0.70</li> <li>Increase detection_confirmation_frames to 4</li> <li>Improve consistent lighting</li> <li>Retrain model with more diverse examples</li> <li>Add negative examples to training data</li> </ol>"},{"location":"troubleshooting/#faq","title":"FAQ","text":""},{"location":"troubleshooting/#general-questions","title":"General Questions","text":"<p>Q: How many unique object types can the system sort? A: Theoretically unlimited, but practical limit is ~10-15 unique object types due to EEPROM storage and sorting time. Each additional type requires one more pass.</p> <p>Q: How accurate is the sorting? A: Accuracy depends on model quality, lighting, and object distinctiveness. A properly trained model and a controlled testing and deployment environment can yield an accuracy above 95%.</p> <p>Q: How fast can it sort? A: Speed heavily depends on servo movement time and detection settings, and partially dependent on the quality of the model being used.</p>"},{"location":"troubleshooting/#technical-questions","title":"Technical Questions","text":"<p>Q: Why does Arduino send PASS_COMPLETE 3 times? A: Redundancy to ensure Python receives the message despite potential serial buffer issues.</p> <p>Q: What is the detection cooldown for? A: Prevents the same object from being counted multiple times as it passes through the camera view.</p> <p>Q: Can I use a different Arduino board? A: Yes, but must support Serial (not just USB CDC). Leonardo, Mega, and Uno work. Nano has limited EEPROM.</p> <p>Q: Why is the first pass total used as ground truth? A: The first pass counts ALL objects (target + non-target), providing the true total count before any are removed.</p>"},{"location":"vibration_bowl_feeder/","title":"Version 1 (Shelved)","text":"<p>The focus for development will first be on the vibration bowl feeder, as that is the more difficult thing to prototype between the vibration bowl feeder and the conveyor belt system. </p>"},{"location":"vibration_bowl_feeder/#version-11-bowl-feeder","title":"Version 1.1 (Bowl Feeder)","text":"<p>A design relatively similar to those found in industry and automation will try to be emulated, as it has strong proof of concept. Below is a list of either designed or sourced components to build the bowl feeder:</p> <ul> <li>Bowl</li> <li>3x 1027 Vibration Motors</li> <li>Underside Bowl Motor Holder (to ensure motors are pressed against bowl to transfer vibrations)</li> <li>3x Shims set 120 degrees apart (to add dampening to system)</li> <li>Hardware</li> </ul>"},{"location":"vibration_bowl_feeder/#cad","title":"CAD","text":"<p>Pictures of Components and Assembly (Click thumbnail to enlarge):</p> \u276e \u276f"},{"location":"vibration_bowl_feeder/#testing","title":"Testing","text":"<p>No images/videos are present after the very brief testing session I had with Version 1.1. Below I have written out some observations of the test.</p> <p>Observations:</p> <ul> <li>Prototype was easy to assembly (minus any soldering that had to be done due to the tiny wires and my inexperience)</li> <li>Despite using 3 1027 vibration motors, the objects did not move at all.</li> <li>The vibration power was way too low to be able to get the objects to vibrate. This was after testing various kinds of objects with various weights.</li> </ul> <p>Conclusions:</p> <ul> <li>I severly underestimated the power of a 1027 vibration motor. They are best used to give haptic feedback, but not great for vibrating an entired bowl and any components within.</li> <li>This development path might have some scope, but is yet to be seen.</li> </ul> <p>Path Forward:</p> <ul> <li>Source a stronger vibration motor that can also work with higher voltages.</li> <li>Adjust design to be able to accomodate new motor in such a way to add some dampening to ensure the right parts are vibrating. </li> </ul>"},{"location":"vibration_bowl_feeder/#version-12-bowl-feeder","title":"Version 1.2 (Bowl Feeder)","text":"<p>This design is iterated on from Version 1.1, instead focusing on using a stronger vibration motor to be able to hopefully send objects up the correct path. </p> <p>Only major changes from this version and last are as follows:</p> <p>a. Stronger motor to be used for this version, similar to this one from Amazon. </p> <p></p> <p>b. Any related design changes made to be able to accomodate motors, which meant a redesign of the underside area of the bowl itself. </p> <p>List of components included in this design below:</p> <ul> <li>Bowl (same as before)</li> <li>Eccentric Rotating Mass Vibration Motor</li> <li>Motor Grip</li> <li>Motor Housing</li> <li>3x Shims set 120 degrees apart (same as before)</li> <li>Hardware</li> </ul>"},{"location":"vibration_bowl_feeder/#cad_1","title":"CAD","text":"<p>Pictures of Components and Assembly (Click thumbnail to enlarge):</p> \u276e \u276f"},{"location":"vibration_bowl_feeder/#testing_1","title":"Testing","text":"<p>A few images are included below to show the final result of the assembly, along with my obvervations for the test.</p> <p>Observations:</p> <ul> <li>Prototype was easy to assemble, relatively similar to the last version with now more components.</li> <li>Motor was significantly more powerful, and I had to end up holding it down while I was doing my testing initially.</li> <li>Despite placing the motor horizontally in an effort to reduce the vertical attentuation, there was still significant vertical movement in the objects and the table I was testing on. A litle bit of vertical vibrations was to be expected and in fact, welcome, due to the fact the objects had to rotate up. </li> <li>The objects made it about 1/4 of the way up before the vibrations were bouncing up and down way too much, and would either fall back down the ramp or fly out of the bowl. </li> <li>After trying several voltages (ranging from 3.3V to 9V), the same things occured, which means that the concept is inherently limited.</li> </ul> <p>Post-Test Actions:</p> <ul> <li>I don't have too much knowledge of vibrations and dampening apart from a spring mass damper system that I was taught in controls class. </li> <li>I was expecting a concept that seemed easy to tune and get working to be very plug and play, when in fact, there are a lot more factors that go into the design than was expected.</li> <li>To try to fix the issue, I went online and tried to research what could be done with the motor placement. All I found was that the angle that it is placed at matters, but that is something that has to be extensively tested with the setup I have currently.</li> </ul> <p>Conclusions:</p> <ul> <li>This concept has potential to work, however, it would either require: <ol> <li>Extensive testing on my side</li> <li>Another person to be working alongside me to solely focus on tuning my current setup (ideally someone with more knowledge than me on the matter)</li> <li>A complete design overhaul of something that has nothing to do with either object detection, object sorting, or playing with more YOLO models</li> </ol> </li> </ul> <p>Path Forward:</p> <p>Based on the conclusions and the results of the testing, it is best to go down a different concept path that has more potential to be proven and to redefine the scope of the project. While object feeding would be nice, it is NOT a necessary part to get a minimum viable product up and running. Despite the system not auto feeding, I believe that something like this can still reduce object sorting times, and there is scope for object feeding to be added.</p> <p>Because of what is mentioned above, this concept is now deemed shelved and is put aside for an unspecified amount of time, and will most likely be revisited when drawing conclusions for the overall project.</p>"}]}